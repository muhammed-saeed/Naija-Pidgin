







































































































































































































































































































Epochs 1/2. Running Loss:    2.6729:   5%| | 2499/49955 [09:51<3:03:43,  4.31i/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.| 0/4206 [00:00<?, ?it/s]
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3671: FutureWarning:
`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular
`__call__` method to prepare your inputs and targets.
Here is a short example:
model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)
If you either need to use different keyword arguments for the source and target texts, you should do two calls like
this:
model_inputs = tokenizer(src_texts, ...)
labels = tokenizer(text_target=tgt_texts, ...)
model_inputs["labels"] = labels["input_ids"]
See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.
For a more complete example, see the implementation of `prepare_seq2seq_batch`.
  warnings.warn(formatted_warning, FutureWarning)
/local/home/CE/musaeed/transformers/src/transformers/tokenization_utils_base.py:3545: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(


Process ForkPoolWorker-10:                 | 501/4206 [00:27<01:04, 57.76it/s]
Process ForkPoolWorker-11:
Process ForkPoolWorker-18:
Process ForkPoolWorker-20:
Process ForkPoolWorker-13:
Process ForkPoolWorker-15:
Process ForkPoolWorker-14:
Process ForkPoolWorker-19:
Process ForkPoolWorker-17:
Process ForkPoolWorker-16:
Process ForkPoolWorker-21:
Process ForkPoolWorker-3:
Process ForkPoolWorker-4:
 48%|█████████████▎              | 2000/4206 [234:33:21<258:42:54, 422.20s/it]
Process ForkPoolWorker-1:
Process ForkPoolWorker-6:
Process ForkPoolWorker-7:
Process ForkPoolWorker-2:
Process ForkPoolWorker-9:
Process ForkPoolWorker-8:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
KeyboardInterrupt
Traceback (most recent call last):
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 365, in get
    res = self._reader.recv_bytes()
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/connection.py", line 221, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/connection.py", line 419, in _recv_bytes
    buf = self._recv(4)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/connection.py", line 384, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
KeyboardInterrupt
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Epochs 1/2. Running Loss:    2.6729:   5%| | 2499/49955 [234:43:16<4457:21:20,
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 853, in next
    item = self._items.popleft()
IndexError: pop from an empty deque
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_utils.py", line 417, in __init__
    self.examples = list(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 420, in <genexpr>
    return (item for chunk in result for item in chunk)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 858, in next
    self._cond.wait(timeout)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/CE/musaeed/Naija-Pidgin/mBART/translation/02_training_translation.py", line 54, in <module>
    model.train_model(train_df, eval_data=eval_df)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 447, in train_model
    global_step, training_details = self.train(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 830, in train
    results = self.eval_model(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 1145, in eval_model
    eval_dataset = self.load_and_cache_examples(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 1497, in load_and_cache_examples
    return SimpleSummarizationDataset(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_utils.py", line 417, in __init__
    self.examples = list(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 736, in __exit__
    self.terminate()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 654, in terminate
    self._terminate()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 692, in _terminate_pool
    cls._help_stuff_finish(inqueue, task_handler, len(pool))
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 672, in _help_stuff_finish
    inqueue._rlock.acquire()
KeyboardInterrupt
Error in sys.excepthook:
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1694, in print
    extend(render(renderable, render_options))
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/constrain.py", line 29, in __rich_console__
    yield from console.render(self.renderable, child_options)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/syntax.py", line 609, in __rich_console__
    segments = Segments(self._get_syntax(console, options))
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/segment.py", line 668, in __init__
    self.segments = list(segments)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/syntax.py", line 637, in _get_syntax
    text = self.highlight(processed_code, self.line_range)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/syntax.py", line 509, in highlight
    text.append_tokens(tokens_to_spans())
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/rich/text.py", line 999, in append_tokens
    offset += len(content)
KeyboardInterrupt
Original exception was:
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 853, in next
    item = self._items.popleft()
IndexError: pop from an empty deque
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_utils.py", line 417, in __init__
    self.examples = list(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 420, in <genexpr>
    return (item for chunk in result for item in chunk)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 858, in next
    self._cond.wait(timeout)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/CE/musaeed/Naija-Pidgin/mBART/translation/02_training_translation.py", line 54, in <module>
    model.train_model(train_df, eval_data=eval_df)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 447, in train_model
    global_step, training_details = self.train(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 830, in train
    results = self.eval_model(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 1145, in eval_model
    eval_dataset = self.load_and_cache_examples(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_model.py", line 1497, in load_and_cache_examples
    return SimpleSummarizationDataset(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/site-packages/simpletransformers/seq2seq/seq2seq_utils.py", line 417, in __init__
    self.examples = list(
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 736, in __exit__
    self.terminate()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 654, in terminate
    self._terminate()
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 692, in _terminate_pool
    cls._help_stuff_finish(inqueue, task_handler, len(pool))
  File "/home/CE/musaeed/anaconda3/envs/t5/lib/python3.9/multiprocessing/pool.py", line 672, in _help_stuff_finish
    inqueue._rlock.acquire()
KeyboardInterrupt
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<document id="doc0000624" url="http://www10.edacafe.com/nbc/articles/view_weekly.php?section=Magazine&amp;articleid=209200&amp;printerfriendly=1" time="2012-07-12-15:55" support="3" score="0.0030036634929288025" bingtitle="Six Sigma and CMM - September 20, 2004" webtitle="Six Sigma and CMM - September 20, 2004">
			<query id="000272" bing-rank="244"/>
			<query id="000257" bing-rank="110"/>
			<query id="000266" bing-rank="237"/>
	<description>... might be the drive thru at the local fast food restaurant. ... foods as a function of time from receipt of order and ... order is repeated to the customers and confirmation ...</description>
	<body>
		[ Back ] [ More News ] [ Home ] September 20, 2004 
Six Sigma and CMM
 Please note that contributed articles, blog entries, and comments posted on EDACafe.com are the views and opinion of the author and do not necessarily represent the views and opinions of the management and staff of Internet Business Systems and its subsidiary web-sites. 
 
 

 by Jack Horgan - Contributing Editor 
 Posted anew every four weeks or so, the EDA WEEKLY delivers to its readers information concerning the latest happenings in the EDA industry, covering vendors, products, finances and new developments. Frequently, feature articles on selected public or private EDA companies are presented. Brought to you by EDACafe.com. If we miss a story or subject that you feel deserves to be included, or you just want to suggest a future topic, please contact us! Questions? Feedback? Click here . Thank you! 
 
 Introduction 

Six Sigma began in 1986, when Bill Smith, a senior engineer and scientist at Motorola, introduced the concept to standardize the way defects are counted in response to increasing complaints from the field sales force about warranty claims. CEO Bob Galvin embraced the approach as the key to addressing quality concerns. The Six Sigma Quality Program was formally launched in 1987 with goals to“Improve product and service quality ten times by 1989, and at least one hundred fold by 1991. Achieve Six Sigma capability by 1992”. Six Sigma became central to Motorola&apos;s strategy of delivering products that were fit for use by customers. The application of Six Sigma was a major factor in
 Motorola


 winning the Malcolm Baldrige National Quality Award in 1988, the first year the award was given.

In 1996 Jack Welsh, the legendary CEO at General Electric, established a goal of becoming a six sigma quality company by the year 2000. Welsh credits the Six Sigma quality initiative with &quot;changing the DNA of the company, it is now the way we work - in everything we do and in every product we design.” In 1999, Six Sigma contributed $2 billion to operating income for GE.

According to GE, “Six Sigma is a highly disciplined process that helps us focus on developing and delivering near-perfect products and services” . For GE the key concepts of SixSigma are:


 Critical to Quality: Attributes most important to customers Defect: Failure to deliver what the customer wants Process Capability: What your process can deliver Variation: What the customer sees and feels Stable Operations: Ensuring consistent, predictable processes Design for Six Sigma: Designing to meet customer requirements 


 Some Mathematical Background 

Before delving into Six Sigma, we should first review some mathematical and statistical concepts. If one makes repeated and sufficiently precise measurements of a characteristic feature (area, volume, capacitance, resistance, frequency, ..) of a manufactured part or the duration of an activity, one does not get an endless series of identical values but rather a distribution of values. If there is no systematic skew, the frequency distribution is called a Gaussian or Normal distribution which is symmetric about a mean value (µ). This distribution is the familiar bell-shaped curve described by the equation:


 


whereµ(mu) is the mean value andσ(sigma) is the standard deviation given by the equation:


 


The distribution is narrow ifσis narrow and broad if it is large. The square of the standard deviation (σ 2 ) is called the variance. One can calculate the percentage of measurements that fall inside and outside the ranges ofσ±nσas shown in the diagram.


 Figure 1 Gaussian/Normal Distribution
Showing percent within±ns of the mean. 


A defect is a measurable characteristic outside the range of customer acceptance define by upper and lower specification limits. A defect is a source of irritation for the customer. Yield is defined the percentage within acceptable limits. If the measurements conform to the normal distribution, it should be straightforward to determine the yield and the number of defects. There is however a subtlety. Long experience has shown that most manufacturing processes experience a shift (due to drift over time) of 1.5 standard deviations so that the mean no longer equals target. If this sigma shift is taken into account, one can generate the table below showing defects per million
 opportunities (DPMO), i.e. number lying outside±nσof the mean.


 Table 1 Defects per million opportunities
Function of nσ 


Note: there may be numerous opportunities for defects in any given product or service.

Six Sigma is a business-driven, multi-faceted approach to process improvement, reduced costs, and increased profits. With a fundamental principle to improve customer satisfaction by reducing defects, its ultimate performance target is virtually defect-free processes and products (3.4 or fewer defective parts per million). In some industries or occupations (air traffic controller, surgeon, pharmacist) even a single defect can be catastrophic. In some industries (US Postal Service) the sheer volume of products or services delivered is such that even 3.4 dpmo can have significant consequences.

The Six Sigma process for existing products and processes is defined by the acronym DMAIC, pronounced“de-may-ick”, referring to five interconnected phases.
 Define the project goals and customer (internal and external) deliverables
 Measure the process to determine current performance
 Analyze and determine the root cause(s) of the defects
 Improve the results by redesigning the process and by eliminating defects
 Control future process performance to ensure improvements are permanent 
A second Six Sigma process is defined by the acronym DMADV, pronounced“duh-mad-vee”, for define, measure, analyze, design, and verify new processes or products that are trying to achieve Six Sigma. DMADV is sometimes referred to as Design for Six Sigma (DFSS).

An easily understood example of a Six Sigma project might be the drive thru at the local fast food restaurant. The customer requirements are a) food is still hot when customers gets to their destination b) the content of order is correct c) the change is correct and d) the time spent waiting is reasonable. One assumes that the same menu and prices are offered to drive thru customers as those who order inside.

The Six Sigma team would take measurements of wait times (time in line before ordering, time from order to delivery) at different times during the day and week, measurements of the temperature of different foods as a function of time from receipt of order and from time of delivery and so forth. They would also look at the local competition and possibly get data from other areas. Targets would be established for maximum wait time, for acceptable temperature and for the time that food remains above that temperature, and so forth.

Since the major restaurant chains have already made efforts to improve their service, we need only to look at the steps they have taken to see solutions. To reduce wait times, additional personnel are put on duty at peak times. During these busy times, the function of order taker and cashier are separated from the function of order fulfillment (also improves order accuracy) and a second window used. Drink dispensers are located near the pickup window to reduce walk time. Customers are allowed to phone in or fax in orders.

To improve the accuracy of the orders, the order is repeated to the customers and confirmation requested. Some fast food chains have computer screens so that the customer both sees and hears the order being repeated. The order is confirmed again at the pickup window.

To insure that food remains hot until it arrives at the destination, changes have been made in the packaging. A simple aluminum foil wrapper helps to keep the heat in.

To improve the accuracy of change, the cashier pushes iconic buttons defining the content of the order and the machine calculates the cost plus any tax. The cashier enters the amount received and the machine calculates the correct change.

As a control mechanism, timers are used to record customers wait times.

While this example may be useful to explain the general concepts, it greatly oversimplifies the situation. In each step there are complexities and the need for expertise not only in Six Sigma techniques but also in the specific products and processes under study. The solution to a given problem may be as complex as a semiconductor company moving to a new process node. Sophisticated tools for statistical analysis such as Pareto charts, Fishbone cause/effect diagrams, Statistical Process Control (SPC), Design of Experiments and Failure Mode and Effects Analysis are routinely employed.

Six Sigma is not a methodology or tool set that is used for one or two isolated projects. Companies adopting Six Sigma see it as company-wide culture, a corporate way of life. Executive management commitment is essential. In support of Six Sigma there is an entire industry offering training courses, formal certification programs, consulting, books, magazines, websites, software and so forth. Personnel within a firm seeking to embrace Six Sigma need to be assigned different roles related to Six Sigma projects and receive the corresponding level of training. The major roles are champion, master black belt, black belt and green belt.
 Champions sponsor Six Sigma projects through the business. A Champion is a member of the management team who is responsible for the logistical and business aspects of the Black Belt program. They link the business objectives to projects selected for the Black Belts.

 Master Black Belts train others in process improvement, have the highest level of skill and training, and sometimes are an outside consultant who specializes in Six Sigma process improvements. Master Black Belts are mentors, trainers, and coaches.

 Black Belts engage in Six Sigma &quot;full time&quot;, head Six Sigma projects, and move from department to department.

 Green Belts are trained in Six Sigma and participate in Six Sigma projects &quot;part-time&quot; which tie directly to their day-to-day work 
Other employees who receive minimal training in Six Sigma concepts are called“yellow belts”.

Six Sigma has been successfully used in many diverse industries. While Six Sigma philosophy and techniques came out of manufacturing environments, it also has been used in projects that span the entire functional organization. There are also success stories related to service organizations. A reasonable question is whether Six Sigma is adaptable for software development and maintenance and therefore for EDA companies whose products are predominately or even exclusively software.

Software manufacturing deals with the duplication, packaging and distribution of software. While software firms should take sufficient care to ensure the quality of this operation, it is the development process (requirements thru quality assurance) that is the source of concern.“Bug”or software defects are almost always generated before software manufacturing by a combination of sins of omission and commission. Bugs are generally classified according to their level of severity with crashes and loss of data being the most severe and cosmetic issues the least.

While there are parallel between the manufacture of discrete parts and the development of software, there are many differences. Consequently, one is not surprised that the software industry has come up with its own methodologies and tool sets.



 CMM 

Software Engineering Institute (SEI) of Carnegie Mellon is a federally funded research and development center sponsored by the U.S. Department of Defense. The SEI&apos;s core purpose is to help others make measured improvements in their software engineering capabilities. SEI&apos;s vision is“the right software, delivered defect free, on time and on cost, every time.”SEI seeks to help create and identify new and improved practices, leading-edge software developers and acquirers to apply and validate the new and improved practices and to encourage and support their widespread adoption.

SEI developed Capability Maturity Model (CMM) for Software in 1991. Just as a human being goes through several stages of maturity, so does a software development organization. Just as some people never truly mature, the same is true for software groups. In fact according to published accounts, few reach the highest level of maturity as shown in the figure below.


 Figure 2 Capability Maturity Model (CMM) 


At the Initial Level, the organization typically does not provide a stable environment for developing and maintaining software.

At the Repeatable Level, policies for managing a software project and procedures to implement those policies are established.

At the Defined Level, the standard process for developing and maintaining software across the organization is documented, including both software engineering and management processes, and these processes are integrated into a coherent whole.

At the Managed Level, the organization sets quantitative quality goals for both software products and processes.

At the Optimizing Level, the entire organization is focused on continuous process improvement.

CMM covers practices for planning, engineering, and managing software development and maintenance. At each level of maturity there are key practice areas that need to be focused on (see table). When followed, these key practices improve the ability of organizations to meet goals for cost, schedule, functionality, and product quality.


 Table 2 Key Practice Areas 


Each of these areas would easily justify an individual chapter in a book on CMM. Each key practice area can be described in terms of features related to commitment to perform, ability to perform, activities to be performed, measurement and analysis and verification.

Just as was the case with Six Sigma there are roles to be played, training to be given and a cottage industry of consultants, books, formal accreditation, and websites to support CMM. All quality programs Six Sigma, TQM (Total Quality Management), ISO9000 and so forth insist upon formal and well documented processes and procedures, measurement and analysis of results, and corrective actions to ensure compliance. CMM has its own process improvement model called IDEAL that serves as a roadmap for initiating, planning, and implementing improvement actions. IDEAL is an acronym for the five phases it describes: initiating, diagnosing, establishing, acting, and learning. This parallels the Six
 Sigma model.



 Requirements 

Virtually every approach to software quality and process improvement stresses the importance of ensuring the accuracy of customer requirements, i.e. Voice of the Customer. When there is a single customer for a software deliverable, there must be a common and agreed upon understanding of the requirements (function, cost, schedule, quality, performance, and environment). What may be surprising is that even when is there a single customer much less a mass market, the tasks of gathering and prioritizing requirements is a daunting one.

The Kano Diagram, introduced by Narioto Kano, divides design features into three categories: basic, performance and excitement.


 Figure 3 


Basic or threshold attributes must be present. They are implied, self-evident, and seen as the price of entry. Improvements in these attributes do not increase customer satisfaction.

Performance attributes have a linear relationship between performance and perceived value, the more the better.

Excitement features or“delighters”are unexpected, unspoken and liable to induce a“wow”response. They lead to the highest level of customer satisfaction and can provide true competitive advantage. Customers may pay a premium for these features. At a higher level a delighter would be the often sought“killer application”, an entirely new product rather than a new feature for an existing product.

Using an automobile as an example product, basic features would include engine, steering wheel, and brakes; performance features would include gas mileage and time to accelerate from 0 to 60 mph; recently introduced excitement features might include DVD entertainment center and GPS navigation system.

Marketers who use Kano diagrams take surveys, interview and/or hold focus groups of current, previous and prospective customers asking the subjects to rate existing and proposed features as


 I like it that way helpful It must be that way need I am neutral no impact I can live with it that way minor inconvenience I dislike it that way major problem 


Unfortunately the process is not as simple and straightforward as it appears on the surface. Among the common difficulties of extracting requirements are tendencies of those being asked to describe solutions rather than needs or problems, to logically extrapolate features of current systems rather than think outside the box, to add up features of every known system without regard for usefulness or need, and to treat every internal request as having equally priority - everything is a number 1 priority. A second major problem area is that requirements tend to change during the course of the project. This is sometimes referred to as“feature creep”. If a software product under
 development


 falls behind schedule, there is inevitably pressure to add requirements which of course only increases the likelihood of more delay.

During the early days of mechanical CAD it was common practice for existing customers and prospects to form large evaluation teams that created thick detailed RFP specifications, visited vendors and performed extensive benchmarks. Twelve to eighteen months sales cycles were the industry norm. Mechanical CAD seats sold at the time for well over $100K per seat versus $4K to $12K today. Since most vendor products were shared logic based, i.e. mainframe or minicomputer, the minimum purchase was in the range of 4-6 seats. The stated functional requirements grew exponentially as the evaluation teams began to include people from manufacturing and analysis. At no time did any of these
 evaluation


 teams ever ask for a minimally functional, difficult to use and slow PC based solution. But this is precisely what AutoDesk brought to the market. Few of the original mechanical CAD companies are still in existence, while AutoDesk had revenues of $280 million last quarter and a market cap of $5.4 billion.

Once I was presented with a detailed functional specification for a 5-axis Numerical Control (NC) programming package from a major customer. This would be a major development challenge at any point in time. But just to make matter worse, we were only part way along the development of a next generation system. Given the stated time requirements of the customer, we could only make the deadline, if we wrote the software on the old and soon to be replaced system. By using some third party software we were miraculously able to comber together a 5-axis package. We contacted the customer to arrange for testing the software. We were informed that the company had no 5-axis NC machines. It
 seems


 that some manager in the NC department was asked to prepare the specification. Not wishing to divert his best talent from ongoing projects, he assigned the task to someone who had just joined the company. That person wrote a specification that was well suited for his previous employer but had no relevance to the needs of our major customer.

Among more recent and relevant examples is the 64-bit processor. Intel went with a dedicated 64-bit only chip targeted at high end computing. AMD choose to offer a dual purpose chip. AMD supported a legacy mode that runs legacy (16- or 32-bit) operating systems, a compatibility mode executing existing 32-bit applications without recompilation under a 64-bit operating system and a 64-bit mode that requires an application to be compiled for 64-bit execution. AMD has made considerable inroads with this approach, which Intel has now adopted.

A second example is subscription based model for software licensing. During the most recent quarterly analysts call Dr. Aart de Geus, Synopsys CEO, commenting on 6% decrease in sales relative to last year said in part:

 “In addition, customers became more reluctant to part with cash for up-front licenses. Given that in our model, early payments are required for us to take up-front revenue, our quarterly turns business was well below the target we had set for the quarter.We have decided to immediately complete our transition to a maximally subscription-based model, where 90% or more of our revenue rolls off our backlog every quarter.” 

In general the end users of EDA tools have seen their businesses shift from telecommunications to consumer and mobile electronics with a corresponding change in product requirements e.g. need for lower power consumption. This in turn has an impact on EDA vendors.



 Quality Function Deployment There have been attempts to make requirements gathering more scientific. One such approach is Quality Function Deployment. Yoji Akao defined QFD as &quot;a method for developing a design quality aimed at satisfying the consumer and then translating the consumer&apos;s demands into design targets and major quality assurance points to be used throughout the production phase&quot; .

The most familiar form of QFD is the House of Quality that captures the customer&apos;s requirement (how), the corresponding technical requirements (what), interrelationships, correlations, priorities and benchmarks.


 Figure 4 QFD House of Quality 


If nothing else the diagram should convey the challenge involved in accurately capturing, prioritizing and translating of end user requirements.



 Agile Software Methodology 

Most of what has been written and what has been developed recently in the area of software methodology have been targeted at IT projects rather than product development much of which is enhancement and maintenance of existing code. IT projects have a well known high rate of failure and are notorious for their cost and schedule overruns. A Praeto analysis would show that misunderstand and miscommunication of often changing requirements are the major contributor to this situation. This has caused many to look for a drastic alternative to the“waterfall”approach to software development, i.e. a series of well defined steps requiring formal completion of each step before the next
 begins.


 The alternatives such as XP (eXtreme Programming) and SCRUM are members of the Agile software development family. According to the Agile Manifesto published in 2001, agilists value
 - Individuals and interaction over processes and tools
- Working software over comprehensive documentation
- Customer collaboration over contract negotiation
- Responding to change over following a plan
 
The Agile approach is incremental, collaborative, incremental and adaptive but not without its own structure, roles, responsibilities and procedures. The approach stresses the value of collocation of programmers and customer.



 Weekly Highlights 

 Mentor Graphics Announces Synthesis Support For Xilinx Virtex-4 FPGAs 

 Mentor Graphics Announces OASIS Stream File Format Ready for Production, 10X-50X File Size Reduction Benefit Confirmed

 Synopsys and Photronics Collaborate to Improve Quality and Delivery Time of Advanced Photomasks 

 Synopsys&apos; Proteus OPC Software Adopted by NEC Electronics for 90-Nanometer Production 

 Synopsys Chief Financial Officer to Speak at Banc of America Securities 34th Annual Investment Conference on September 21, 2004 

 Stone Pillar Technologies Adds Test Plan Management Software to Silicon Insighttoolkit for Semiconductor Technology Development 

 Toshiba Adopts Apache&apos;s RedHawk-SDL for SoC Power Closure 

 New Wave of FPGA Prototyping for System-on-Chip Designs 

 Synplicity Promotes Jim Lovas to Vice President, North American Sales 

 Mentor Graphics Advances Accurate Nanometer Silicon Modeling with New Resistance and Capacitance Engines 

 Synplicity Announces Best-in-Class Synthesis Support for Xilinx&apos;s Virtex-4 and Lattice Semiconductor&apos;s LatticeECP and LatticeEC FPGAs 




 More EDA in the News and More IP&amp;SoC News 


 Upcoming Events... 



 --Contributing Editors can be reached by clicking here . 

You can find the full EDACafe event calendar here .

To read more news, click here .


 -- Jack Horgan, EDACafe.com Contributing Editor. 
 
 Rating:
	</body>
</document>

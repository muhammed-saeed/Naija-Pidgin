import sys

import urllib.request as urlreq
from html.parser import HTMLParser
import re
from html.entities import entitydefs#, name2codepoint
#from io import StringIO
#import html2text

import createQueries as cQ
import readMsFiles as M
from DefaultDict import DD
import bingFunctions as bF


def removeComments(full_html):
  """
  Removes javascript from the html
  http://www.daniweb.com/software-development/python/threads/185151
  vidaj
  """
  return full_html

  tagRegex = re.compile("(?i)<(\/?\w+)((\s+\w+(\s*=\s*(?:\".*?\"|'.*?'|[^'\">\s]+))?)+\s*|\s*)\/?>")
  tagPos = {}
  indices = []
  links = {}
  for match in tagRegex.finditer(full_html):
    name = match.group(1).lower()
    value = (name, match.group(0), match.start(), match.end())
    indices.append(match.start())
    tagPos[match.start()] = value
    if name not in links.keys(): links[name] = [value]
    else: links[name].append(value)
  indices.sort()

  html = ""
  removed = ""
  tag = 'comment'
  tagCount = len(links[tag])#self.countStartTag('script')
  startTags = links[tag]
  stopTags = links[tag]

  lastStop = 0
  for start, stop in zip(startTags, stopTags):
    html += full_html[lastStop:start[2]]
    removed += full_html[start[2]:stop[3]]
    lastStop = stop[3]
  html += full_html[lastStop]

  removeTags('script')

  #print('removed javascript:')
  #print(removed)
  return html

def removeJavaScript(full_html):
  #TODO remove comments as HTMLParser does not recognize multiline comments
  full_html = removeComments(full_html)
  # but maybe these are mostly in javascript
  """
  Removes javascript from the html
  http://www.daniweb.com/software-development/python/threads/185151
  vidaj
  """
  tagRegex = re.compile("(?i)<(\/?\w+)((\s+\w+(\s*=\s*(?:\".*?\"|'.*?'|[^'\">\s]+))?)+\s*|\s*)\/?>")
  tagPos = {}
  indices = []
  links = {}
  for match in tagRegex.finditer(full_html):
    print('match:')
    print(match.groups())
    name = match.group(1).lower()
    value = (name, match.group(0), match.start(), match.end())
    indices.append(match.start())
    tagPos[match.start()] = value
    if name not in links.keys(): links[name] = [value]
    else: links[name].append(value)
  indices.sort()

  html = ""
  removed = ""

  def removeTags(tag):
    tagCount = len(links[tag])#self.countStartTag('script')
    startTags = links[tag]
    stopTags = links[tag]

    lastStop = 0
    for start, stop in zip(startTags, stopTags):
      html += full_html[lastStop:start[2]]
      removed += full_html[start[2]:stop[3]]
      lastStop = stop[3]
    html += full_html[lastStop]

  removeTags('script')

  #print('removed javascript:')
  #print(removed)
  return html

class  HTMLReader(HTMLParser):
  def __init__(self):
    self.doc = ''
    self.title = ''
    self.in_body = False
    self.in_title = False
    self.in_script = False
    self.in_style = False
    super().__init__()


  
  def handle_starttag(self, tag, attrs):
    
    if self.in_body:
      self.doc += ' '
      if tag == "script":
        self.in_script = True
      if tag == "style":
        self.in_style = True

    elif tag == 'title':
      self.in_title = True

    elif tag == "body":
      self.in_body = True
      #print('inBody')
    #print('start',tag)

  def handle_endtag(self, tag):
    if self.in_body and not self.in_script:
      self.doc += ' '

    if tag == "script":
      self.in_script = False
      if tag == "style":
        self.in_style = False
    elif tag == 'title':
      self.in_title = False
      #print(self.title)
    elif tag == "body":
      self.in_body = False
    #print('end',tag)

  def handle_data(self, data):
    if self.in_body and not self.in_script and not self.in_style:
      self.doc += data.strip()   
      #print(data.strip())
    elif self.in_title:
      self.title += data.strip()

  def handle_startendtag(self, tag, attrs):
    if self.in_body and not self.in_script and not self.in_style:
      self.doc += ' '
    #print('stend',tag)

  def handle_charref(self, name):
    if self.in_body and not self.in_script and not self.in_style:
      try:
        if name.startswith('x'):
          c = chr(int(name[1:],16))
        else:
          c = chr(int(name))
        self.doc += c

      except Exception as e:
        print('char could not be recognized:')
        print(e)
        print('\t',self.url)

      #print('char:',name,c)

  def handle_entityref(self, name):
    #print('entity:',name, chr(name2codepoint[name]), entitydefs[name])
    if self.in_body and not self.in_script and not self.in_style:
      try:
        self.doc += entitydefs[name] # '&' + name + ';'
      except KeyError as e:
        print('entitydefs KeyError', e)
        print('\t', self.url)


def get_doc(url):
  hr = HTMLReader()
  hr.url = url
  req = urlreq.Request(url)
  browser = 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)'
  req.add_header('User-Agent', browser)
  try:
    with urlreq.urlopen(req) as h:
      try:
        html = h.read().decode(errors='ignore')#.replace("'",'"')
      except Exception as e:
        print('error while decoding:')
        print(e)
        print('\t',url)
      #print('1\n',html)
      html = removeJavaScript(html) 
      try:
        hr.feed(html)
      except Exception as e:
        print('error while parsing html:')
        print(e)
        print('\t',url)
        #print('\n\n2\n',hr.title,'\n',hr.doc)
  except Exception as e:
      print('error while opening website:')
      print(e)
      print('\t',url)
      return('Website could not be opened','')
  return (hr.title,re.sub('[<>"'+"']|(&(?!(quot|amp|lt|gt|apo);))",
          lambda mo:'&' + {'<':'lt','>':'gt','&':'amp','"':'quot',
            "'":'apos'}[mo.group(0)]+ ';',hr.doc))

def get_doc_section(url, queries):
  doc = get_doc(url)
  #look for smallest complete para(s)/sections including queries?
  # immer am stueck?
  



if __name__ == '__main__':
  urls = {'http://dogdishdiet.com/2011/07/how-much-dry-food-should-i-feed-my-dog/',
          'http://en.wikipedia.org/wiki/XML'}
  for url in urls:
    with open('htmltextoutput.txt','w') as f:
      title, doc = get_doc(url)
      f.write('\n\n  <title> ' + title + '</title>\n')
      f.write('  <body>\n' + doc + '\n  </body>\n')








'''
  #mit html2text
  #http://www.tek-tips.com/viewthread.cfm?qid=1604666
  encoding = 'utf-8'
  f = urllib.urlopen(url)
  try: s = f.read()
  except: print('reading failed')
  finally: f.close()
  ustr = s.decode(encoding)
  #b = StringIO()
  #old = sys.stdout
  try:
    #sys.stdout = b
    html2text.wrapwrite(html2text.html2text(ustr, url))
  
  finally: pass #sys.stdout = old
  #text = b.getvalue()
  #b.close()
  #print(text)
  return  
  #text
'''

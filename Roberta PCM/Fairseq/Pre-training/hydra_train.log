[2022-06-12 13:27:42,756][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11969', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1}, 'task': {'_name': 'masked_lm', 'data': '/home/CE/musaeed/pcm_roberta/data-bin/pcm', 'sample_break_mode': complete, 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': none, 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 10000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2022-06-12 13:27:42,846][fairseq.tasks.masked_lm][INFO] - dictionary: 49360 types
[2022-06-12 13:27:46,093][fairseq_cli.train][INFO] - RobertaModel(
  (encoder): RobertaEncoder(
    (sentence_encoder): TransformerEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(49361, 768, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)
      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict()
)
[2022-06-12 13:27:46,095][fairseq_cli.train][INFO] - task: MaskedLMTask
[2022-06-12 13:27:46,095][fairseq_cli.train][INFO] - model: RobertaModel
[2022-06-12 13:27:46,095][fairseq_cli.train][INFO] - criterion: MaskedLmLoss
[2022-06-12 13:27:46,096][fairseq_cli.train][INFO] - num. shared model params: 124,001,489 (num. trained: 124,001,489)
[2022-06-12 13:27:46,097][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2022-06-12 13:27:46,102][fairseq.data.data_utils][INFO] - loaded 52,609 examples from: /home/CE/musaeed/pcm_roberta/data-bin/pcm/valid
[2022-06-12 13:27:46,106][fairseq.tasks.masked_lm][INFO] - loaded 6092 blocks from: /home/CE/musaeed/pcm_roberta/data-bin/pcm/valid
[2022-06-12 13:27:46,173][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2022-06-12 13:27:46,530][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2022-06-12 13:27:46,531][fairseq.trainer][INFO] - detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight
[2022-06-12 13:27:46,608][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2022-06-12 13:27:46,608][fairseq.utils][INFO] - rank   0: capabilities =  5.2  ; total memory = 11.927 GB ; name = GeForce GTX TITAN X                     
[2022-06-12 13:27:46,608][fairseq.utils][INFO] - rank   1: capabilities =  5.2  ; total memory = 11.927 GB ; name = GeForce GTX TITAN X                     
[2022-06-12 13:27:46,608][fairseq.utils][INFO] - rank   2: capabilities =  5.2  ; total memory = 11.927 GB ; name = GeForce GTX TITAN X                     
[2022-06-12 13:27:46,608][fairseq.utils][INFO] - rank   3: capabilities =  5.2  ; total memory = 11.927 GB ; name = GeForce GTX TITAN X                     
[2022-06-12 13:27:46,608][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2022-06-12 13:27:46,608][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2022-06-12 13:27:46,608][fairseq_cli.train][INFO] - max tokens per device = None and max sentences per device = 8
[2022-06-12 13:27:46,609][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2022-06-12 13:27:46,610][fairseq.trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2022-06-12 13:27:46,610][fairseq.trainer][INFO] - loading train data for epoch 1
[2022-06-12 13:27:46,618][fairseq.data.data_utils][INFO] - loaded 245,511 examples from: /home/CE/musaeed/pcm_roberta/data-bin/pcm/train
[2022-06-12 13:27:46,628][fairseq.tasks.masked_lm][INFO] - loaded 28408 blocks from: /home/CE/musaeed/pcm_roberta/data-bin/pcm/train
[2022-06-12 13:27:46,754][fairseq.tasks.fairseq_task][WARNING] - 2,036 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[12217, 4705, 4330, 26434, 20799, 27032, 2042, 4281, 25658, 2490]
[2022-06-12 13:27:46,801][fairseq.trainer][INFO] - NOTE: your device does NOT support faster training with --fp16 or --amp, please switch to FP32 which is likely to be faster
[2022-06-12 13:27:46,829][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 13:27:46,835][fairseq.trainer][INFO] - begin training epoch 1
[2022-06-12 13:27:46,835][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 13:27:59,394][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-12 13:27:59,462][root][INFO] - Reducer buckets have been rebuilt in this iteration.
[2022-06-12 13:28:09,899][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2022-06-12 13:36:00,162][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 13:36:00,165][fairseq.tasks.fairseq_task][WARNING] - 401 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[3447, 5228, 2835, 1868, 3055, 3080, 4851, 5574, 5580, 5949]
[2022-06-12 13:36:37,650][valid][INFO] - {"epoch": 1, "valid_loss": "14.944", "valid_ppl": "31527.1", "valid_wps": "67133.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "50"}
[2022-06-12 13:36:37,652][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 50 updates
[2022-06-12 13:36:37,653][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 13:36:41,082][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 13:36:41,993][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 50 updates, score 14.944) (writing took 4.340891246916726 seconds)
[2022-06-12 13:36:41,993][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2022-06-12 13:36:41,994][train][INFO] - {"epoch": 1, "train_loss": "15.531", "train_ppl": "47332.4", "train_wps": "20805.1", "train_ups": "0.1", "train_wpb": "212928", "train_bsz": "503.1", "train_num_updates": "50", "train_lr": "2.5e-06", "train_gnorm": "2.914", "train_loss_scale": "32", "train_train_wall": "489", "train_gb_free": "6.1", "train_wall": "535"}
[2022-06-12 13:36:42,004][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 13:36:42,007][fairseq.trainer][INFO] - begin training epoch 2
[2022-06-12 13:36:42,007][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 13:44:52,059][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 13:45:29,672][valid][INFO] - {"epoch": 2, "valid_loss": "14.101", "valid_ppl": "17574", "valid_wps": "67346.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "102", "valid_best_loss": "14.101"}
[2022-06-12 13:45:29,674][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 102 updates
[2022-06-12 13:45:29,675][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 13:45:34,019][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 13:45:37,632][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 102 updates, score 14.101) (writing took 7.9577004939783365 seconds)
[2022-06-12 13:45:37,632][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2022-06-12 13:45:37,633][train][INFO] - {"epoch": 2, "train_loss": "14.554", "train_ppl": "24053.2", "train_wps": "20656.2", "train_ups": "0.1", "train_wpb": "212774", "train_bsz": "503.5", "train_num_updates": "102", "train_lr": "5.1e-06", "train_gnorm": "2.319", "train_loss_scale": "32", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "1071"}
[2022-06-12 13:45:37,646][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 13:45:37,649][fairseq.trainer][INFO] - begin training epoch 3
[2022-06-12 13:45:37,649][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 13:53:46,432][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 13:54:24,060][valid][INFO] - {"epoch": 3, "valid_loss": "13.501", "valid_ppl": "11590.2", "valid_wps": "66970.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "154", "valid_best_loss": "13.501"}
[2022-06-12 13:54:24,062][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 154 updates
[2022-06-12 13:54:24,063][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 13:54:28,175][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 13:54:31,718][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 154 updates, score 13.501) (writing took 7.656228767940775 seconds)
[2022-06-12 13:54:31,719][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2022-06-12 13:54:31,721][train][INFO] - {"epoch": 3, "train_loss": "13.881", "train_ppl": "15089.4", "train_wps": "20731.8", "train_ups": "0.1", "train_wpb": "212934", "train_bsz": "503.5", "train_num_updates": "154", "train_lr": "7.7e-06", "train_gnorm": "2.081", "train_loss_scale": "32", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "1605"}
[2022-06-12 13:54:31,738][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 13:54:31,741][fairseq.trainer][INFO] - begin training epoch 4
[2022-06-12 13:54:31,741][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:01:47,572][train_inner][INFO] - {"epoch": 4, "update": 3.885, "loss": "14.323", "ppl": "20501.7", "wps": "21202.4", "ups": "0.1", "wpb": "213838", "bsz": "505.3", "num_updates": "200", "lr": "1e-05", "gnorm": "2.308", "loss_scale": "32", "train_wall": "1890", "gb_free": "6.2", "wall": "2041"}
[2022-06-12 14:02:39,497][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 14:03:17,130][valid][INFO] - {"epoch": 4, "valid_loss": "12.755", "valid_ppl": "6913.56", "valid_wps": "67405.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "206", "valid_best_loss": "12.755"}
[2022-06-12 14:03:17,131][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 206 updates
[2022-06-12 14:03:17,132][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:03:21,595][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:03:25,088][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 206 updates, score 12.755) (writing took 7.956669923034497 seconds)
[2022-06-12 14:03:25,088][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2022-06-12 14:03:25,089][train][INFO] - {"epoch": 4, "train_loss": "13.236", "train_ppl": "9644.72", "train_wps": "20757.3", "train_ups": "0.1", "train_wpb": "212909", "train_bsz": "503.5", "train_num_updates": "206", "train_lr": "1.03e-05", "train_gnorm": "1.969", "train_loss_scale": "32", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "2138"}
[2022-06-12 14:03:25,099][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 14:03:25,102][fairseq.trainer][INFO] - begin training epoch 5
[2022-06-12 14:03:25,102][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:11:35,227][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 14:12:12,887][valid][INFO] - {"epoch": 5, "valid_loss": "11.847", "valid_ppl": "3684.04", "valid_wps": "66999.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "258", "valid_best_loss": "11.847"}
[2022-06-12 14:12:12,888][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 258 updates
[2022-06-12 14:12:12,889][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:12:17,099][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:12:20,421][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 5 @ 258 updates, score 11.847) (writing took 7.532852557953447 seconds)
[2022-06-12 14:12:20,422][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2022-06-12 14:12:20,425][train][INFO] - {"epoch": 5, "train_loss": "12.396", "train_ppl": "5390.73", "train_wps": "20673.1", "train_ups": "0.1", "train_wpb": "212828", "train_bsz": "503.5", "train_num_updates": "258", "train_lr": "1.29e-05", "train_gnorm": "1.845", "train_loss_scale": "64", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "2674"}
[2022-06-12 14:12:20,456][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 14:12:20,465][fairseq.trainer][INFO] - begin training epoch 6
[2022-06-12 14:12:20,467][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:20:31,361][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 14:21:08,663][valid][INFO] - {"epoch": 6, "valid_loss": "10.988", "valid_ppl": "2031.63", "valid_wps": "67316.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "310", "valid_best_loss": "10.988"}
[2022-06-12 14:21:08,664][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 310 updates
[2022-06-12 14:21:08,665][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:21:12,787][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:21:16,110][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 6 @ 310 updates, score 10.988) (writing took 7.445715702953748 seconds)
[2022-06-12 14:21:16,110][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2022-06-12 14:21:16,112][train][INFO] - {"epoch": 6, "train_loss": "11.498", "train_ppl": "2893.02", "train_wps": "20665.2", "train_ups": "0.1", "train_wpb": "212886", "train_bsz": "503.5", "train_num_updates": "310", "train_lr": "1.55e-05", "train_gnorm": "1.615", "train_loss_scale": "64", "train_train_wall": "486", "train_gb_free": "6.1", "train_wall": "3210"}
[2022-06-12 14:21:16,139][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 14:21:16,147][fairseq.trainer][INFO] - begin training epoch 7
[2022-06-12 14:21:16,149][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:29:25,016][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 14:30:02,695][valid][INFO] - {"epoch": 7, "valid_loss": "10.277", "valid_ppl": "1240.72", "valid_wps": "67446.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "362", "valid_best_loss": "10.277"}
[2022-06-12 14:30:02,697][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 362 updates
[2022-06-12 14:30:02,698][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:30:06,894][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:30:10,244][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 7 @ 362 updates, score 10.277) (writing took 7.5473208100302145 seconds)
[2022-06-12 14:30:10,245][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2022-06-12 14:30:10,245][train][INFO] - {"epoch": 7, "train_loss": "10.698", "train_ppl": "1661.4", "train_wps": "20729.6", "train_ups": "0.1", "train_wpb": "212930", "train_bsz": "503.5", "train_num_updates": "362", "train_lr": "1.81e-05", "train_gnorm": "1.306", "train_loss_scale": "64", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "3744"}
[2022-06-12 14:30:10,256][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 14:30:10,259][fairseq.trainer][INFO] - begin training epoch 8
[2022-06-12 14:30:10,260][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:36:10,385][train_inner][INFO] - {"epoch": 8, "update": 7.731, "loss": "11.298", "ppl": "2517.66", "wps": "20613.5", "ups": "0.1", "wpb": "212608", "bsz": "503.1", "num_updates": "400", "lr": "2e-05", "gnorm": "1.504", "loss_scale": "64", "train_wall": "1864", "gb_free": "6.2", "wall": "4104"}
[2022-06-12 14:38:19,244][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 14:38:56,818][valid][INFO] - {"epoch": 8, "valid_loss": "9.794", "valid_ppl": "888.03", "valid_wps": "67220.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "414", "valid_best_loss": "9.794"}
[2022-06-12 14:38:56,820][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 414 updates
[2022-06-12 14:38:56,821][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:39:01,019][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:39:04,354][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 8 @ 414 updates, score 9.794) (writing took 7.534718306036666 seconds)
[2022-06-12 14:39:04,355][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2022-06-12 14:39:04,357][train][INFO] - {"epoch": 8, "train_loss": "10.085", "train_ppl": "1086.14", "train_wps": "20723.5", "train_ups": "0.1", "train_wpb": "212859", "train_bsz": "503.5", "train_num_updates": "414", "train_lr": "2.07e-05", "train_gnorm": "0.987", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.1", "train_wall": "4278"}
[2022-06-12 14:39:04,374][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 14:39:04,377][fairseq.trainer][INFO] - begin training epoch 9
[2022-06-12 14:39:04,377][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:47:15,916][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 14:47:53,503][valid][INFO] - {"epoch": 9, "valid_loss": "9.458", "valid_ppl": "703.21", "valid_wps": "67183.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "466", "valid_best_loss": "9.458"}
[2022-06-12 14:47:53,505][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 466 updates
[2022-06-12 14:47:53,506][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:47:57,820][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:48:01,284][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 9 @ 466 updates, score 9.458) (writing took 7.778824111097492 seconds)
[2022-06-12 14:48:01,285][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2022-06-12 14:48:01,287][train][INFO] - {"epoch": 9, "train_loss": "9.677", "train_ppl": "818.51", "train_wps": "20624.9", "train_ups": "0.1", "train_wpb": "212963", "train_bsz": "503.5", "train_num_updates": "466", "train_lr": "2.33e-05", "train_gnorm": "0.765", "train_loss_scale": "64", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "4815"}
[2022-06-12 14:48:01,305][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 14:48:01,309][fairseq.trainer][INFO] - begin training epoch 10
[2022-06-12 14:48:01,309][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:56:10,925][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 14:56:48,528][valid][INFO] - {"epoch": 10, "valid_loss": "9.26", "valid_ppl": "613.16", "valid_wps": "67001.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "518", "valid_best_loss": "9.26"}
[2022-06-12 14:56:48,530][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 518 updates
[2022-06-12 14:56:48,531][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:56:52,938][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 14:56:56,309][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 10 @ 518 updates, score 9.26) (writing took 7.778115296037868 seconds)
[2022-06-12 14:56:56,310][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2022-06-12 14:56:56,313][train][INFO] - {"epoch": 10, "train_loss": "9.427", "train_ppl": "688.48", "train_wps": "20690.1", "train_ups": "0.1", "train_wpb": "212879", "train_bsz": "503.5", "train_num_updates": "518", "train_lr": "2.59e-05", "train_gnorm": "0.524", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "5350"}
[2022-06-12 14:56:56,346][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 14:56:56,355][fairseq.trainer][INFO] - begin training epoch 11
[2022-06-12 14:56:56,356][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 14:57:05,921][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-12 15:05:05,472][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 15:05:43,188][valid][INFO] - {"epoch": 11, "valid_loss": "9.119", "valid_ppl": "555.88", "valid_wps": "67079.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "569", "valid_best_loss": "9.119"}
[2022-06-12 15:05:43,190][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 11 @ 569 updates
[2022-06-12 15:05:43,191][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:05:47,203][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:05:50,552][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 11 @ 569 updates, score 9.119) (writing took 7.361902424949221 seconds)
[2022-06-12 15:05:50,552][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2022-06-12 15:05:50,554][train][INFO] - {"epoch": 11, "train_loss": "9.251", "train_ppl": "609.47", "train_wps": "20321.9", "train_ups": "0.1", "train_wpb": "212878", "train_bsz": "503.3", "train_num_updates": "569", "train_lr": "2.845e-05", "train_gnorm": "0.608", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "5884"}
[2022-06-12 15:05:50,573][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 15:05:50,576][fairseq.trainer][INFO] - begin training epoch 12
[2022-06-12 15:05:50,576][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 15:10:44,160][train_inner][INFO] - {"epoch": 12, "update": 11.596, "loss": "9.437", "ppl": "693.29", "wps": "20521", "ups": "0.1", "wpb": "212779", "bsz": "503.1", "num_updates": "600", "lr": "3e-05", "gnorm": "0.652", "loss_scale": "64", "train_wall": "1875", "gb_free": "6.1", "wall": "6178"}
[2022-06-12 15:13:59,650][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 15:14:37,137][valid][INFO] - {"epoch": 12, "valid_loss": "9.082", "valid_ppl": "541.94", "valid_wps": "67039.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "621", "valid_best_loss": "9.082"}
[2022-06-12 15:14:37,139][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 621 updates
[2022-06-12 15:14:37,140][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:14:41,369][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:14:44,686][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 12 @ 621 updates, score 9.082) (writing took 7.54719265201129 seconds)
[2022-06-12 15:14:44,687][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2022-06-12 15:14:44,688][train][INFO] - {"epoch": 12, "train_loss": "9.129", "train_ppl": "560.04", "train_wps": "20732.5", "train_ups": "0.1", "train_wpb": "212960", "train_bsz": "503.5", "train_num_updates": "621", "train_lr": "3.105e-05", "train_gnorm": "0.638", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "6418"}
[2022-06-12 15:14:44,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 15:14:44,726][fairseq.trainer][INFO] - begin training epoch 13
[2022-06-12 15:14:44,727][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 15:14:54,894][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2022-06-12 15:15:03,188][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2022-06-12 15:22:55,597][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 15:23:33,105][valid][INFO] - {"epoch": 13, "valid_loss": "8.887", "valid_ppl": "473.44", "valid_wps": "67039.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "671", "valid_best_loss": "8.887"}
[2022-06-12 15:23:33,106][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 13 @ 671 updates
[2022-06-12 15:23:33,107][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:23:37,817][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:23:41,658][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 13 @ 671 updates, score 8.887) (writing took 8.551684182020836 seconds)
[2022-06-12 15:23:41,659][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2022-06-12 15:23:41,660][train][INFO] - {"epoch": 13, "train_loss": "9.017", "train_ppl": "517.98", "train_wps": "19801.5", "train_ups": "0.09", "train_wpb": "212656", "train_bsz": "503.1", "train_num_updates": "671", "train_lr": "3.355e-05", "train_gnorm": "0.967", "train_loss_scale": "16", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "6955"}
[2022-06-12 15:23:41,690][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 15:23:41,698][fairseq.trainer][INFO] - begin training epoch 14
[2022-06-12 15:23:41,699][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 15:31:52,657][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 15:32:30,142][valid][INFO] - {"epoch": 14, "valid_loss": "8.864", "valid_ppl": "465.97", "valid_wps": "67010", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "723", "valid_best_loss": "8.864"}
[2022-06-12 15:32:30,144][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 723 updates
[2022-06-12 15:32:30,145][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:32:34,559][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:32:38,011][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 14 @ 723 updates, score 8.864) (writing took 7.867273056996055 seconds)
[2022-06-12 15:32:38,011][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2022-06-12 15:32:38,012][train][INFO] - {"epoch": 14, "train_loss": "8.872", "train_ppl": "468.55", "train_wps": "20653", "train_ups": "0.1", "train_wpb": "213024", "train_bsz": "503.5", "train_num_updates": "723", "train_lr": "3.615e-05", "train_gnorm": "0.987", "train_loss_scale": "16", "train_train_wall": "486", "train_gb_free": "6.1", "train_wall": "7491"}
[2022-06-12 15:32:38,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 15:32:38,026][fairseq.trainer][INFO] - begin training epoch 15
[2022-06-12 15:32:38,027][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 15:40:49,550][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 15:41:27,172][valid][INFO] - {"epoch": 15, "valid_loss": "8.616", "valid_ppl": "392.47", "valid_wps": "67162.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "775", "valid_best_loss": "8.616"}
[2022-06-12 15:41:27,173][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 775 updates
[2022-06-12 15:41:27,174][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:41:31,423][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:41:34,709][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 15 @ 775 updates, score 8.616) (writing took 7.535104262991808 seconds)
[2022-06-12 15:41:34,710][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2022-06-12 15:41:34,711][train][INFO] - {"epoch": 15, "train_loss": "8.735", "train_ppl": "425.99", "train_wps": "20635", "train_ups": "0.1", "train_wpb": "212976", "train_bsz": "503.5", "train_num_updates": "775", "train_lr": "3.875e-05", "train_gnorm": "1.389", "train_loss_scale": "16", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "8028"}
[2022-06-12 15:41:34,733][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 15:41:34,736][fairseq.trainer][INFO] - begin training epoch 16
[2022-06-12 15:41:34,737][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 15:45:30,504][train_inner][INFO] - {"epoch": 16, "update": 15.481, "loss": "8.864", "ppl": "465.8", "wps": "20393", "ups": "0.1", "wpb": "212734", "bsz": "503.1", "num_updates": "800", "lr": "4e-05", "gnorm": "1.073", "loss_scale": "16", "train_wall": "1887", "gb_free": "6.2", "wall": "8264"}
[2022-06-12 15:49:43,330][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 15:50:20,756][valid][INFO] - {"epoch": 16, "valid_loss": "8.844", "valid_ppl": "459.65", "valid_wps": "67131.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "827", "valid_best_loss": "8.616"}
[2022-06-12 15:50:20,757][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 827 updates
[2022-06-12 15:50:20,758][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 15:50:25,045][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 15:50:25,085][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 16 @ 827 updates, score 8.844) (writing took 4.32772753702011 seconds)
[2022-06-12 15:50:25,085][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2022-06-12 15:50:25,086][train][INFO] - {"epoch": 16, "train_loss": "8.612", "train_ppl": "391.18", "train_wps": "20872.1", "train_ups": "0.1", "train_wpb": "212885", "train_bsz": "503.5", "train_num_updates": "827", "train_lr": "4.135e-05", "train_gnorm": "1.429", "train_loss_scale": "16", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "8558"}
[2022-06-12 15:50:25,099][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 15:50:25,102][fairseq.trainer][INFO] - begin training epoch 17
[2022-06-12 15:50:25,103][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 15:50:35,207][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 15:58:35,058][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 15:59:12,444][valid][INFO] - {"epoch": 17, "valid_loss": "8.404", "valid_ppl": "338.7", "valid_wps": "67245.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "878", "valid_best_loss": "8.404"}
[2022-06-12 15:59:12,445][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 17 @ 878 updates
[2022-06-12 15:59:12,446][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:59:16,617][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 15:59:19,994][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 17 @ 878 updates, score 8.404) (writing took 7.5483304660301656 seconds)
[2022-06-12 15:59:19,995][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2022-06-12 15:59:19,997][train][INFO] - {"epoch": 17, "train_loss": "8.561", "train_ppl": "377.8", "train_wps": "20291.8", "train_ups": "0.1", "train_wpb": "212829", "train_bsz": "503.3", "train_num_updates": "878", "train_lr": "4.39e-05", "train_gnorm": "1.897", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "9093"}
[2022-06-12 15:59:20,022][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 15:59:20,030][fairseq.trainer][INFO] - begin training epoch 18
[2022-06-12 15:59:20,032][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 16:07:27,309][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 16:08:04,708][valid][INFO] - {"epoch": 18, "valid_loss": "8.352", "valid_ppl": "326.73", "valid_wps": "67140", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "930", "valid_best_loss": "8.352"}
[2022-06-12 16:08:04,709][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 18 @ 930 updates
[2022-06-12 16:08:04,710][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:08:08,952][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:08:12,493][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 18 @ 930 updates, score 8.352) (writing took 7.784094001050107 seconds)
[2022-06-12 16:08:12,494][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2022-06-12 16:08:12,496][train][INFO] - {"epoch": 18, "train_loss": "8.436", "train_ppl": "346.43", "train_wps": "20798.4", "train_ups": "0.1", "train_wpb": "212982", "train_bsz": "503.5", "train_num_updates": "930", "train_lr": "4.65e-05", "train_gnorm": "1.193", "train_loss_scale": "8", "train_train_wall": "483", "train_gb_free": "6.3", "train_wall": "9626"}
[2022-06-12 16:08:12,520][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 16:08:12,529][fairseq.trainer][INFO] - begin training epoch 19
[2022-06-12 16:08:12,530][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 16:16:21,923][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 16:16:59,501][valid][INFO] - {"epoch": 19, "valid_loss": "8.499", "valid_ppl": "361.83", "valid_wps": "67388.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "982", "valid_best_loss": "8.352"}
[2022-06-12 16:16:59,503][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 19 @ 982 updates
[2022-06-12 16:16:59,504][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 16:17:03,668][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 16:17:03,734][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 19 @ 982 updates, score 8.499) (writing took 4.230647379066795 seconds)
[2022-06-12 16:17:03,734][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2022-06-12 16:17:03,735][train][INFO] - {"epoch": 19, "train_loss": "8.344", "train_ppl": "324.98", "train_wps": "20830.7", "train_ups": "0.1", "train_wpb": "212809", "train_bsz": "503.5", "train_num_updates": "982", "train_lr": "4.91e-05", "train_gnorm": "1.48", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "10157"}
[2022-06-12 16:17:03,753][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 16:17:03,758][fairseq.trainer][INFO] - begin training epoch 20
[2022-06-12 16:17:03,759][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 16:19:55,994][train_inner][INFO] - {"epoch": 20, "update": 19.346, "loss": "8.459", "ppl": "351.85", "wps": "20613.7", "ups": "0.1", "wpb": "212887", "bsz": "503.1", "num_updates": "1000", "lr": "5e-05", "gnorm": "1.632", "loss_scale": "8", "train_wall": "1873", "gb_free": "6.2", "wall": "10329"}
[2022-06-12 16:25:11,999][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 16:25:49,697][valid][INFO] - {"epoch": 20, "valid_loss": "8.331", "valid_ppl": "321.96", "valid_wps": "67133.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1034", "valid_best_loss": "8.331"}
[2022-06-12 16:25:49,699][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 1034 updates
[2022-06-12 16:25:49,700][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:25:53,749][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:25:57,087][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 20 @ 1034 updates, score 8.331) (writing took 7.38844060106203 seconds)
[2022-06-12 16:25:57,088][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2022-06-12 16:25:57,089][train][INFO] - {"epoch": 20, "train_loss": "8.306", "train_ppl": "316.47", "train_wps": "20754", "train_ups": "0.1", "train_wpb": "212870", "train_bsz": "503.5", "train_num_updates": "1034", "train_lr": "5.17e-05", "train_gnorm": "1.624", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "10690"}
[2022-06-12 16:25:57,117][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 16:25:57,126][fairseq.trainer][INFO] - begin training epoch 21
[2022-06-12 16:25:57,127][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 16:34:06,937][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 16:34:44,575][valid][INFO] - {"epoch": 21, "valid_loss": "8.261", "valid_ppl": "306.82", "valid_wps": "67339.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1086", "valid_best_loss": "8.261"}
[2022-06-12 16:34:44,577][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 21 @ 1086 updates
[2022-06-12 16:34:44,578][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:34:49,135][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:34:52,637][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 21 @ 1086 updates, score 8.261) (writing took 8.059114622999914 seconds)
[2022-06-12 16:34:52,638][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2022-06-12 16:34:52,641][train][INFO] - {"epoch": 21, "train_loss": "8.223", "train_ppl": "298.75", "train_wps": "20662", "train_ups": "0.1", "train_wpb": "212798", "train_bsz": "503.5", "train_num_updates": "1086", "train_lr": "5.43e-05", "train_gnorm": "1.924", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "11226"}
[2022-06-12 16:34:52,661][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 16:34:52,666][fairseq.trainer][INFO] - begin training epoch 22
[2022-06-12 16:34:52,667][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 16:35:02,686][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 16:42:58,530][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 16:43:36,183][valid][INFO] - {"epoch": 22, "valid_loss": "8.147", "valid_ppl": "283.41", "valid_wps": "66984.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1137", "valid_best_loss": "8.147"}
[2022-06-12 16:43:36,185][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 22 @ 1137 updates
[2022-06-12 16:43:36,186][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:43:40,277][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:43:43,805][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 22 @ 1137 updates, score 8.147) (writing took 7.619542667991482 seconds)
[2022-06-12 16:43:43,805][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2022-06-12 16:43:43,807][train][INFO] - {"epoch": 22, "train_loss": "8.139", "train_ppl": "281.83", "train_wps": "20428.4", "train_ups": "0.1", "train_wpb": "212762", "train_bsz": "503.3", "train_num_updates": "1137", "train_lr": "5.685e-05", "train_gnorm": "1.874", "train_loss_scale": "8", "train_train_wall": "481", "train_gb_free": "6.2", "train_wall": "11757"}
[2022-06-12 16:43:43,823][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 16:43:43,826][fairseq.trainer][INFO] - begin training epoch 23
[2022-06-12 16:43:43,826][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 16:51:51,454][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 16:52:28,982][valid][INFO] - {"epoch": 23, "valid_loss": "8.13", "valid_ppl": "280.07", "valid_wps": "67313.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1189", "valid_best_loss": "8.13"}
[2022-06-12 16:52:28,984][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 23 @ 1189 updates
[2022-06-12 16:52:28,984][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:52:33,258][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 16:52:36,535][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 23 @ 1189 updates, score 8.13) (writing took 7.551720600924455 seconds)
[2022-06-12 16:52:36,536][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2022-06-12 16:52:36,538][train][INFO] - {"epoch": 23, "train_loss": "8.066", "train_ppl": "267.96", "train_wps": "20777.7", "train_ups": "0.1", "train_wpb": "212864", "train_bsz": "503.5", "train_num_updates": "1189", "train_lr": "5.945e-05", "train_gnorm": "1.798", "train_loss_scale": "8", "train_train_wall": "483", "train_gb_free": "6.1", "train_wall": "12290"}
[2022-06-12 16:52:36,556][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 16:52:36,559][fairseq.trainer][INFO] - begin training epoch 24
[2022-06-12 16:52:36,560][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 16:54:22,091][train_inner][INFO] - {"epoch": 24, "update": 23.212, "loss": "8.162", "ppl": "286.36", "wps": "20594.1", "ups": "0.1", "wpb": "212746", "bsz": "503.1", "num_updates": "1200", "lr": "6e-05", "gnorm": "1.814", "loss_scale": "8", "train_wall": "1867", "gb_free": "6.1", "wall": "12395"}
[2022-06-12 17:00:45,898][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 17:01:23,529][valid][INFO] - {"epoch": 24, "valid_loss": "7.881", "valid_ppl": "235.69", "valid_wps": "67004.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1241", "valid_best_loss": "7.881"}
[2022-06-12 17:01:23,531][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 24 @ 1241 updates
[2022-06-12 17:01:23,532][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:01:27,580][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:01:30,904][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 24 @ 1241 updates, score 7.881) (writing took 7.372529592947103 seconds)
[2022-06-12 17:01:30,904][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2022-06-12 17:01:30,906][train][INFO] - {"epoch": 24, "train_loss": "8.014", "train_ppl": "258.43", "train_wps": "20719.3", "train_ups": "0.1", "train_wpb": "212918", "train_bsz": "503.5", "train_num_updates": "1241", "train_lr": "6.205e-05", "train_gnorm": "1.933", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "12824"}
[2022-06-12 17:01:30,933][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 17:01:30,941][fairseq.trainer][INFO] - begin training epoch 25
[2022-06-12 17:01:30,942][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 17:09:40,735][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 17:10:18,043][valid][INFO] - {"epoch": 25, "valid_loss": "7.975", "valid_ppl": "251.65", "valid_wps": "67399.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1293", "valid_best_loss": "7.881"}
[2022-06-12 17:10:18,044][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 1293 updates
[2022-06-12 17:10:18,045][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 17:10:22,559][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 17:10:22,600][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 25 @ 1293 updates, score 7.975) (writing took 4.555195421911776 seconds)
[2022-06-12 17:10:22,600][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2022-06-12 17:10:22,601][train][INFO] - {"epoch": 25, "train_loss": "7.928", "train_ppl": "243.58", "train_wps": "20804.9", "train_ups": "0.1", "train_wpb": "212728", "train_bsz": "503.5", "train_num_updates": "1293", "train_lr": "6.465e-05", "train_gnorm": "1.803", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "13356"}
[2022-06-12 17:10:22,613][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 17:10:22,617][fairseq.trainer][INFO] - begin training epoch 26
[2022-06-12 17:10:22,618][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 17:18:32,117][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 17:19:09,562][valid][INFO] - {"epoch": 26, "valid_loss": "7.903", "valid_ppl": "239.3", "valid_wps": "67114.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1345", "valid_best_loss": "7.881"}
[2022-06-12 17:19:09,564][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 26 @ 1345 updates
[2022-06-12 17:19:09,565][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 17:19:13,790][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 17:19:13,835][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 26 @ 1345 updates, score 7.903) (writing took 4.27163135795854 seconds)
[2022-06-12 17:19:13,836][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2022-06-12 17:19:13,837][train][INFO] - {"epoch": 26, "train_loss": "7.866", "train_ppl": "233.29", "train_wps": "20836.4", "train_ups": "0.1", "train_wpb": "212866", "train_bsz": "503.5", "train_num_updates": "1345", "train_lr": "6.725e-05", "train_gnorm": "1.878", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "13887"}
[2022-06-12 17:19:13,848][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 17:19:13,851][fairseq.trainer][INFO] - begin training epoch 27
[2022-06-12 17:19:13,851][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 17:19:23,284][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 17:27:22,673][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 17:28:00,111][valid][INFO] - {"epoch": 27, "valid_loss": "7.838", "valid_ppl": "228.84", "valid_wps": "66958.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1396", "valid_best_loss": "7.838"}
[2022-06-12 17:28:00,113][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 27 @ 1396 updates
[2022-06-12 17:28:00,113][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:28:04,155][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:28:07,571][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 27 @ 1396 updates, score 7.838) (writing took 7.4586903610033914 seconds)
[2022-06-12 17:28:07,572][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2022-06-12 17:28:07,574][train][INFO] - {"epoch": 27, "train_loss": "7.794", "train_ppl": "221.94", "train_wps": "20344.7", "train_ups": "0.1", "train_wpb": "212916", "train_bsz": "503.4", "train_num_updates": "1396", "train_lr": "6.98e-05", "train_gnorm": "2.145", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "14421"}
[2022-06-12 17:28:07,594][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 17:28:07,602][fairseq.trainer][INFO] - begin training epoch 28
[2022-06-12 17:28:07,603][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 17:28:42,926][train_inner][INFO] - {"epoch": 28, "update": 27.077, "loss": "7.889", "ppl": "237.05", "wps": "20639", "ups": "0.1", "wpb": "212668", "bsz": "503.1", "num_updates": "1400", "lr": "7e-05", "gnorm": "1.916", "loss_scale": "8", "train_wall": "1870", "gb_free": "6.2", "wall": "14456"}
[2022-06-12 17:36:15,009][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 17:36:52,499][valid][INFO] - {"epoch": 28, "valid_loss": "7.642", "valid_ppl": "199.78", "valid_wps": "67253.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1448", "valid_best_loss": "7.642"}
[2022-06-12 17:36:52,500][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 28 @ 1448 updates
[2022-06-12 17:36:52,501][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:36:57,108][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:37:00,338][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 28 @ 1448 updates, score 7.642) (writing took 7.837459281086922 seconds)
[2022-06-12 17:37:00,338][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2022-06-12 17:37:00,339][train][INFO] - {"epoch": 28, "train_loss": "7.723", "train_ppl": "211.35", "train_wps": "20791.5", "train_ups": "0.1", "train_wpb": "213019", "train_bsz": "503.5", "train_num_updates": "1448", "train_lr": "7.24e-05", "train_gnorm": "1.987", "train_loss_scale": "8", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "14954"}
[2022-06-12 17:37:00,351][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 17:37:00,354][fairseq.trainer][INFO] - begin training epoch 29
[2022-06-12 17:37:00,355][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 17:45:07,573][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 17:45:45,137][valid][INFO] - {"epoch": 29, "valid_loss": "8.228", "valid_ppl": "299.76", "valid_wps": "67073.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1500", "valid_best_loss": "7.642"}
[2022-06-12 17:45:45,138][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 29 @ 1500 updates
[2022-06-12 17:45:45,139][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 17:45:49,323][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 17:45:49,385][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 29 @ 1500 updates, score 8.228) (writing took 4.24657965998631 seconds)
[2022-06-12 17:45:49,385][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2022-06-12 17:45:49,386][train][INFO] - {"epoch": 29, "train_loss": "7.642", "train_ppl": "199.79", "train_wps": "20929.4", "train_ups": "0.1", "train_wpb": "212935", "train_bsz": "503.5", "train_num_updates": "1500", "train_lr": "7.5e-05", "train_gnorm": "1.986", "train_loss_scale": "8", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "15483"}
[2022-06-12 17:45:49,403][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 17:45:49,408][fairseq.trainer][INFO] - begin training epoch 30
[2022-06-12 17:45:49,409][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 17:53:59,010][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 17:54:36,392][valid][INFO] - {"epoch": 30, "valid_loss": "7.497", "valid_ppl": "180.68", "valid_wps": "67159.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1552", "valid_best_loss": "7.497"}
[2022-06-12 17:54:36,394][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 1552 updates
[2022-06-12 17:54:36,395][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:54:40,697][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 17:54:43,886][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 30 @ 1552 updates, score 7.497) (writing took 7.492699944996275 seconds)
[2022-06-12 17:54:43,887][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2022-06-12 17:54:43,889][train][INFO] - {"epoch": 30, "train_loss": "7.665", "train_ppl": "202.9", "train_wps": "20709.4", "train_ups": "0.1", "train_wpb": "212869", "train_bsz": "503.5", "train_num_updates": "1552", "train_lr": "7.76e-05", "train_gnorm": "2.241", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "16017"}
[2022-06-12 17:54:43,906][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 17:54:43,909][fairseq.trainer][INFO] - begin training epoch 31
[2022-06-12 17:54:43,909][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 18:02:21,802][train_inner][INFO] - {"epoch": 31, "update": 30.923, "loss": "7.633", "ppl": "198.47", "wps": "21174.5", "ups": "0.1", "wpb": "213744", "bsz": "505.3", "num_updates": "1600", "lr": "8e-05", "gnorm": "2.067", "loss_scale": "8", "train_wall": "1870", "gb_free": "6.2", "wall": "16475"}
[2022-06-12 18:02:55,002][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 18:03:32,569][valid][INFO] - {"epoch": 31, "valid_loss": "7.615", "valid_ppl": "196.1", "valid_wps": "67388", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1604", "valid_best_loss": "7.497"}
[2022-06-12 18:03:32,570][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 31 @ 1604 updates
[2022-06-12 18:03:32,571][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:03:36,915][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:03:37,010][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 31 @ 1604 updates, score 7.615) (writing took 4.440124285058118 seconds)
[2022-06-12 18:03:37,011][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2022-06-12 18:03:37,013][train][INFO] - {"epoch": 31, "train_loss": "7.515", "train_ppl": "182.88", "train_wps": "20778.9", "train_ups": "0.1", "train_wpb": "213032", "train_bsz": "503.5", "train_num_updates": "1604", "train_lr": "8.02e-05", "train_gnorm": "2.312", "train_loss_scale": "16", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "16550"}
[2022-06-12 18:03:37,039][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 18:03:37,046][fairseq.trainer][INFO] - begin training epoch 32
[2022-06-12 18:03:37,048][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 18:03:47,328][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 18:11:47,393][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 18:12:24,988][valid][INFO] - {"epoch": 32, "valid_loss": "7.477", "valid_ppl": "178.1", "valid_wps": "67049.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1655", "valid_best_loss": "7.477"}
[2022-06-12 18:12:24,990][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 32 @ 1655 updates
[2022-06-12 18:12:24,992][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 18:12:29,215][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 18:12:32,441][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 32 @ 1655 updates, score 7.477) (writing took 7.4509994690306485 seconds)
[2022-06-12 18:12:32,442][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2022-06-12 18:12:32,445][train][INFO] - {"epoch": 32, "train_loss": "7.467", "train_ppl": "176.94", "train_wps": "20268.3", "train_ups": "0.1", "train_wpb": "212790", "train_bsz": "503.3", "train_num_updates": "1655", "train_lr": "8.275e-05", "train_gnorm": "2.43", "train_loss_scale": "8", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "17086"}
[2022-06-12 18:12:32,462][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 18:12:32,466][fairseq.trainer][INFO] - begin training epoch 33
[2022-06-12 18:12:32,466][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 18:20:42,171][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 18:21:19,510][valid][INFO] - {"epoch": 33, "valid_loss": "7.503", "valid_ppl": "181.44", "valid_wps": "67143.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1707", "valid_best_loss": "7.477"}
[2022-06-12 18:21:19,512][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 33 @ 1707 updates
[2022-06-12 18:21:19,513][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:21:23,786][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:21:23,873][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 33 @ 1707 updates, score 7.503) (writing took 4.361507960013114 seconds)
[2022-06-12 18:21:23,874][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2022-06-12 18:21:23,876][train][INFO] - {"epoch": 33, "train_loss": "7.389", "train_ppl": "167.63", "train_wps": "20826.7", "train_ups": "0.1", "train_wpb": "212844", "train_bsz": "503.5", "train_num_updates": "1707", "train_lr": "8.535e-05", "train_gnorm": "2.038", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "17617"}
[2022-06-12 18:21:23,889][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 18:21:23,892][fairseq.trainer][INFO] - begin training epoch 34
[2022-06-12 18:21:23,892][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 18:29:32,105][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 18:30:09,613][valid][INFO] - {"epoch": 34, "valid_loss": "8.502", "valid_ppl": "362.46", "valid_wps": "67338", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1759", "valid_best_loss": "7.477"}
[2022-06-12 18:30:09,615][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 34 @ 1759 updates
[2022-06-12 18:30:09,616][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:30:13,913][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:30:14,012][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 34 @ 1759 updates, score 8.502) (writing took 4.39746574300807 seconds)
[2022-06-12 18:30:14,013][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2022-06-12 18:30:14,015][train][INFO] - {"epoch": 34, "train_loss": "7.329", "train_ppl": "160.79", "train_wps": "20885.7", "train_ups": "0.1", "train_wpb": "212929", "train_bsz": "503.5", "train_num_updates": "1759", "train_lr": "8.795e-05", "train_gnorm": "2.272", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "18147"}
[2022-06-12 18:30:14,036][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 18:30:14,044][fairseq.trainer][INFO] - begin training epoch 35
[2022-06-12 18:30:14,045][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 18:36:42,683][train_inner][INFO] - {"epoch": 35, "update": 34.788, "loss": "7.419", "ppl": "171.17", "wps": "20655.5", "ups": "0.1", "wpb": "212843", "bsz": "503.1", "num_updates": "1800", "lr": "9e-05", "gnorm": "2.309", "loss_scale": "8", "train_wall": "1872", "gb_free": "6.2", "wall": "18536"}
[2022-06-12 18:38:22,301][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 18:38:59,628][valid][INFO] - {"epoch": 35, "valid_loss": "7.21", "valid_ppl": "148.1", "valid_wps": "67392.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1811", "valid_best_loss": "7.21"}
[2022-06-12 18:38:59,630][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 1811 updates
[2022-06-12 18:38:59,631][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 18:39:03,817][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 18:39:07,093][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 35 @ 1811 updates, score 7.21) (writing took 7.462957901065238 seconds)
[2022-06-12 18:39:07,093][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2022-06-12 18:39:07,095][train][INFO] - {"epoch": 35, "train_loss": "7.446", "train_ppl": "174.37", "train_wps": "20770.4", "train_ups": "0.1", "train_wpb": "212928", "train_bsz": "503.5", "train_num_updates": "1811", "train_lr": "9.055e-05", "train_gnorm": "2.224", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.1", "train_wall": "18680"}
[2022-06-12 18:39:07,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 18:39:07,128][fairseq.trainer][INFO] - begin training epoch 36
[2022-06-12 18:39:07,130][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 18:47:20,813][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 18:47:58,210][valid][INFO] - {"epoch": 36, "valid_loss": "7.188", "valid_ppl": "145.84", "valid_wps": "67320.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1863", "valid_best_loss": "7.188"}
[2022-06-12 18:47:58,212][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 36 @ 1863 updates
[2022-06-12 18:47:58,213][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 18:48:02,437][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 18:48:06,048][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 36 @ 1863 updates, score 7.188) (writing took 7.835701697040349 seconds)
[2022-06-12 18:48:06,048][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2022-06-12 18:48:06,050][train][INFO] - {"epoch": 36, "train_loss": "7.19", "train_ppl": "146.06", "train_wps": "20548.9", "train_ups": "0.1", "train_wpb": "212979", "train_bsz": "503.5", "train_num_updates": "1863", "train_lr": "9.315e-05", "train_gnorm": "1.997", "train_loss_scale": "16", "train_train_wall": "489", "train_gb_free": "6.2", "train_wall": "19219"}
[2022-06-12 18:48:06,066][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 18:48:06,069][fairseq.trainer][INFO] - begin training epoch 37
[2022-06-12 18:48:06,069][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 18:48:16,267][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 18:56:17,691][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 18:56:55,024][valid][INFO] - {"epoch": 37, "valid_loss": "7.71", "valid_ppl": "209.4", "valid_wps": "67255.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1914", "valid_best_loss": "7.188"}
[2022-06-12 18:56:55,025][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 37 @ 1914 updates
[2022-06-12 18:56:55,026][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:56:59,357][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 18:56:59,397][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 37 @ 1914 updates, score 7.71) (writing took 4.371770391939208 seconds)
[2022-06-12 18:56:59,397][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2022-06-12 18:56:59,398][train][INFO] - {"epoch": 37, "train_loss": "7.128", "train_ppl": "139.86", "train_wps": "20345.3", "train_ups": "0.1", "train_wpb": "212766", "train_bsz": "503.3", "train_num_updates": "1914", "train_lr": "9.57e-05", "train_gnorm": "2.084", "train_loss_scale": "8", "train_train_wall": "487", "train_gb_free": "6.1", "train_wall": "19753"}
[2022-06-12 18:56:59,408][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 18:56:59,411][fairseq.trainer][INFO] - begin training epoch 38
[2022-06-12 18:56:59,412][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 19:05:09,816][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 19:05:47,342][valid][INFO] - {"epoch": 38, "valid_loss": "6.934", "valid_ppl": "122.26", "valid_wps": "67244.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "1966", "valid_best_loss": "6.934"}
[2022-06-12 19:05:47,343][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 1966 updates
[2022-06-12 19:05:47,344][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 19:05:51,394][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 19:05:54,658][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 38 @ 1966 updates, score 6.934) (writing took 7.314848815090954 seconds)
[2022-06-12 19:05:54,659][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2022-06-12 19:05:54,661][train][INFO] - {"epoch": 38, "train_loss": "7.137", "train_ppl": "140.72", "train_wps": "20679.6", "train_ups": "0.1", "train_wpb": "212865", "train_bsz": "503.5", "train_num_updates": "1966", "train_lr": "9.83e-05", "train_gnorm": "2.065", "train_loss_scale": "8", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "20288"}
[2022-06-12 19:05:54,688][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 19:05:54,700][fairseq.trainer][INFO] - begin training epoch 39
[2022-06-12 19:05:54,701][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 19:11:16,427][train_inner][INFO] - {"epoch": 39, "update": 38.654, "loss": "7.129", "ppl": "139.99", "wps": "20504.3", "ups": "0.1", "wpb": "212604", "bsz": "503.1", "num_updates": "2000", "lr": "0.0001", "gnorm": "1.985", "loss_scale": "8", "train_wall": "1879", "gb_free": "6.2", "wall": "20610"}
[2022-06-12 19:14:02,922][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 19:14:40,595][valid][INFO] - {"epoch": 39, "valid_loss": "7.238", "valid_ppl": "151", "valid_wps": "67406.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2018", "valid_best_loss": "6.934"}
[2022-06-12 19:14:40,596][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 39 @ 2018 updates
[2022-06-12 19:14:40,597][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:14:44,615][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:14:44,663][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 39 @ 2018 updates, score 7.238) (writing took 4.0664615699788556 seconds)
[2022-06-12 19:14:44,663][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2022-06-12 19:14:44,664][train][INFO] - {"epoch": 39, "train_loss": "6.971", "train_ppl": "125.43", "train_wps": "20880.3", "train_ups": "0.1", "train_wpb": "212819", "train_bsz": "503.5", "train_num_updates": "2018", "train_lr": "0.0001009", "train_gnorm": "1.78", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "20818"}
[2022-06-12 19:14:44,675][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 19:14:44,678][fairseq.trainer][INFO] - begin training epoch 40
[2022-06-12 19:14:44,678][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 19:22:53,144][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 19:23:30,645][valid][INFO] - {"epoch": 40, "valid_loss": "6.94", "valid_ppl": "122.79", "valid_wps": "67368.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2070", "valid_best_loss": "6.934"}
[2022-06-12 19:23:30,647][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 2070 updates
[2022-06-12 19:23:30,648][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:23:34,877][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:23:34,927][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 40 @ 2070 updates, score 6.94) (writing took 4.279856776003726 seconds)
[2022-06-12 19:23:34,927][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2022-06-12 19:23:34,928][train][INFO] - {"epoch": 40, "train_loss": "6.921", "train_ppl": "121.17", "train_wps": "20881.7", "train_ups": "0.1", "train_wpb": "212939", "train_bsz": "503.5", "train_num_updates": "2070", "train_lr": "0.0001035", "train_gnorm": "1.959", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "21348"}
[2022-06-12 19:23:34,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 19:23:34,943][fairseq.trainer][INFO] - begin training epoch 41
[2022-06-12 19:23:34,943][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 19:31:44,949][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 19:32:22,524][valid][INFO] - {"epoch": 41, "valid_loss": "7.043", "valid_ppl": "131.85", "valid_wps": "67450.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2122", "valid_best_loss": "6.934"}
[2022-06-12 19:32:22,526][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 41 @ 2122 updates
[2022-06-12 19:32:22,527][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:32:27,022][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:32:27,080][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 41 @ 2122 updates, score 7.043) (writing took 4.553863805951551 seconds)
[2022-06-12 19:32:27,080][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2022-06-12 19:32:27,082][train][INFO] - {"epoch": 41, "train_loss": "6.813", "train_ppl": "112.47", "train_wps": "20810.9", "train_ups": "0.1", "train_wpb": "212972", "train_bsz": "503.5", "train_num_updates": "2122", "train_lr": "0.0001061", "train_gnorm": "2.111", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "21880"}
[2022-06-12 19:32:27,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 19:32:27,096][fairseq.trainer][INFO] - begin training epoch 42
[2022-06-12 19:32:27,097][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 19:32:35,997][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 19:40:33,705][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 19:41:11,134][valid][INFO] - {"epoch": 42, "valid_loss": "6.71", "valid_ppl": "104.7", "valid_wps": "67134.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2173", "valid_best_loss": "6.71"}
[2022-06-12 19:41:11,135][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 42 @ 2173 updates
[2022-06-12 19:41:11,136][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 19:41:15,445][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 19:41:18,980][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 42 @ 2173 updates, score 6.71) (writing took 7.845080756000243 seconds)
[2022-06-12 19:41:18,981][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2022-06-12 19:41:18,981][train][INFO] - {"epoch": 42, "train_loss": "6.737", "train_ppl": "106.64", "train_wps": "20412.1", "train_ups": "0.1", "train_wpb": "212886", "train_bsz": "503.3", "train_num_updates": "2173", "train_lr": "0.00010865", "train_gnorm": "1.806", "train_loss_scale": "8", "train_train_wall": "482", "train_gb_free": "6.3", "train_wall": "22412"}
[2022-06-12 19:41:18,993][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 19:41:18,996][fairseq.trainer][INFO] - begin training epoch 43
[2022-06-12 19:41:18,997][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 19:45:34,062][train_inner][INFO] - {"epoch": 43, "update": 42.519, "loss": "6.814", "ppl": "112.55", "wps": "20694.2", "ups": "0.1", "wpb": "212905", "bsz": "503.1", "num_updates": "2200", "lr": "0.00011", "gnorm": "1.953", "loss_scale": "8", "train_wall": "1869", "gb_free": "6.2", "wall": "22667"}
[2022-06-12 19:49:26,523][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 19:50:03,934][valid][INFO] - {"epoch": 43, "valid_loss": "6.46", "valid_ppl": "88.04", "valid_wps": "67190.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2225", "valid_best_loss": "6.46"}
[2022-06-12 19:50:03,936][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 43 @ 2225 updates
[2022-06-12 19:50:03,937][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 19:50:08,272][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 19:50:11,812][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 43 @ 2225 updates, score 6.46) (writing took 7.875516484025866 seconds)
[2022-06-12 19:50:11,812][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2022-06-12 19:50:11,814][train][INFO] - {"epoch": 43, "train_loss": "6.61", "train_ppl": "97.71", "train_wps": "20780.1", "train_ups": "0.1", "train_wpb": "212928", "train_bsz": "503.5", "train_num_updates": "2225", "train_lr": "0.00011125", "train_gnorm": "1.695", "train_loss_scale": "8", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "22945"}
[2022-06-12 19:50:11,830][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 19:50:11,833][fairseq.trainer][INFO] - begin training epoch 44
[2022-06-12 19:50:11,833][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 19:58:20,450][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 19:58:58,136][valid][INFO] - {"epoch": 44, "valid_loss": "6.541", "valid_ppl": "93.14", "valid_wps": "67213.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2277", "valid_best_loss": "6.46"}
[2022-06-12 19:58:58,137][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 44 @ 2277 updates
[2022-06-12 19:58:58,138][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:59:02,244][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 19:59:02,291][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 44 @ 2277 updates, score 6.541) (writing took 4.153899240074679 seconds)
[2022-06-12 19:59:02,292][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2022-06-12 19:59:02,293][train][INFO] - {"epoch": 44, "train_loss": "6.471", "train_ppl": "88.71", "train_wps": "20872.8", "train_ups": "0.1", "train_wpb": "212934", "train_bsz": "503.5", "train_num_updates": "2277", "train_lr": "0.00011385", "train_gnorm": "1.782", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "23476"}
[2022-06-12 19:59:02,303][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 19:59:02,306][fairseq.trainer][INFO] - begin training epoch 45
[2022-06-12 19:59:02,307][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 20:07:11,753][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 20:07:49,228][valid][INFO] - {"epoch": 45, "valid_loss": "6.307", "valid_ppl": "79.19", "valid_wps": "67197", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2329", "valid_best_loss": "6.307"}
[2022-06-12 20:07:49,229][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 2329 updates
[2022-06-12 20:07:49,230][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:07:53,552][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:07:56,914][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 45 @ 2329 updates, score 6.307) (writing took 7.684277047985233 seconds)
[2022-06-12 20:07:56,914][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2022-06-12 20:07:56,915][train][INFO] - {"epoch": 45, "train_loss": "6.363", "train_ppl": "82.3", "train_wps": "20695.3", "train_ups": "0.1", "train_wpb": "212772", "train_bsz": "503.5", "train_num_updates": "2329", "train_lr": "0.00011645", "train_gnorm": "1.642", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.1", "train_wall": "24010"}
[2022-06-12 20:07:56,926][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 20:07:56,929][fairseq.trainer][INFO] - begin training epoch 46
[2022-06-12 20:07:56,930][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 20:16:04,797][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 20:16:42,386][valid][INFO] - {"epoch": 46, "valid_loss": "6.068", "valid_ppl": "67.09", "valid_wps": "66973.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2381", "valid_best_loss": "6.068"}
[2022-06-12 20:16:42,388][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 46 @ 2381 updates
[2022-06-12 20:16:42,389][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:16:46,754][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:16:49,993][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 46 @ 2381 updates, score 6.068) (writing took 7.6054589920677245 seconds)
[2022-06-12 20:16:49,994][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2022-06-12 20:16:49,994][train][INFO] - {"epoch": 46, "train_loss": "6.194", "train_ppl": "73.2", "train_wps": "20751.1", "train_ups": "0.1", "train_wpb": "212731", "train_bsz": "503.5", "train_num_updates": "2381", "train_lr": "0.00011905", "train_gnorm": "1.699", "train_loss_scale": "16", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "24543"}
[2022-06-12 20:16:50,006][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 20:16:50,010][fairseq.trainer][INFO] - begin training epoch 47
[2022-06-12 20:16:50,010][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 20:19:48,418][train_inner][INFO] - {"epoch": 47, "update": 46.365, "loss": "6.346", "ppl": "81.33", "wps": "20688.8", "ups": "0.1", "wpb": "212511", "bsz": "503.1", "num_updates": "2400", "lr": "0.00012", "gnorm": "1.677", "loss_scale": "16", "train_wall": "1859", "gb_free": "6.2", "wall": "24722"}
[2022-06-12 20:24:58,427][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 20:25:36,018][valid][INFO] - {"epoch": 47, "valid_loss": "5.729", "valid_ppl": "53.02", "valid_wps": "67133.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2433", "valid_best_loss": "5.729"}
[2022-06-12 20:25:36,020][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 47 @ 2433 updates
[2022-06-12 20:25:36,021][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:25:40,322][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:25:44,087][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 47 @ 2433 updates, score 5.729) (writing took 8.06672093004454 seconds)
[2022-06-12 20:25:44,087][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2022-06-12 20:25:44,089][train][INFO] - {"epoch": 47, "train_loss": "6.019", "train_ppl": "64.86", "train_wps": "20734.4", "train_ups": "0.1", "train_wpb": "212964", "train_bsz": "503.5", "train_num_updates": "2433", "train_lr": "0.00012165", "train_gnorm": "1.448", "train_loss_scale": "16", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "25077"}
[2022-06-12 20:25:44,110][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 20:25:44,118][fairseq.trainer][INFO] - begin training epoch 48
[2022-06-12 20:25:44,119][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 20:33:53,280][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 20:34:30,902][valid][INFO] - {"epoch": 48, "valid_loss": "5.693", "valid_ppl": "51.74", "valid_wps": "66874.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2485", "valid_best_loss": "5.693"}
[2022-06-12 20:34:30,904][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 48 @ 2485 updates
[2022-06-12 20:34:30,905][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:34:35,138][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:34:38,399][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 48 @ 2485 updates, score 5.693) (writing took 7.495447602937929 seconds)
[2022-06-12 20:34:38,400][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2022-06-12 20:34:38,402][train][INFO] - {"epoch": 48, "train_loss": "5.818", "train_ppl": "56.41", "train_wps": "20720.8", "train_ups": "0.1", "train_wpb": "212911", "train_bsz": "503.5", "train_num_updates": "2485", "train_lr": "0.00012425", "train_gnorm": "1.385", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.3", "train_wall": "25612"}
[2022-06-12 20:34:38,432][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 20:34:38,440][fairseq.trainer][INFO] - begin training epoch 49
[2022-06-12 20:34:38,442][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 20:42:47,822][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 20:43:25,603][valid][INFO] - {"epoch": 49, "valid_loss": "5.638", "valid_ppl": "49.79", "valid_wps": "67019.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2537", "valid_best_loss": "5.638"}
[2022-06-12 20:43:25,605][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 49 @ 2537 updates
[2022-06-12 20:43:25,605][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:43:29,828][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:43:33,335][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 49 @ 2537 updates, score 5.638) (writing took 7.730057562002912 seconds)
[2022-06-12 20:43:33,335][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2022-06-12 20:43:33,337][train][INFO] - {"epoch": 49, "train_loss": "5.706", "train_ppl": "52.19", "train_wps": "20691.4", "train_ups": "0.1", "train_wpb": "212856", "train_bsz": "503.5", "train_num_updates": "2537", "train_lr": "0.00012685", "train_gnorm": "1.55", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "26147"}
[2022-06-12 20:43:33,369][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 20:43:33,377][fairseq.trainer][INFO] - begin training epoch 50
[2022-06-12 20:43:33,378][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 20:43:42,544][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 20:51:46,230][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 20:52:23,908][valid][INFO] - {"epoch": 50, "valid_loss": "5.377", "valid_ppl": "41.56", "valid_wps": "66752.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2588", "valid_best_loss": "5.377"}
[2022-06-12 20:52:23,909][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 2588 updates
[2022-06-12 20:52:23,910][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:52:28,040][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 20:52:31,955][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 50 @ 2588 updates, score 5.377) (writing took 8.045668798033148 seconds)
[2022-06-12 20:52:31,956][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2022-06-12 20:52:31,957][train][INFO] - {"epoch": 50, "train_loss": "5.574", "train_ppl": "47.64", "train_wps": "20166.6", "train_ups": "0.09", "train_wpb": "212983", "train_bsz": "503.3", "train_num_updates": "2588", "train_lr": "0.0001294", "train_gnorm": "1.742", "train_loss_scale": "8", "train_train_wall": "488", "train_gb_free": "6.1", "train_wall": "26685"}
[2022-06-12 20:52:31,985][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 20:52:31,993][fairseq.trainer][INFO] - begin training epoch 51
[2022-06-12 20:52:31,994][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 20:54:25,163][train_inner][INFO] - {"epoch": 51, "update": 50.231, "loss": "5.731", "ppl": "53.13", "wps": "20489.2", "ups": "0.1", "wpb": "212754", "bsz": "503.1", "num_updates": "2600", "lr": "0.00013", "gnorm": "1.514", "loss_scale": "8", "train_wall": "1876", "gb_free": "6.2", "wall": "26799"}
[2022-06-12 21:00:42,553][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 21:01:20,127][valid][INFO] - {"epoch": 51, "valid_loss": "5.312", "valid_ppl": "39.73", "valid_wps": "66922", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2640", "valid_best_loss": "5.312"}
[2022-06-12 21:01:20,129][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 51 @ 2640 updates
[2022-06-12 21:01:20,130][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:01:24,472][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:01:28,212][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 51 @ 2640 updates, score 5.312) (writing took 8.08357977308333 seconds)
[2022-06-12 21:01:28,213][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2022-06-12 21:01:28,215][train][INFO] - {"epoch": 51, "train_loss": "5.448", "train_ppl": "43.66", "train_wps": "20640", "train_ups": "0.1", "train_wpb": "212852", "train_bsz": "503.5", "train_num_updates": "2640", "train_lr": "0.000132", "train_gnorm": "1.428", "train_loss_scale": "8", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "27222"}
[2022-06-12 21:01:28,242][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 21:01:28,251][fairseq.trainer][INFO] - begin training epoch 52
[2022-06-12 21:01:28,252][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 21:09:38,150][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 21:10:15,815][valid][INFO] - {"epoch": 52, "valid_loss": "5.184", "valid_ppl": "36.35", "valid_wps": "66748.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2692", "valid_best_loss": "5.184"}
[2022-06-12 21:10:15,816][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 52 @ 2692 updates
[2022-06-12 21:10:15,817][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:10:19,905][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:10:23,650][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 52 @ 2692 updates, score 5.184) (writing took 7.833612950053066 seconds)
[2022-06-12 21:10:23,651][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2022-06-12 21:10:23,652][train][INFO] - {"epoch": 52, "train_loss": "5.357", "train_ppl": "40.99", "train_wps": "20681.2", "train_ups": "0.1", "train_wpb": "212951", "train_bsz": "503.5", "train_num_updates": "2692", "train_lr": "0.0001346", "train_gnorm": "1.571", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.1", "train_wall": "27757"}
[2022-06-12 21:10:23,676][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 21:10:23,685][fairseq.trainer][INFO] - begin training epoch 53
[2022-06-12 21:10:23,686][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 21:18:33,951][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 21:19:11,454][valid][INFO] - {"epoch": 53, "valid_loss": "5.159", "valid_ppl": "35.72", "valid_wps": "66984.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2744", "valid_best_loss": "5.159"}
[2022-06-12 21:19:11,456][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 53 @ 2744 updates
[2022-06-12 21:19:11,457][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:19:15,542][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:19:19,137][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 53 @ 2744 updates, score 5.159) (writing took 7.6811098490143195 seconds)
[2022-06-12 21:19:19,137][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2022-06-12 21:19:19,138][train][INFO] - {"epoch": 53, "train_loss": "5.259", "train_ppl": "38.29", "train_wps": "20676.8", "train_ups": "0.1", "train_wpb": "212925", "train_bsz": "503.5", "train_num_updates": "2744", "train_lr": "0.0001372", "train_gnorm": "1.322", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "28293"}
[2022-06-12 21:19:19,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 21:19:19,153][fairseq.trainer][INFO] - begin training epoch 54
[2022-06-12 21:19:19,154][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 21:27:23,851][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 21:28:01,739][valid][INFO] - {"epoch": 54, "valid_loss": "5.089", "valid_ppl": "34.04", "valid_wps": "66950.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2796", "valid_best_loss": "5.089"}
[2022-06-12 21:28:01,741][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 54 @ 2796 updates
[2022-06-12 21:28:01,742][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:28:05,883][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:28:09,198][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 54 @ 2796 updates, score 5.089) (writing took 7.457136948942207 seconds)
[2022-06-12 21:28:09,199][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2022-06-12 21:28:09,200][train][INFO] - {"epoch": 54, "train_loss": "5.176", "train_ppl": "36.14", "train_wps": "20880.3", "train_ups": "0.1", "train_wpb": "212843", "train_bsz": "503.5", "train_num_updates": "2796", "train_lr": "0.0001398", "train_gnorm": "1.408", "train_loss_scale": "16", "train_train_wall": "480", "train_gb_free": "6.2", "train_wall": "28823"}
[2022-06-12 21:28:09,231][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 21:28:09,240][fairseq.trainer][INFO] - begin training epoch 55
[2022-06-12 21:28:09,241][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 21:28:19,279][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2022-06-12 21:28:56,488][train_inner][INFO] - {"epoch": 55, "update": 54.096, "loss": "5.293", "ppl": "39.2", "wps": "20550.8", "ups": "0.1", "wpb": "212837", "bsz": "503.1", "num_updates": "2800", "lr": "0.00014", "gnorm": "1.44", "loss_scale": "8", "train_wall": "1872", "gb_free": "6.2", "wall": "28870"}
[2022-06-12 21:36:19,226][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 21:36:56,629][valid][INFO] - {"epoch": 55, "valid_loss": "5.058", "valid_ppl": "33.31", "valid_wps": "67195.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2847", "valid_best_loss": "5.058"}
[2022-06-12 21:36:56,631][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 2847 updates
[2022-06-12 21:36:56,632][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:37:00,850][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:37:04,198][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 55 @ 2847 updates, score 5.058) (writing took 7.566829506889917 seconds)
[2022-06-12 21:37:04,198][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2022-06-12 21:37:04,199][train][INFO] - {"epoch": 55, "train_loss": "5.092", "train_ppl": "34.12", "train_wps": "20299.3", "train_ups": "0.1", "train_wpb": "212943", "train_bsz": "503.3", "train_num_updates": "2847", "train_lr": "0.00014235", "train_gnorm": "1.474", "train_loss_scale": "8", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "29358"}
[2022-06-12 21:37:04,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 21:37:04,217][fairseq.trainer][INFO] - begin training epoch 56
[2022-06-12 21:37:04,217][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 21:45:15,800][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 21:45:53,542][valid][INFO] - {"epoch": 56, "valid_loss": "4.906", "valid_ppl": "29.97", "valid_wps": "67147.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2899", "valid_best_loss": "4.906"}
[2022-06-12 21:45:53,544][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 56 @ 2899 updates
[2022-06-12 21:45:53,544][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:45:57,838][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:46:01,519][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 56 @ 2899 updates, score 4.906) (writing took 7.975602405960672 seconds)
[2022-06-12 21:46:01,520][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2022-06-12 21:46:01,521][train][INFO] - {"epoch": 56, "train_loss": "5.005", "train_ppl": "32.11", "train_wps": "20597.9", "train_ups": "0.1", "train_wpb": "212840", "train_bsz": "503.5", "train_num_updates": "2899", "train_lr": "0.00014495", "train_gnorm": "1.466", "train_loss_scale": "8", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "29895"}
[2022-06-12 21:46:01,550][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 21:46:01,559][fairseq.trainer][INFO] - begin training epoch 57
[2022-06-12 21:46:01,560][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 21:54:08,870][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 21:54:46,689][valid][INFO] - {"epoch": 57, "valid_loss": "4.773", "valid_ppl": "27.34", "valid_wps": "66953.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "2951", "valid_best_loss": "4.773"}
[2022-06-12 21:54:46,690][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 57 @ 2951 updates
[2022-06-12 21:54:46,691][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:54:50,875][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 21:54:54,421][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 57 @ 2951 updates, score 4.773) (writing took 7.731049590976909 seconds)
[2022-06-12 21:54:54,422][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2022-06-12 21:54:54,423][train][INFO] - {"epoch": 57, "train_loss": "4.913", "train_ppl": "30.13", "train_wps": "20760.7", "train_ups": "0.1", "train_wpb": "212757", "train_bsz": "503.5", "train_num_updates": "2951", "train_lr": "0.00014755", "train_gnorm": "1.385", "train_loss_scale": "8", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "30428"}
[2022-06-12 21:54:54,434][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 21:54:54,437][fairseq.trainer][INFO] - begin training epoch 58
[2022-06-12 21:54:54,437][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 22:02:39,326][train_inner][INFO] - {"epoch": 58, "update": 57.942, "loss": "4.959", "ppl": "31.11", "wps": "21132.6", "ups": "0.1", "wpb": "213739", "bsz": "505.3", "num_updates": "3000", "lr": "0.00015", "gnorm": "1.308", "loss_scale": "8", "train_wall": "1870", "gb_free": "6.2", "wall": "30893"}
[2022-06-12 22:03:02,866][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 22:03:40,729][valid][INFO] - {"epoch": 58, "valid_loss": "4.684", "valid_ppl": "25.7", "valid_wps": "67055.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3003", "valid_best_loss": "4.684"}
[2022-06-12 22:03:40,730][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 58 @ 3003 updates
[2022-06-12 22:03:40,731][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:03:44,820][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:03:48,205][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 58 @ 3003 updates, score 4.684) (writing took 7.474980316008441 seconds)
[2022-06-12 22:03:48,206][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2022-06-12 22:03:48,208][train][INFO] - {"epoch": 58, "train_loss": "4.843", "train_ppl": "28.71", "train_wps": "20738.8", "train_ups": "0.1", "train_wpb": "212886", "train_bsz": "503.5", "train_num_updates": "3003", "train_lr": "0.00015015", "train_gnorm": "1.131", "train_loss_scale": "8", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "30962"}
[2022-06-12 22:03:48,235][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 22:03:48,244][fairseq.trainer][INFO] - begin training epoch 59
[2022-06-12 22:03:48,245][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 22:11:58,861][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 22:12:36,525][valid][INFO] - {"epoch": 59, "valid_loss": "4.536", "valid_ppl": "23.21", "valid_wps": "67250.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3055", "valid_best_loss": "4.536"}
[2022-06-12 22:12:36,526][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 59 @ 3055 updates
[2022-06-12 22:12:36,527][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:12:40,726][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:12:44,071][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 59 @ 3055 updates, score 4.536) (writing took 7.544217937975191 seconds)
[2022-06-12 22:12:44,071][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2022-06-12 22:12:44,073][train][INFO] - {"epoch": 59, "train_loss": "4.75", "train_ppl": "26.9", "train_wps": "20665.3", "train_ups": "0.1", "train_wpb": "212958", "train_bsz": "503.5", "train_num_updates": "3055", "train_lr": "0.00015275", "train_gnorm": "1.127", "train_loss_scale": "16", "train_train_wall": "486", "train_gb_free": "6.3", "train_wall": "31497"}
[2022-06-12 22:12:44,091][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 22:12:44,094][fairseq.trainer][INFO] - begin training epoch 60
[2022-06-12 22:12:44,095][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 22:20:53,938][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 22:21:31,596][valid][INFO] - {"epoch": 60, "valid_loss": "4.547", "valid_ppl": "23.38", "valid_wps": "66618.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3107", "valid_best_loss": "4.536"}
[2022-06-12 22:21:31,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 3107 updates
[2022-06-12 22:21:31,599][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 22:21:35,826][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-12 22:21:35,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 60 @ 3107 updates, score 4.547) (writing took 4.317835627007298 seconds)
[2022-06-12 22:21:35,916][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2022-06-12 22:21:35,918][train][INFO] - {"epoch": 60, "train_loss": "4.623", "train_ppl": "24.64", "train_wps": "20802.3", "train_ups": "0.1", "train_wpb": "212761", "train_bsz": "503.5", "train_num_updates": "3107", "train_lr": "0.00015535", "train_gnorm": "1.078", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "32029"}
[2022-06-12 22:21:35,941][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 22:21:35,948][fairseq.trainer][INFO] - begin training epoch 61
[2022-06-12 22:21:35,949][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 22:29:45,753][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 22:30:23,342][valid][INFO] - {"epoch": 61, "valid_loss": "4.338", "valid_ppl": "20.22", "valid_wps": "67104.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3159", "valid_best_loss": "4.338"}
[2022-06-12 22:30:23,344][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 61 @ 3159 updates
[2022-06-12 22:30:23,345][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:30:27,604][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:30:31,207][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 61 @ 3159 updates, score 4.338) (writing took 7.8632356899324805 seconds)
[2022-06-12 22:30:31,208][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2022-06-12 22:30:31,210][train][INFO] - {"epoch": 61, "train_loss": "4.508", "train_ppl": "22.75", "train_wps": "20681.1", "train_ups": "0.1", "train_wpb": "212892", "train_bsz": "503.5", "train_num_updates": "3159", "train_lr": "0.00015795", "train_gnorm": "1.123", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "32565"}
[2022-06-12 22:30:31,239][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 22:30:31,248][fairseq.trainer][INFO] - begin training epoch 62
[2022-06-12 22:30:31,249][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 22:36:58,124][train_inner][INFO] - {"epoch": 62, "update": 61.788, "loss": "4.583", "ppl": "23.98", "wps": "20644.3", "ups": "0.1", "wpb": "212512", "bsz": "503.1", "num_updates": "3200", "lr": "0.00016", "gnorm": "1.098", "loss_scale": "16", "train_wall": "1863", "gb_free": "6.2", "wall": "32952"}
[2022-06-12 22:38:39,573][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 22:39:17,206][valid][INFO] - {"epoch": 62, "valid_loss": "4.272", "valid_ppl": "19.31", "valid_wps": "67065.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3211", "valid_best_loss": "4.272"}
[2022-06-12 22:39:17,207][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 62 @ 3211 updates
[2022-06-12 22:39:17,208][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:39:21,377][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:39:24,870][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 62 @ 3211 updates, score 4.272) (writing took 7.663059656973928 seconds)
[2022-06-12 22:39:24,871][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2022-06-12 22:39:24,873][train][INFO] - {"epoch": 62, "train_loss": "4.397", "train_ppl": "21.07", "train_wps": "20741.5", "train_ups": "0.1", "train_wpb": "212865", "train_bsz": "503.5", "train_num_updates": "3211", "train_lr": "0.00016055", "train_gnorm": "1.009", "train_loss_scale": "16", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "33098"}
[2022-06-12 22:39:24,890][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 22:39:24,894][fairseq.trainer][INFO] - begin training epoch 63
[2022-06-12 22:39:24,894][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 22:47:34,767][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 22:48:12,639][valid][INFO] - {"epoch": 63, "valid_loss": "4.15", "valid_ppl": "17.75", "valid_wps": "66484.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3263", "valid_best_loss": "4.15"}
[2022-06-12 22:48:12,641][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 63 @ 3263 updates
[2022-06-12 22:48:12,642][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:48:16,689][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:48:20,284][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 63 @ 3263 updates, score 4.15) (writing took 7.642646482097916 seconds)
[2022-06-12 22:48:20,284][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2022-06-12 22:48:20,286][train][INFO] - {"epoch": 63, "train_loss": "4.298", "train_ppl": "19.68", "train_wps": "20683.3", "train_ups": "0.1", "train_wpb": "212963", "train_bsz": "503.5", "train_num_updates": "3263", "train_lr": "0.00016315", "train_gnorm": "0.898", "train_loss_scale": "16", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "33634"}
[2022-06-12 22:48:20,302][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 22:48:20,306][fairseq.trainer][INFO] - begin training epoch 64
[2022-06-12 22:48:20,306][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 22:56:30,175][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 22:57:07,716][valid][INFO] - {"epoch": 64, "valid_loss": "4.089", "valid_ppl": "17.01", "valid_wps": "66928", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3315", "valid_best_loss": "4.089"}
[2022-06-12 22:57:07,718][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 64 @ 3315 updates
[2022-06-12 22:57:07,719][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:57:11,800][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 22:57:15,094][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 64 @ 3315 updates, score 4.089) (writing took 7.376098917913623 seconds)
[2022-06-12 22:57:15,095][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2022-06-12 22:57:15,096][train][INFO] - {"epoch": 64, "train_loss": "4.199", "train_ppl": "18.37", "train_wps": "20708", "train_ups": "0.1", "train_wpb": "212977", "train_bsz": "503.5", "train_num_updates": "3315", "train_lr": "0.00016575", "train_gnorm": "0.839", "train_loss_scale": "32", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "34168"}
[2022-06-12 22:57:15,124][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 22:57:15,132][fairseq.trainer][INFO] - begin training epoch 65
[2022-06-12 22:57:15,133][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 23:05:22,358][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 23:06:00,135][valid][INFO] - {"epoch": 65, "valid_loss": "3.964", "valid_ppl": "15.61", "valid_wps": "67236.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3367", "valid_best_loss": "3.964"}
[2022-06-12 23:06:00,136][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 3367 updates
[2022-06-12 23:06:00,137][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:06:04,235][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:06:07,477][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 65 @ 3367 updates, score 3.964) (writing took 7.340597981936298 seconds)
[2022-06-12 23:06:07,478][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2022-06-12 23:06:07,479][train][INFO] - {"epoch": 65, "train_loss": "4.117", "train_ppl": "17.35", "train_wps": "20800.5", "train_ups": "0.1", "train_wpb": "212958", "train_bsz": "503.5", "train_num_updates": "3367", "train_lr": "0.00016835", "train_gnorm": "0.812", "train_loss_scale": "32", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "34701"}
[2022-06-12 23:06:07,507][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 23:06:07,515][fairseq.trainer][INFO] - begin training epoch 66
[2022-06-12 23:06:07,517][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 23:11:20,747][train_inner][INFO] - {"epoch": 66, "update": 65.635, "loss": "4.186", "ppl": "18.2", "wps": "20643.5", "ups": "0.1", "wpb": "212899", "bsz": "503.1", "num_updates": "3400", "lr": "0.00017", "gnorm": "0.853", "loss_scale": "32", "train_wall": "1864", "gb_free": "6.2", "wall": "35014"}
[2022-06-12 23:14:16,066][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 23:14:53,640][valid][INFO] - {"epoch": 66, "valid_loss": "3.907", "valid_ppl": "15", "valid_wps": "67036.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3419", "valid_best_loss": "3.907"}
[2022-06-12 23:14:53,642][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 66 @ 3419 updates
[2022-06-12 23:14:53,643][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:14:57,805][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:15:01,566][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 66 @ 3419 updates, score 3.907) (writing took 7.9236703659407794 seconds)
[2022-06-12 23:15:01,567][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2022-06-12 23:15:01,569][train][INFO] - {"epoch": 66, "train_loss": "4.038", "train_ppl": "16.43", "train_wps": "20733.3", "train_ups": "0.1", "train_wpb": "212950", "train_bsz": "503.5", "train_num_updates": "3419", "train_lr": "0.00017095", "train_gnorm": "0.782", "train_loss_scale": "32", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "35235"}
[2022-06-12 23:15:01,601][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 23:15:01,610][fairseq.trainer][INFO] - begin training epoch 67
[2022-06-12 23:15:01,611][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 23:23:15,394][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 23:23:53,143][valid][INFO] - {"epoch": 67, "valid_loss": "3.861", "valid_ppl": "14.53", "valid_wps": "66848.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3471", "valid_best_loss": "3.861"}
[2022-06-12 23:23:53,145][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 67 @ 3471 updates
[2022-06-12 23:23:53,145][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:23:57,365][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:24:00,772][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 67 @ 3471 updates, score 3.861) (writing took 7.62724215106573 seconds)
[2022-06-12 23:24:00,772][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2022-06-12 23:24:00,773][train][INFO] - {"epoch": 67, "train_loss": "3.963", "train_ppl": "15.59", "train_wps": "20529.3", "train_ups": "0.1", "train_wpb": "212875", "train_bsz": "503.5", "train_num_updates": "3471", "train_lr": "0.00017355", "train_gnorm": "0.736", "train_loss_scale": "32", "train_train_wall": "489", "train_gb_free": "6.2", "train_wall": "35774"}
[2022-06-12 23:24:00,784][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 23:24:00,788][fairseq.trainer][INFO] - begin training epoch 68
[2022-06-12 23:24:00,788][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 23:32:12,457][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 23:32:49,956][valid][INFO] - {"epoch": 68, "valid_loss": "3.78", "valid_ppl": "13.74", "valid_wps": "67065.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3523", "valid_best_loss": "3.78"}
[2022-06-12 23:32:49,957][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 68 @ 3523 updates
[2022-06-12 23:32:49,958][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:32:54,840][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:32:58,205][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 68 @ 3523 updates, score 3.78) (writing took 8.247763909981586 seconds)
[2022-06-12 23:32:58,206][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2022-06-12 23:32:58,212][train][INFO] - {"epoch": 68, "train_loss": "3.897", "train_ppl": "14.89", "train_wps": "20599.2", "train_ups": "0.1", "train_wpb": "212899", "train_bsz": "503.5", "train_num_updates": "3523", "train_lr": "0.00017615", "train_gnorm": "0.722", "train_loss_scale": "32", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "36312"}
[2022-06-12 23:32:58,228][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 23:32:58,232][fairseq.trainer][INFO] - begin training epoch 69
[2022-06-12 23:32:58,232][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 23:41:03,084][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 23:41:40,767][valid][INFO] - {"epoch": 69, "valid_loss": "3.75", "valid_ppl": "13.45", "valid_wps": "67227.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3575", "valid_best_loss": "3.75"}
[2022-06-12 23:41:40,769][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 3575 updates
[2022-06-12 23:41:40,770][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:41:44,776][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:41:48,046][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 69 @ 3575 updates, score 3.75) (writing took 7.277650673990138 seconds)
[2022-06-12 23:41:48,047][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2022-06-12 23:41:48,049][train][INFO] - {"epoch": 69, "train_loss": "3.821", "train_ppl": "14.14", "train_wps": "20887.7", "train_ups": "0.1", "train_wpb": "212828", "train_bsz": "503.5", "train_num_updates": "3575", "train_lr": "0.00017875", "train_gnorm": "0.698", "train_loss_scale": "64", "train_train_wall": "480", "train_gb_free": "6.2", "train_wall": "36841"}
[2022-06-12 23:41:48,081][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 23:41:48,090][fairseq.trainer][INFO] - begin training epoch 70
[2022-06-12 23:41:48,091][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 23:45:43,473][train_inner][INFO] - {"epoch": 70, "update": 69.481, "loss": "3.895", "ppl": "14.88", "wps": "20623.9", "ups": "0.1", "wpb": "212707", "bsz": "503.1", "num_updates": "3600", "lr": "0.00018", "gnorm": "0.72", "loss_scale": "64", "train_wall": "1863", "gb_free": "6.1", "wall": "37077"}
[2022-06-12 23:49:55,581][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 23:50:33,097][valid][INFO] - {"epoch": 70, "valid_loss": "3.679", "valid_ppl": "12.81", "valid_wps": "67059.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3627", "valid_best_loss": "3.679"}
[2022-06-12 23:50:33,098][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 3627 updates
[2022-06-12 23:50:33,099][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:50:37,231][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:50:40,658][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 70 @ 3627 updates, score 3.679) (writing took 7.55953446298372 seconds)
[2022-06-12 23:50:40,659][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2022-06-12 23:50:40,660][train][INFO] - {"epoch": 70, "train_loss": "3.77", "train_ppl": "13.64", "train_wps": "20786.7", "train_ups": "0.1", "train_wpb": "212908", "train_bsz": "503.5", "train_num_updates": "3627", "train_lr": "0.00018135", "train_gnorm": "0.672", "train_loss_scale": "64", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "37374"}
[2022-06-12 23:50:40,688][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 23:50:40,697][fairseq.trainer][INFO] - begin training epoch 71
[2022-06-12 23:50:40,698][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-12 23:58:50,311][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-12 23:59:28,137][valid][INFO] - {"epoch": 71, "valid_loss": "3.647", "valid_ppl": "12.53", "valid_wps": "67127.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3679", "valid_best_loss": "3.647"}
[2022-06-12 23:59:28,139][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 71 @ 3679 updates
[2022-06-12 23:59:28,140][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:59:32,382][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-12 23:59:35,731][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 71 @ 3679 updates, score 3.647) (writing took 7.591775821056217 seconds)
[2022-06-12 23:59:35,732][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2022-06-12 23:59:35,733][train][INFO] - {"epoch": 71, "train_loss": "3.705", "train_ppl": "13.04", "train_wps": "20687.2", "train_ups": "0.1", "train_wpb": "212868", "train_bsz": "503.5", "train_num_updates": "3679", "train_lr": "0.00018395", "train_gnorm": "0.64", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "37909"}
[2022-06-12 23:59:35,753][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-12 23:59:35,756][fairseq.trainer][INFO] - begin training epoch 72
[2022-06-12 23:59:35,757][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 00:07:47,160][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 00:08:24,503][valid][INFO] - {"epoch": 72, "valid_loss": "3.581", "valid_ppl": "11.97", "valid_wps": "67245.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3731", "valid_best_loss": "3.581"}
[2022-06-13 00:08:24,505][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 72 @ 3731 updates
[2022-06-13 00:08:24,505][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:08:28,521][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:08:32,069][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 72 @ 3731 updates, score 3.581) (writing took 7.563888418953866 seconds)
[2022-06-13 00:08:32,069][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2022-06-13 00:08:32,071][train][INFO] - {"epoch": 72, "train_loss": "3.654", "train_ppl": "12.59", "train_wps": "20652.1", "train_ups": "0.1", "train_wpb": "213010", "train_bsz": "503.5", "train_num_updates": "3731", "train_lr": "0.00018655", "train_gnorm": "0.64", "train_loss_scale": "64", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "38445"}
[2022-06-13 00:08:32,099][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 00:08:32,107][fairseq.trainer][INFO] - begin training epoch 73
[2022-06-13 00:08:32,109][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 00:16:39,084][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 00:17:16,570][valid][INFO] - {"epoch": 73, "valid_loss": "3.526", "valid_ppl": "11.52", "valid_wps": "67038.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3783", "valid_best_loss": "3.526"}
[2022-06-13 00:17:16,571][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 73 @ 3783 updates
[2022-06-13 00:17:16,572][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:17:20,699][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:17:23,958][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 73 @ 3783 updates, score 3.526) (writing took 7.386595556978136 seconds)
[2022-06-13 00:17:23,958][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2022-06-13 00:17:23,959][train][INFO] - {"epoch": 73, "train_loss": "3.588", "train_ppl": "12.03", "train_wps": "20807.6", "train_ups": "0.1", "train_wpb": "212832", "train_bsz": "503.5", "train_num_updates": "3783", "train_lr": "0.00018915", "train_gnorm": "0.633", "train_loss_scale": "64", "train_train_wall": "482", "train_gb_free": "6.2", "train_wall": "38977"}
[2022-06-13 00:17:23,981][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 00:17:23,990][fairseq.trainer][INFO] - begin training epoch 74
[2022-06-13 00:17:23,991][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 00:20:05,607][train_inner][INFO] - {"epoch": 74, "update": 73.327, "loss": "3.657", "ppl": "12.61", "wps": "20645.7", "ups": "0.1", "wpb": "212871", "bsz": "503.1", "num_updates": "3800", "lr": "0.00019", "gnorm": "0.64", "loss_scale": "64", "train_wall": "1864", "gb_free": "6.2", "wall": "39139"}
[2022-06-13 00:25:33,914][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 00:26:11,556][valid][INFO] - {"epoch": 74, "valid_loss": "3.491", "valid_ppl": "11.24", "valid_wps": "66798.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3835", "valid_best_loss": "3.491"}
[2022-06-13 00:26:11,557][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 74 @ 3835 updates
[2022-06-13 00:26:11,558][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:26:15,629][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:26:19,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 74 @ 3835 updates, score 3.491) (writing took 7.895929984049872 seconds)
[2022-06-13 00:26:19,454][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2022-06-13 00:26:19,455][train][INFO] - {"epoch": 74, "train_loss": "3.546", "train_ppl": "11.68", "train_wps": "20675", "train_ups": "0.1", "train_wpb": "212911", "train_bsz": "503.5", "train_num_updates": "3835", "train_lr": "0.00019175", "train_gnorm": "0.608", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "39513"}
[2022-06-13 00:26:19,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 00:26:19,481][fairseq.trainer][INFO] - begin training epoch 75
[2022-06-13 00:26:19,482][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 00:34:28,032][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 00:35:05,568][valid][INFO] - {"epoch": 75, "valid_loss": "3.455", "valid_ppl": "10.96", "valid_wps": "66827.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3887", "valid_best_loss": "3.455"}
[2022-06-13 00:35:05,569][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 3887 updates
[2022-06-13 00:35:05,570][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:35:09,891][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:35:13,467][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 75 @ 3887 updates, score 3.455) (writing took 7.897919495939277 seconds)
[2022-06-13 00:35:13,468][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2022-06-13 00:35:13,470][train][INFO] - {"epoch": 75, "train_loss": "3.496", "train_ppl": "11.28", "train_wps": "20712.9", "train_ups": "0.1", "train_wpb": "212712", "train_bsz": "503.5", "train_num_updates": "3887", "train_lr": "0.00019435", "train_gnorm": "0.617", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "40047"}
[2022-06-13 00:35:13,488][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 00:35:13,491][fairseq.trainer][INFO] - begin training epoch 76
[2022-06-13 00:35:13,492][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 00:43:21,157][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 00:43:58,508][valid][INFO] - {"epoch": 76, "valid_loss": "3.377", "valid_ppl": "10.39", "valid_wps": "67345.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3939", "valid_best_loss": "3.377"}
[2022-06-13 00:43:58,509][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 76 @ 3939 updates
[2022-06-13 00:43:58,510][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:44:02,643][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:44:05,957][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 76 @ 3939 updates, score 3.377) (writing took 7.447493033017963 seconds)
[2022-06-13 00:44:05,958][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2022-06-13 00:44:05,959][train][INFO] - {"epoch": 76, "train_loss": "3.46", "train_ppl": "11", "train_wps": "20789.4", "train_ups": "0.1", "train_wpb": "212887", "train_bsz": "503.5", "train_num_updates": "3939", "train_lr": "0.00019695", "train_gnorm": "0.605", "train_loss_scale": "128", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "40579"}
[2022-06-13 00:44:05,986][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 00:44:05,994][fairseq.trainer][INFO] - begin training epoch 77
[2022-06-13 00:44:05,995][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 00:52:15,576][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 00:52:53,105][valid][INFO] - {"epoch": 77, "valid_loss": "3.348", "valid_ppl": "10.18", "valid_wps": "67276.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "3991", "valid_best_loss": "3.348"}
[2022-06-13 00:52:53,107][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 77 @ 3991 updates
[2022-06-13 00:52:53,108][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:52:57,414][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 00:53:00,958][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 77 @ 3991 updates, score 3.348) (writing took 7.851021106005646 seconds)
[2022-06-13 00:53:00,959][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2022-06-13 00:53:00,960][train][INFO] - {"epoch": 77, "train_loss": "3.401", "train_ppl": "10.56", "train_wps": "20702.6", "train_ups": "0.1", "train_wpb": "212998", "train_bsz": "503.5", "train_num_updates": "3991", "train_lr": "0.00019955", "train_gnorm": "0.581", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "41114"}
[2022-06-13 00:53:00,993][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 00:53:01,002][fairseq.trainer][INFO] - begin training epoch 78
[2022-06-13 00:53:01,003][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 00:54:26,788][train_inner][INFO] - {"epoch": 78, "update": 77.173, "loss": "3.46", "ppl": "11.01", "wps": "20643.3", "ups": "0.1", "wpb": "212748", "bsz": "503.1", "num_updates": "4000", "lr": "0.0002", "gnorm": "0.601", "loss_scale": "128", "train_wall": "1862", "gb_free": "6.2", "wall": "41200"}
[2022-06-13 01:01:12,509][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 01:01:49,991][valid][INFO] - {"epoch": 78, "valid_loss": "3.309", "valid_ppl": "9.91", "valid_wps": "67131.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4043", "valid_best_loss": "3.309"}
[2022-06-13 01:01:49,993][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 78 @ 4043 updates
[2022-06-13 01:01:49,994][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:01:54,189][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:01:57,820][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 78 @ 4043 updates, score 3.309) (writing took 7.826817695051432 seconds)
[2022-06-13 01:01:57,821][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2022-06-13 01:01:57,822][train][INFO] - {"epoch": 78, "train_loss": "3.366", "train_ppl": "10.31", "train_wps": "20615.4", "train_ups": "0.1", "train_wpb": "212838", "train_bsz": "503.5", "train_num_updates": "4043", "train_lr": "0.00020215", "train_gnorm": "0.582", "train_loss_scale": "128", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "41651"}
[2022-06-13 01:01:57,846][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 01:01:57,853][fairseq.trainer][INFO] - begin training epoch 79
[2022-06-13 01:01:57,855][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 01:10:06,566][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 01:10:43,931][valid][INFO] - {"epoch": 79, "valid_loss": "3.278", "valid_ppl": "9.7", "valid_wps": "67205", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4095", "valid_best_loss": "3.278"}
[2022-06-13 01:10:43,933][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 79 @ 4095 updates
[2022-06-13 01:10:43,934][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:10:47,994][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:10:51,788][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 79 @ 4095 updates, score 3.278) (writing took 7.855045021977276 seconds)
[2022-06-13 01:10:51,789][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2022-06-13 01:10:51,791][train][INFO] - {"epoch": 79, "train_loss": "3.313", "train_ppl": "9.94", "train_wps": "20726.1", "train_ups": "0.1", "train_wpb": "212828", "train_bsz": "503.5", "train_num_updates": "4095", "train_lr": "0.00020475", "train_gnorm": "0.569", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.3", "train_wall": "42185"}
[2022-06-13 01:10:51,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 01:10:51,831][fairseq.trainer][INFO] - begin training epoch 80
[2022-06-13 01:10:51,832][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 01:19:01,497][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 01:19:38,984][valid][INFO] - {"epoch": 80, "valid_loss": "3.238", "valid_ppl": "9.44", "valid_wps": "67406.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4147", "valid_best_loss": "3.238"}
[2022-06-13 01:19:38,985][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 4147 updates
[2022-06-13 01:19:38,986][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:19:43,354][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:19:46,866][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 80 @ 4147 updates, score 3.238) (writing took 7.880124809918925 seconds)
[2022-06-13 01:19:46,867][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2022-06-13 01:19:46,869][train][INFO] - {"epoch": 80, "train_loss": "3.276", "train_ppl": "9.69", "train_wps": "20698.4", "train_ups": "0.1", "train_wpb": "212986", "train_bsz": "503.5", "train_num_updates": "4147", "train_lr": "0.00020735", "train_gnorm": "0.573", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "42720"}
[2022-06-13 01:19:46,898][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 01:19:46,906][fairseq.trainer][INFO] - begin training epoch 81
[2022-06-13 01:19:46,908][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 01:27:56,168][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 01:28:33,687][valid][INFO] - {"epoch": 81, "valid_loss": "3.213", "valid_ppl": "9.27", "valid_wps": "66910.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4199", "valid_best_loss": "3.213"}
[2022-06-13 01:28:33,688][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 81 @ 4199 updates
[2022-06-13 01:28:33,689][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:28:37,722][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:28:40,992][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 81 @ 4199 updates, score 3.213) (writing took 7.304135914891958 seconds)
[2022-06-13 01:28:40,993][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2022-06-13 01:28:40,995][train][INFO] - {"epoch": 81, "train_loss": "3.229", "train_ppl": "9.37", "train_wps": "20713.9", "train_ups": "0.1", "train_wpb": "212765", "train_bsz": "503.5", "train_num_updates": "4199", "train_lr": "0.00020995", "train_gnorm": "0.561", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "43254"}
[2022-06-13 01:28:41,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 01:28:41,032][fairseq.trainer][INFO] - begin training epoch 82
[2022-06-13 01:28:41,033][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 01:28:51,467][train_inner][INFO] - {"epoch": 82, "update": 81.019, "loss": "3.291", "ppl": "9.79", "wps": "20604.8", "ups": "0.1", "wpb": "212712", "bsz": "503.2", "num_updates": "4200", "lr": "0.00021", "gnorm": "0.569", "loss_scale": "256", "train_wall": "1866", "gb_free": "6.2", "wall": "43265"}
[2022-06-13 01:36:48,276][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 01:37:25,909][valid][INFO] - {"epoch": 82, "valid_loss": "3.164", "valid_ppl": "8.96", "valid_wps": "67238.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4251", "valid_best_loss": "3.164"}
[2022-06-13 01:37:25,910][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 82 @ 4251 updates
[2022-06-13 01:37:25,911][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:37:30,170][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:37:33,932][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 82 @ 4251 updates, score 3.164) (writing took 8.022059590904973 seconds)
[2022-06-13 01:37:33,933][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2022-06-13 01:37:33,934][train][INFO] - {"epoch": 82, "train_loss": "3.196", "train_ppl": "9.16", "train_wps": "20777.9", "train_ups": "0.1", "train_wpb": "212949", "train_bsz": "503.5", "train_num_updates": "4251", "train_lr": "0.00021255", "train_gnorm": "0.564", "train_loss_scale": "256", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "43787"}
[2022-06-13 01:37:33,964][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 01:37:33,972][fairseq.trainer][INFO] - begin training epoch 83
[2022-06-13 01:37:33,974][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 01:45:44,168][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 01:46:21,774][valid][INFO] - {"epoch": 83, "valid_loss": "3.139", "valid_ppl": "8.81", "valid_wps": "66928.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4303", "valid_best_loss": "3.139"}
[2022-06-13 01:46:21,775][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 83 @ 4303 updates
[2022-06-13 01:46:21,776][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:46:25,853][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:46:29,151][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 83 @ 4303 updates, score 3.139) (writing took 7.37517159502022 seconds)
[2022-06-13 01:46:29,152][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2022-06-13 01:46:29,153][train][INFO] - {"epoch": 83, "train_loss": "3.149", "train_ppl": "8.87", "train_wps": "20702", "train_ups": "0.1", "train_wpb": "213078", "train_bsz": "503.5", "train_num_updates": "4303", "train_lr": "0.00021515", "train_gnorm": "0.554", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "44323"}
[2022-06-13 01:46:29,184][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 01:46:29,193][fairseq.trainer][INFO] - begin training epoch 84
[2022-06-13 01:46:29,194][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 01:46:47,996][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 01:54:36,416][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 01:55:13,879][valid][INFO] - {"epoch": 84, "valid_loss": "3.133", "valid_ppl": "8.77", "valid_wps": "67051.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4354", "valid_best_loss": "3.133"}
[2022-06-13 01:55:13,881][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 84 @ 4354 updates
[2022-06-13 01:55:13,882][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:55:18,024][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 01:55:21,316][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 84 @ 4354 updates, score 3.133) (writing took 7.435170035925694 seconds)
[2022-06-13 01:55:21,317][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2022-06-13 01:55:21,319][train][INFO] - {"epoch": 84, "train_loss": "3.123", "train_ppl": "8.71", "train_wps": "20394.9", "train_ups": "0.1", "train_wpb": "212813", "train_bsz": "503.3", "train_num_updates": "4354", "train_lr": "0.0002177", "train_gnorm": "0.558", "train_loss_scale": "128", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "44855"}
[2022-06-13 01:55:21,347][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 01:55:21,356][fairseq.trainer][INFO] - begin training epoch 85
[2022-06-13 01:55:21,357][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 02:02:39,188][train_inner][INFO] - {"epoch": 85, "update": 84.885, "loss": "3.141", "ppl": "8.82", "wps": "21076.8", "ups": "0.1", "wpb": "213690", "bsz": "505.3", "num_updates": "4400", "lr": "0.00022", "gnorm": "0.549", "loss_scale": "128", "train_wall": "1875", "gb_free": "6.2", "wall": "45293"}
[2022-06-13 02:03:32,239][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 02:04:09,925][valid][INFO] - {"epoch": 85, "valid_loss": "3.074", "valid_ppl": "8.42", "valid_wps": "67162.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4406", "valid_best_loss": "3.074"}
[2022-06-13 02:04:09,927][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 85 @ 4406 updates
[2022-06-13 02:04:09,928][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:04:14,105][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:04:17,458][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 85 @ 4406 updates, score 3.074) (writing took 7.53025019611232 seconds)
[2022-06-13 02:04:17,458][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2022-06-13 02:04:17,459][train][INFO] - {"epoch": 85, "train_loss": "3.09", "train_ppl": "8.51", "train_wps": "20649.1", "train_ups": "0.1", "train_wpb": "212900", "train_bsz": "503.5", "train_num_updates": "4406", "train_lr": "0.0002203", "train_gnorm": "0.552", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "45391"}
[2022-06-13 02:04:17,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 02:04:17,476][fairseq.trainer][INFO] - begin training epoch 86
[2022-06-13 02:04:17,477][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 02:12:25,395][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 02:13:02,879][valid][INFO] - {"epoch": 86, "valid_loss": "3.048", "valid_ppl": "8.27", "valid_wps": "67391.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4458", "valid_best_loss": "3.048"}
[2022-06-13 02:13:02,881][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 86 @ 4458 updates
[2022-06-13 02:13:02,882][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:13:06,990][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:13:10,396][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 86 @ 4458 updates, score 3.048) (writing took 7.515004927990958 seconds)
[2022-06-13 02:13:10,396][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2022-06-13 02:13:10,397][train][INFO] - {"epoch": 86, "train_loss": "3.046", "train_ppl": "8.26", "train_wps": "20775.2", "train_ups": "0.1", "train_wpb": "212921", "train_bsz": "503.5", "train_num_updates": "4458", "train_lr": "0.0002229", "train_gnorm": "0.54", "train_loss_scale": "128", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "45924"}
[2022-06-13 02:13:10,409][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 02:13:10,412][fairseq.trainer][INFO] - begin training epoch 87
[2022-06-13 02:13:10,412][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 02:21:20,790][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 02:21:58,456][valid][INFO] - {"epoch": 87, "valid_loss": "3.031", "valid_ppl": "8.17", "valid_wps": "67095.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4510", "valid_best_loss": "3.031"}
[2022-06-13 02:21:58,457][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 87 @ 4510 updates
[2022-06-13 02:21:58,458][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:22:02,630][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:22:06,166][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 87 @ 4510 updates, score 3.031) (writing took 7.708796315942891 seconds)
[2022-06-13 02:22:06,167][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2022-06-13 02:22:06,169][train][INFO] - {"epoch": 87, "train_loss": "3.013", "train_ppl": "8.07", "train_wps": "20672.9", "train_ups": "0.1", "train_wpb": "212999", "train_bsz": "503.5", "train_num_updates": "4510", "train_lr": "0.0002255", "train_gnorm": "0.538", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "46460"}
[2022-06-13 02:22:06,199][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 02:22:06,208][fairseq.trainer][INFO] - begin training epoch 88
[2022-06-13 02:22:06,209][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 02:30:14,657][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 02:30:52,060][valid][INFO] - {"epoch": 88, "valid_loss": "3.03", "valid_ppl": "8.17", "valid_wps": "67120.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4562", "valid_best_loss": "3.03"}
[2022-06-13 02:30:52,061][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 88 @ 4562 updates
[2022-06-13 02:30:52,062][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:30:56,219][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:30:59,606][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 88 @ 4562 updates, score 3.03) (writing took 7.54457963607274 seconds)
[2022-06-13 02:30:59,607][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2022-06-13 02:30:59,608][train][INFO] - {"epoch": 88, "train_loss": "2.977", "train_ppl": "7.88", "train_wps": "20753.9", "train_ups": "0.1", "train_wpb": "212903", "train_bsz": "503.5", "train_num_updates": "4562", "train_lr": "0.0002281", "train_gnorm": "0.549", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.3", "train_wall": "46993"}
[2022-06-13 02:30:59,637][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 02:30:59,645][fairseq.trainer][INFO] - begin training epoch 89
[2022-06-13 02:30:59,646][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 02:36:59,149][train_inner][INFO] - {"epoch": 89, "update": 88.731, "loss": "3.002", "ppl": "8.01", "wps": "20661", "ups": "0.1", "wpb": "212804", "bsz": "503.1", "num_updates": "4600", "lr": "0.00023", "gnorm": "0.548", "loss_scale": "256", "train_wall": "1861", "gb_free": "6.2", "wall": "47353"}
[2022-06-13 02:39:08,195][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 02:39:45,659][valid][INFO] - {"epoch": 89, "valid_loss": "2.959", "valid_ppl": "7.78", "valid_wps": "67320", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4614", "valid_best_loss": "2.959"}
[2022-06-13 02:39:45,661][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 89 @ 4614 updates
[2022-06-13 02:39:45,662][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:39:49,893][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:39:53,285][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 89 @ 4614 updates, score 2.959) (writing took 7.6236238530837 seconds)
[2022-06-13 02:39:53,285][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2022-06-13 02:39:53,287][train][INFO] - {"epoch": 89, "train_loss": "2.956", "train_ppl": "7.76", "train_wps": "20746", "train_ups": "0.1", "train_wpb": "212917", "train_bsz": "503.5", "train_num_updates": "4614", "train_lr": "0.0002307", "train_gnorm": "0.549", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "47527"}
[2022-06-13 02:39:53,312][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 02:39:53,321][fairseq.trainer][INFO] - begin training epoch 90
[2022-06-13 02:39:53,322][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 02:48:01,832][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 02:48:39,277][valid][INFO] - {"epoch": 90, "valid_loss": "2.942", "valid_ppl": "7.68", "valid_wps": "67072.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4666", "valid_best_loss": "2.942"}
[2022-06-13 02:48:39,279][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 4666 updates
[2022-06-13 02:48:39,280][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:48:43,498][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:48:46,736][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 90 @ 4666 updates, score 2.942) (writing took 7.456960541894659 seconds)
[2022-06-13 02:48:46,738][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2022-06-13 02:48:46,740][train][INFO] - {"epoch": 90, "train_loss": "2.909", "train_ppl": "7.51", "train_wps": "20754.9", "train_ups": "0.1", "train_wpb": "212918", "train_bsz": "503.5", "train_num_updates": "4666", "train_lr": "0.0002333", "train_gnorm": "0.535", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "48060"}
[2022-06-13 02:48:46,767][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 02:48:46,776][fairseq.trainer][INFO] - begin training epoch 91
[2022-06-13 02:48:46,778][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 02:56:55,403][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 02:57:32,911][valid][INFO] - {"epoch": 91, "valid_loss": "2.932", "valid_ppl": "7.63", "valid_wps": "66964.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4718", "valid_best_loss": "2.932"}
[2022-06-13 02:57:32,912][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 91 @ 4718 updates
[2022-06-13 02:57:32,913][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:57:37,119][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 02:57:40,589][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 91 @ 4718 updates, score 2.932) (writing took 7.67647002695594 seconds)
[2022-06-13 02:57:40,589][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2022-06-13 02:57:40,591][train][INFO] - {"epoch": 91, "train_loss": "2.883", "train_ppl": "7.38", "train_wps": "20741.3", "train_ups": "0.1", "train_wpb": "212937", "train_bsz": "503.5", "train_num_updates": "4718", "train_lr": "0.0002359", "train_gnorm": "0.543", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "48594"}
[2022-06-13 02:57:40,618][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 02:57:40,626][fairseq.trainer][INFO] - begin training epoch 92
[2022-06-13 02:57:40,627][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 03:05:52,918][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 03:06:30,365][valid][INFO] - {"epoch": 92, "valid_loss": "2.892", "valid_ppl": "7.42", "valid_wps": "67174.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4770", "valid_best_loss": "2.892"}
[2022-06-13 03:06:30,367][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 92 @ 4770 updates
[2022-06-13 03:06:30,368][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:06:34,511][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:06:37,832][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 92 @ 4770 updates, score 2.892) (writing took 7.464797434979118 seconds)
[2022-06-13 03:06:37,832][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2022-06-13 03:06:37,834][train][INFO] - {"epoch": 92, "train_loss": "2.867", "train_ppl": "7.29", "train_wps": "20601.9", "train_ups": "0.1", "train_wpb": "212850", "train_bsz": "503.5", "train_num_updates": "4770", "train_lr": "0.0002385", "train_gnorm": "0.537", "train_loss_scale": "256", "train_train_wall": "488", "train_gb_free": "6.2", "train_wall": "49131"}
[2022-06-13 03:06:37,851][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 03:06:37,854][fairseq.trainer][INFO] - begin training epoch 93
[2022-06-13 03:06:37,855][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 03:11:22,713][train_inner][INFO] - {"epoch": 93, "update": 92.577, "loss": "2.883", "ppl": "7.38", "wps": "20609.1", "ups": "0.1", "wpb": "212641", "bsz": "503.1", "num_updates": "4800", "lr": "0.00024", "gnorm": "0.538", "loss_scale": "256", "train_wall": "1865", "gb_free": "6.2", "wall": "49416"}
[2022-06-13 03:14:46,530][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 03:15:23,973][valid][INFO] - {"epoch": 93, "valid_loss": "2.888", "valid_ppl": "7.4", "valid_wps": "67225.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4822", "valid_best_loss": "2.888"}
[2022-06-13 03:15:23,975][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 93 @ 4822 updates
[2022-06-13 03:15:23,975][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:15:28,233][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:15:31,706][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 93 @ 4822 updates, score 2.888) (writing took 7.731628792011179 seconds)
[2022-06-13 03:15:31,707][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2022-06-13 03:15:31,709][train][INFO] - {"epoch": 93, "train_loss": "2.828", "train_ppl": "7.1", "train_wps": "20728.1", "train_ups": "0.1", "train_wpb": "212811", "train_bsz": "503.5", "train_num_updates": "4822", "train_lr": "0.0002411", "train_gnorm": "0.533", "train_loss_scale": "512", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "49665"}
[2022-06-13 03:15:31,739][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 03:15:31,748][fairseq.trainer][INFO] - begin training epoch 94
[2022-06-13 03:15:31,749][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 03:15:41,211][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 03:23:37,519][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 03:24:15,106][valid][INFO] - {"epoch": 94, "valid_loss": "2.875", "valid_ppl": "7.33", "valid_wps": "67248.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4873", "valid_best_loss": "2.875"}
[2022-06-13 03:24:15,108][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 94 @ 4873 updates
[2022-06-13 03:24:15,109][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:24:19,157][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:24:22,616][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 94 @ 4873 updates, score 2.875) (writing took 7.507825333043002 seconds)
[2022-06-13 03:24:22,616][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2022-06-13 03:24:22,617][train][INFO] - {"epoch": 94, "train_loss": "2.8", "train_ppl": "6.97", "train_wps": "20443.4", "train_ups": "0.1", "train_wpb": "212815", "train_bsz": "503.3", "train_num_updates": "4873", "train_lr": "0.00024365", "train_gnorm": "0.538", "train_loss_scale": "256", "train_train_wall": "481", "train_gb_free": "6.1", "train_wall": "50196"}
[2022-06-13 03:24:22,628][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 03:24:22,631][fairseq.trainer][INFO] - begin training epoch 95
[2022-06-13 03:24:22,631][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 03:32:30,929][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 03:33:08,435][valid][INFO] - {"epoch": 95, "valid_loss": "2.844", "valid_ppl": "7.18", "valid_wps": "67098.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4925", "valid_best_loss": "2.844"}
[2022-06-13 03:33:08,436][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 95 @ 4925 updates
[2022-06-13 03:33:08,437][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:33:12,465][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:33:15,855][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 95 @ 4925 updates, score 2.844) (writing took 7.418781723012216 seconds)
[2022-06-13 03:33:15,856][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2022-06-13 03:33:15,857][train][INFO] - {"epoch": 95, "train_loss": "2.774", "train_ppl": "6.84", "train_wps": "20756.4", "train_ups": "0.1", "train_wpb": "212849", "train_bsz": "503.5", "train_num_updates": "4925", "train_lr": "0.00024625", "train_gnorm": "0.536", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.1", "train_wall": "50729"}
[2022-06-13 03:33:15,885][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 03:33:15,894][fairseq.trainer][INFO] - begin training epoch 96
[2022-06-13 03:33:15,895][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 03:41:22,683][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 03:42:00,231][valid][INFO] - {"epoch": 96, "valid_loss": "2.833", "valid_ppl": "7.12", "valid_wps": "67154.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "4977", "valid_best_loss": "2.833"}
[2022-06-13 03:42:00,233][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 96 @ 4977 updates
[2022-06-13 03:42:00,233][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:42:04,420][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:42:07,883][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 96 @ 4977 updates, score 2.833) (writing took 7.649953607935458 seconds)
[2022-06-13 03:42:07,883][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2022-06-13 03:42:07,884][train][INFO] - {"epoch": 96, "train_loss": "2.742", "train_ppl": "6.69", "train_wps": "20800.8", "train_ups": "0.1", "train_wpb": "212818", "train_bsz": "503.5", "train_num_updates": "4977", "train_lr": "0.00024885", "train_gnorm": "0.532", "train_loss_scale": "256", "train_train_wall": "482", "train_gb_free": "6.1", "train_wall": "51261"}
[2022-06-13 03:42:07,896][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 03:42:07,905][fairseq.trainer][INFO] - begin training epoch 97
[2022-06-13 03:42:07,906][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 03:45:45,611][train_inner][INFO] - {"epoch": 97, "update": 96.442, "loss": "2.773", "ppl": "6.84", "wps": "20619.6", "ups": "0.1", "wpb": "212680", "bsz": "503.1", "num_updates": "5000", "lr": "0.00025", "gnorm": "0.538", "loss_scale": "256", "train_wall": "1864", "gb_free": "6.2", "wall": "51479"}
[2022-06-13 03:50:18,867][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 03:50:56,539][valid][INFO] - {"epoch": 97, "valid_loss": "2.785", "valid_ppl": "6.89", "valid_wps": "66838.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5029", "valid_best_loss": "2.785"}
[2022-06-13 03:50:56,540][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 97 @ 5029 updates
[2022-06-13 03:50:56,541][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:51:00,727][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:51:04,216][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 97 @ 5029 updates, score 2.785) (writing took 7.675151580944657 seconds)
[2022-06-13 03:51:04,216][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2022-06-13 03:51:04,218][train][INFO] - {"epoch": 97, "train_loss": "2.721", "train_ppl": "6.59", "train_wps": "20654.7", "train_ups": "0.1", "train_wpb": "213035", "train_bsz": "503.5", "train_num_updates": "5029", "train_lr": "0.00025145", "train_gnorm": "0.537", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "51798"}
[2022-06-13 03:51:04,236][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 03:51:04,240][fairseq.trainer][INFO] - begin training epoch 98
[2022-06-13 03:51:04,240][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 03:59:12,238][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 03:59:49,734][valid][INFO] - {"epoch": 98, "valid_loss": "2.774", "valid_ppl": "6.84", "valid_wps": "67349.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5081", "valid_best_loss": "2.774"}
[2022-06-13 03:59:49,736][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 98 @ 5081 updates
[2022-06-13 03:59:49,737][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:59:53,802][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 03:59:57,115][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 98 @ 5081 updates, score 2.774) (writing took 7.379008903983049 seconds)
[2022-06-13 03:59:57,115][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2022-06-13 03:59:57,117][train][INFO] - {"epoch": 98, "train_loss": "2.694", "train_ppl": "6.47", "train_wps": "20780.7", "train_ups": "0.1", "train_wpb": "212962", "train_bsz": "503.5", "train_num_updates": "5081", "train_lr": "0.00025405", "train_gnorm": "0.529", "train_loss_scale": "512", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "52331"}
[2022-06-13 03:59:57,147][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 03:59:57,155][fairseq.trainer][INFO] - begin training epoch 99
[2022-06-13 03:59:57,157][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 04:00:14,919][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 04:08:03,841][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 04:08:41,442][valid][INFO] - {"epoch": 99, "valid_loss": "2.771", "valid_ppl": "6.83", "valid_wps": "66791.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5132", "valid_best_loss": "2.771"}
[2022-06-13 04:08:41,444][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 99 @ 5132 updates
[2022-06-13 04:08:41,444][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:08:45,995][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:08:49,784][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 99 @ 5132 updates, score 2.771) (writing took 8.340734632918611 seconds)
[2022-06-13 04:08:49,785][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2022-06-13 04:08:49,787][train][INFO] - {"epoch": 99, "train_loss": "2.671", "train_ppl": "6.37", "train_wps": "20376.5", "train_ups": "0.1", "train_wpb": "212823", "train_bsz": "503.3", "train_num_updates": "5132", "train_lr": "0.0002566", "train_gnorm": "0.54", "train_loss_scale": "256", "train_train_wall": "482", "train_gb_free": "6.4", "train_wall": "52863"}
[2022-06-13 04:08:49,813][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 04:08:49,821][fairseq.trainer][INFO] - begin training epoch 100
[2022-06-13 04:08:49,822][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 04:17:00,631][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 04:17:38,252][valid][INFO] - {"epoch": 100, "valid_loss": "2.739", "valid_ppl": "6.67", "valid_wps": "66992.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5184", "valid_best_loss": "2.739"}
[2022-06-13 04:17:38,254][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 5184 updates
[2022-06-13 04:17:38,255][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:17:42,272][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:17:45,625][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 100 @ 5184 updates, score 2.739) (writing took 7.370875198976137 seconds)
[2022-06-13 04:17:45,626][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2022-06-13 04:17:45,627][train][INFO] - {"epoch": 100, "train_loss": "2.651", "train_ppl": "6.28", "train_wps": "20659.5", "train_ups": "0.1", "train_wpb": "212888", "train_bsz": "503.5", "train_num_updates": "5184", "train_lr": "0.0002592", "train_gnorm": "0.535", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "53399"}
[2022-06-13 04:17:45,656][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 04:17:45,665][fairseq.trainer][INFO] - begin training epoch 101
[2022-06-13 04:17:45,666][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 04:20:18,131][train_inner][INFO] - {"epoch": 101, "update": 100.308, "loss": "2.675", "ppl": "6.39", "wps": "20546.8", "ups": "0.1", "wpb": "212918", "bsz": "503.1", "num_updates": "5200", "lr": "0.00026", "gnorm": "0.536", "loss_scale": "256", "train_wall": "1873", "gb_free": "6.1", "wall": "53552"}
[2022-06-13 04:25:54,935][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 04:26:32,434][valid][INFO] - {"epoch": 101, "valid_loss": "2.735", "valid_ppl": "6.66", "valid_wps": "67050.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5236", "valid_best_loss": "2.735"}
[2022-06-13 04:26:32,436][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 101 @ 5236 updates
[2022-06-13 04:26:32,437][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:26:36,545][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:26:40,078][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 101 @ 5236 updates, score 2.735) (writing took 7.642402958008461 seconds)
[2022-06-13 04:26:40,079][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2022-06-13 04:26:40,081][train][INFO] - {"epoch": 101, "train_loss": "2.626", "train_ppl": "6.17", "train_wps": "20712.1", "train_ups": "0.1", "train_wpb": "212878", "train_bsz": "503.5", "train_num_updates": "5236", "train_lr": "0.0002618", "train_gnorm": "0.541", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "53933"}
[2022-06-13 04:26:40,106][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 04:26:40,114][fairseq.trainer][INFO] - begin training epoch 102
[2022-06-13 04:26:40,116][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 04:34:49,436][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 04:35:27,056][valid][INFO] - {"epoch": 102, "valid_loss": "2.704", "valid_ppl": "6.52", "valid_wps": "66914.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5288", "valid_best_loss": "2.704"}
[2022-06-13 04:35:27,057][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 102 @ 5288 updates
[2022-06-13 04:35:27,058][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:35:31,373][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:35:34,967][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 102 @ 5288 updates, score 2.704) (writing took 7.910052284016274 seconds)
[2022-06-13 04:35:34,968][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2022-06-13 04:35:34,970][train][INFO] - {"epoch": 102, "train_loss": "2.606", "train_ppl": "6.09", "train_wps": "20695.2", "train_ups": "0.1", "train_wpb": "212878", "train_bsz": "503.5", "train_num_updates": "5288", "train_lr": "0.0002644", "train_gnorm": "0.539", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.3", "train_wall": "54468"}
[2022-06-13 04:35:34,997][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 04:35:35,005][fairseq.trainer][INFO] - begin training epoch 103
[2022-06-13 04:35:35,006][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 04:43:45,083][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 04:43:45,085][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 04:44:22,448][valid][INFO] - {"epoch": 103, "valid_loss": "2.662", "valid_ppl": "6.33", "valid_wps": "67211.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5339", "valid_best_loss": "2.662"}
[2022-06-13 04:44:22,450][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 103 @ 5339 updates
[2022-06-13 04:44:22,451][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:44:26,439][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 04:44:30,036][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 103 @ 5339 updates, score 2.662) (writing took 7.585787103045732 seconds)
[2022-06-13 04:44:30,036][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2022-06-13 04:44:30,038][train][INFO] - {"epoch": 103, "train_loss": "2.582", "train_ppl": "5.99", "train_wps": "20641.6", "train_ups": "0.1", "train_wpb": "216561", "train_bsz": "512", "train_num_updates": "5339", "train_lr": "0.00026695", "train_gnorm": "0.502", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "55003"}
[2022-06-13 04:44:30,066][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 04:44:30,074][fairseq.trainer][INFO] - begin training epoch 104
[2022-06-13 04:44:30,075][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 04:52:36,371][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 04:53:13,861][valid][INFO] - {"epoch": 104, "valid_loss": "2.684", "valid_ppl": "6.43", "valid_wps": "67013.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5391", "valid_best_loss": "2.662"}
[2022-06-13 04:53:13,863][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 104 @ 5391 updates
[2022-06-13 04:53:13,864][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 04:53:18,068][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 04:53:18,114][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 104 @ 5391 updates, score 2.684) (writing took 4.250609021051787 seconds)
[2022-06-13 04:53:18,114][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2022-06-13 04:53:18,115][train][INFO] - {"epoch": 104, "train_loss": "2.529", "train_ppl": "5.77", "train_wps": "20962.6", "train_ups": "0.1", "train_wpb": "212882", "train_bsz": "503.5", "train_num_updates": "5391", "train_lr": "0.00026955", "train_gnorm": "0.515", "train_loss_scale": "256", "train_train_wall": "482", "train_gb_free": "6.2", "train_wall": "55532"}
[2022-06-13 04:53:18,126][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 04:53:18,129][fairseq.trainer][INFO] - begin training epoch 105
[2022-06-13 04:53:18,130][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 04:54:43,622][train_inner][INFO] - {"epoch": 105, "update": 104.173, "loss": "2.58", "ppl": "5.98", "wps": "20694.9", "ups": "0.1", "wpb": "213725", "bsz": "505.4", "num_updates": "5400", "lr": "0.00027", "gnorm": "0.526", "loss_scale": "256", "train_wall": "1870", "gb_free": "6.2", "wall": "55617"}
[2022-06-13 05:01:26,067][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 05:02:03,476][valid][INFO] - {"epoch": 105, "valid_loss": "2.659", "valid_ppl": "6.32", "valid_wps": "67117.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5443", "valid_best_loss": "2.659"}
[2022-06-13 05:02:03,477][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 5443 updates
[2022-06-13 05:02:03,478][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:02:07,614][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:02:11,103][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 105 @ 5443 updates, score 2.659) (writing took 7.625483657000586 seconds)
[2022-06-13 05:02:11,104][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2022-06-13 05:02:11,105][train][INFO] - {"epoch": 105, "train_loss": "2.529", "train_ppl": "5.77", "train_wps": "20782.4", "train_ups": "0.1", "train_wpb": "213016", "train_bsz": "503.5", "train_num_updates": "5443", "train_lr": "0.00027215", "train_gnorm": "0.533", "train_loss_scale": "256", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "56064"}
[2022-06-13 05:02:11,121][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 05:02:11,124][fairseq.trainer][INFO] - begin training epoch 106
[2022-06-13 05:02:11,125][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 05:10:20,788][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 05:10:58,241][valid][INFO] - {"epoch": 106, "valid_loss": "2.635", "valid_ppl": "6.21", "valid_wps": "67115.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5495", "valid_best_loss": "2.635"}
[2022-06-13 05:10:58,243][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 106 @ 5495 updates
[2022-06-13 05:10:58,244][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:11:02,363][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:11:05,871][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 106 @ 5495 updates, score 2.635) (writing took 7.6285646019969136 seconds)
[2022-06-13 05:11:05,872][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2022-06-13 05:11:05,874][train][INFO] - {"epoch": 106, "train_loss": "2.511", "train_ppl": "5.7", "train_wps": "20703.3", "train_ups": "0.1", "train_wpb": "212913", "train_bsz": "503.5", "train_num_updates": "5495", "train_lr": "0.00027475", "train_gnorm": "0.528", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "56599"}
[2022-06-13 05:11:05,902][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 05:11:05,911][fairseq.trainer][INFO] - begin training epoch 107
[2022-06-13 05:11:05,912][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 05:19:16,586][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 05:19:54,109][valid][INFO] - {"epoch": 107, "valid_loss": "2.632", "valid_ppl": "6.2", "valid_wps": "67022.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5547", "valid_best_loss": "2.632"}
[2022-06-13 05:19:54,110][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 107 @ 5547 updates
[2022-06-13 05:19:54,111][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:19:58,233][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:20:01,578][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 107 @ 5547 updates, score 2.632) (writing took 7.4675514079863206 seconds)
[2022-06-13 05:20:01,578][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2022-06-13 05:20:01,580][train][INFO] - {"epoch": 107, "train_loss": "2.487", "train_ppl": "5.61", "train_wps": "20665.9", "train_ups": "0.1", "train_wpb": "212900", "train_bsz": "503.5", "train_num_updates": "5547", "train_lr": "0.00027735", "train_gnorm": "0.538", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "57135"}
[2022-06-13 05:20:01,608][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 05:20:01,616][fairseq.trainer][INFO] - begin training epoch 108
[2022-06-13 05:20:01,618][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 05:28:11,492][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 05:28:48,944][valid][INFO] - {"epoch": 108, "valid_loss": "2.625", "valid_ppl": "6.17", "valid_wps": "67117.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5599", "valid_best_loss": "2.625"}
[2022-06-13 05:28:48,946][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 108 @ 5599 updates
[2022-06-13 05:28:48,946][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:28:53,250][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:28:56,652][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 108 @ 5599 updates, score 2.625) (writing took 7.705971551942639 seconds)
[2022-06-13 05:28:56,652][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2022-06-13 05:28:56,654][train][INFO] - {"epoch": 108, "train_loss": "2.476", "train_ppl": "5.56", "train_wps": "20685.2", "train_ups": "0.1", "train_wpb": "212848", "train_bsz": "503.5", "train_num_updates": "5599", "train_lr": "0.00027995", "train_gnorm": "0.553", "train_loss_scale": "512", "train_train_wall": "485", "train_gb_free": "6.3", "train_wall": "57670"}
[2022-06-13 05:28:56,681][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 05:28:56,690][fairseq.trainer][INFO] - begin training epoch 109
[2022-06-13 05:28:56,691][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 05:29:07,428][train_inner][INFO] - {"epoch": 109, "update": 108.019, "loss": "2.497", "ppl": "5.65", "wps": "20626", "ups": "0.1", "wpb": "212840", "bsz": "503.1", "num_updates": "5600", "lr": "0.00028", "gnorm": "0.536", "loss_scale": "512", "train_wall": "1865", "gb_free": "6.2", "wall": "57681"}
[2022-06-13 05:29:45,384][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 05:37:06,906][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 05:37:44,432][valid][INFO] - {"epoch": 109, "valid_loss": "2.614", "valid_ppl": "6.12", "valid_wps": "66992.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5650", "valid_best_loss": "2.614"}
[2022-06-13 05:37:44,434][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 109 @ 5650 updates
[2022-06-13 05:37:44,435][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:37:48,532][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:37:52,078][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 109 @ 5650 updates, score 2.614) (writing took 7.643606201047078 seconds)
[2022-06-13 05:37:52,079][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2022-06-13 05:37:52,080][train][INFO] - {"epoch": 109, "train_loss": "2.457", "train_ppl": "5.49", "train_wps": "20260.6", "train_ups": "0.1", "train_wpb": "212707", "train_bsz": "503.3", "train_num_updates": "5650", "train_lr": "0.0002825", "train_gnorm": "0.542", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.3", "train_wall": "58205"}
[2022-06-13 05:37:52,108][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 05:37:52,117][fairseq.trainer][INFO] - begin training epoch 110
[2022-06-13 05:37:52,118][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 05:46:01,636][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 05:46:39,220][valid][INFO] - {"epoch": 110, "valid_loss": "2.581", "valid_ppl": "5.98", "valid_wps": "67054.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5702", "valid_best_loss": "2.581"}
[2022-06-13 05:46:39,222][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 5702 updates
[2022-06-13 05:46:39,223][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:46:43,395][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:46:47,336][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 110 @ 5702 updates, score 2.581) (writing took 8.114664555992931 seconds)
[2022-06-13 05:46:47,337][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2022-06-13 05:46:47,339][train][INFO] - {"epoch": 110, "train_loss": "2.424", "train_ppl": "5.37", "train_wps": "20680.5", "train_ups": "0.1", "train_wpb": "212873", "train_bsz": "503.5", "train_num_updates": "5702", "train_lr": "0.0002851", "train_gnorm": "0.537", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "58741"}
[2022-06-13 05:46:47,368][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 05:46:47,377][fairseq.trainer][INFO] - begin training epoch 111
[2022-06-13 05:46:47,378][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 05:54:57,390][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 05:55:34,851][valid][INFO] - {"epoch": 111, "valid_loss": "2.575", "valid_ppl": "5.96", "valid_wps": "67226.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5754", "valid_best_loss": "2.575"}
[2022-06-13 05:55:34,853][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 111 @ 5754 updates
[2022-06-13 05:55:34,854][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:55:39,078][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 05:55:42,832][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 111 @ 5754 updates, score 2.575) (writing took 7.979592759045772 seconds)
[2022-06-13 05:55:42,833][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2022-06-13 05:55:42,835][train][INFO] - {"epoch": 111, "train_loss": "2.413", "train_ppl": "5.33", "train_wps": "20677.7", "train_ups": "0.1", "train_wpb": "212938", "train_bsz": "503.5", "train_num_updates": "5754", "train_lr": "0.0002877", "train_gnorm": "0.532", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "59276"}
[2022-06-13 05:55:42,856][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 05:55:42,864][fairseq.trainer][INFO] - begin training epoch 112
[2022-06-13 05:55:42,865][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 06:03:00,638][train_inner][INFO] - {"epoch": 112, "update": 111.885, "loss": "2.424", "ppl": "5.37", "wps": "21016.5", "ups": "0.1", "wpb": "213655", "bsz": "505.3", "num_updates": "5800", "lr": "0.00029", "gnorm": "0.528", "loss_scale": "256", "train_wall": "1881", "gb_free": "6.2", "wall": "59714"}
[2022-06-13 06:03:52,503][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 06:04:30,010][valid][INFO] - {"epoch": 112, "valid_loss": "2.578", "valid_ppl": "5.97", "valid_wps": "66959.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5806", "valid_best_loss": "2.575"}
[2022-06-13 06:04:30,012][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 112 @ 5806 updates
[2022-06-13 06:04:30,013][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 06:04:34,095][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 06:04:34,137][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 112 @ 5806 updates, score 2.578) (writing took 4.1255771240685135 seconds)
[2022-06-13 06:04:34,138][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2022-06-13 06:04:34,139][train][INFO] - {"epoch": 112, "train_loss": "2.392", "train_ppl": "5.25", "train_wps": "20833.5", "train_ups": "0.1", "train_wpb": "212864", "train_bsz": "503.5", "train_num_updates": "5806", "train_lr": "0.0002903", "train_gnorm": "0.536", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "59808"}
[2022-06-13 06:04:34,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 06:04:34,153][fairseq.trainer][INFO] - begin training epoch 113
[2022-06-13 06:04:34,153][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 06:12:41,765][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 06:13:19,363][valid][INFO] - {"epoch": 113, "valid_loss": "2.549", "valid_ppl": "5.85", "valid_wps": "67345.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5858", "valid_best_loss": "2.549"}
[2022-06-13 06:13:19,365][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 113 @ 5858 updates
[2022-06-13 06:13:19,366][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:13:23,563][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:13:26,893][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 113 @ 5858 updates, score 2.549) (writing took 7.528487470932305 seconds)
[2022-06-13 06:13:26,894][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2022-06-13 06:13:26,894][train][INFO] - {"epoch": 113, "train_loss": "2.378", "train_ppl": "5.2", "train_wps": "20778.5", "train_ups": "0.1", "train_wpb": "212882", "train_bsz": "503.5", "train_num_updates": "5858", "train_lr": "0.0002929", "train_gnorm": "0.538", "train_loss_scale": "256", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "60340"}
[2022-06-13 06:13:26,906][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 06:13:26,909][fairseq.trainer][INFO] - begin training epoch 114
[2022-06-13 06:13:26,909][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 06:16:45,194][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 06:21:35,057][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 06:22:12,491][valid][INFO] - {"epoch": 114, "valid_loss": "2.554", "valid_ppl": "5.87", "valid_wps": "67081", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5909", "valid_best_loss": "2.549"}
[2022-06-13 06:22:12,493][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 114 @ 5909 updates
[2022-06-13 06:22:12,493][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 06:22:16,624][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 06:22:16,666][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 114 @ 5909 updates, score 2.554) (writing took 4.173829861916602 seconds)
[2022-06-13 06:22:16,667][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2022-06-13 06:22:16,668][train][INFO] - {"epoch": 114, "train_loss": "2.351", "train_ppl": "5.1", "train_wps": "20487.6", "train_ups": "0.1", "train_wpb": "212819", "train_bsz": "503.3", "train_num_updates": "5909", "train_lr": "0.00029545", "train_gnorm": "0.54", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "60870"}
[2022-06-13 06:22:16,679][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 06:22:16,682][fairseq.trainer][INFO] - begin training epoch 115
[2022-06-13 06:22:16,683][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 06:30:28,456][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 06:31:05,882][valid][INFO] - {"epoch": 115, "valid_loss": "2.525", "valid_ppl": "5.76", "valid_wps": "67199.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "5961", "valid_best_loss": "2.525"}
[2022-06-13 06:31:05,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 115 @ 5961 updates
[2022-06-13 06:31:05,884][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:31:10,064][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:31:13,758][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 115 @ 5961 updates, score 2.525) (writing took 7.874607086996548 seconds)
[2022-06-13 06:31:13,759][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2022-06-13 06:31:13,759][train][INFO] - {"epoch": 115, "train_loss": "2.342", "train_ppl": "5.07", "train_wps": "20619.9", "train_ups": "0.1", "train_wpb": "212977", "train_bsz": "503.5", "train_num_updates": "5961", "train_lr": "0.00029805", "train_gnorm": "0.54", "train_loss_scale": "256", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "61407"}
[2022-06-13 06:31:13,771][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 06:31:13,774][fairseq.trainer][INFO] - begin training epoch 116
[2022-06-13 06:31:13,775][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 06:37:23,581][train_inner][INFO] - {"epoch": 116, "update": 115.75, "loss": "2.35", "ppl": "5.1", "wps": "20609.4", "ups": "0.1", "wpb": "212580", "bsz": "503.1", "num_updates": "6000", "lr": "0.0003", "gnorm": "0.541", "loss_scale": "256", "train_wall": "1871", "gb_free": "6.1", "wall": "61777"}
[2022-06-13 06:39:24,372][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 06:40:01,809][valid][INFO] - {"epoch": 116, "valid_loss": "2.516", "valid_ppl": "5.72", "valid_wps": "67533.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6013", "valid_best_loss": "2.516"}
[2022-06-13 06:40:01,811][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 116 @ 6013 updates
[2022-06-13 06:40:01,812][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:40:06,033][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:40:09,408][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 116 @ 6013 updates, score 2.516) (writing took 7.597408271045424 seconds)
[2022-06-13 06:40:09,409][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2022-06-13 06:40:09,411][train][INFO] - {"epoch": 116, "train_loss": "2.318", "train_ppl": "4.99", "train_wps": "20664.4", "train_ups": "0.1", "train_wpb": "212864", "train_bsz": "503.5", "train_num_updates": "6013", "train_lr": "0.00030065", "train_gnorm": "0.537", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "61943"}
[2022-06-13 06:40:09,441][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 06:40:09,450][fairseq.trainer][INFO] - begin training epoch 117
[2022-06-13 06:40:09,451][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 06:48:20,238][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 06:48:57,857][valid][INFO] - {"epoch": 117, "valid_loss": "2.513", "valid_ppl": "5.71", "valid_wps": "67219.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6065", "valid_best_loss": "2.513"}
[2022-06-13 06:48:57,858][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 117 @ 6065 updates
[2022-06-13 06:48:57,859][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:49:02,080][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:49:05,556][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 117 @ 6065 updates, score 2.513) (writing took 7.69828111899551 seconds)
[2022-06-13 06:49:05,557][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2022-06-13 06:49:05,560][train][INFO] - {"epoch": 117, "train_loss": "2.304", "train_ppl": "4.94", "train_wps": "20640.2", "train_ups": "0.1", "train_wpb": "212811", "train_bsz": "503.5", "train_num_updates": "6065", "train_lr": "0.00030325", "train_gnorm": "0.545", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.3", "train_wall": "62479"}
[2022-06-13 06:49:05,586][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 06:49:05,595][fairseq.trainer][INFO] - begin training epoch 118
[2022-06-13 06:49:05,596][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 06:57:15,245][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 06:57:52,717][valid][INFO] - {"epoch": 118, "valid_loss": "2.487", "valid_ppl": "5.6", "valid_wps": "67440", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6117", "valid_best_loss": "2.487"}
[2022-06-13 06:57:52,719][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 118 @ 6117 updates
[2022-06-13 06:57:52,720][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:57:57,167][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 06:58:00,459][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 118 @ 6117 updates, score 2.487) (writing took 7.739224500954151 seconds)
[2022-06-13 06:58:00,460][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2022-06-13 06:58:00,463][train][INFO] - {"epoch": 118, "train_loss": "2.298", "train_ppl": "4.92", "train_wps": "20711.7", "train_ups": "0.1", "train_wpb": "213052", "train_bsz": "503.5", "train_num_updates": "6117", "train_lr": "0.00030585", "train_gnorm": "0.535", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "63014"}
[2022-06-13 06:58:00,485][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 06:58:00,489][fairseq.trainer][INFO] - begin training epoch 119
[2022-06-13 06:58:00,489][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 07:06:10,054][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 07:06:47,466][valid][INFO] - {"epoch": 119, "valid_loss": "2.468", "valid_ppl": "5.53", "valid_wps": "67254.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6169", "valid_best_loss": "2.468"}
[2022-06-13 07:06:47,467][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 119 @ 6169 updates
[2022-06-13 07:06:47,468][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 07:06:51,735][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 07:06:55,157][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 119 @ 6169 updates, score 2.468) (writing took 7.688997528050095 seconds)
[2022-06-13 07:06:55,157][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2022-06-13 07:06:55,159][train][INFO] - {"epoch": 119, "train_loss": "2.265", "train_ppl": "4.81", "train_wps": "20720", "train_ups": "0.1", "train_wpb": "213056", "train_bsz": "503.5", "train_num_updates": "6169", "train_lr": "0.00030845", "train_gnorm": "0.529", "train_loss_scale": "512", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "63549"}
[2022-06-13 07:06:55,175][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 07:06:55,178][fairseq.trainer][INFO] - begin training epoch 120
[2022-06-13 07:06:55,178][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 07:07:41,682][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 07:11:59,364][train_inner][INFO] - {"epoch": 120, "update": 119.615, "loss": "2.282", "ppl": "4.86", "wps": "20517.4", "ups": "0.1", "wpb": "212948", "bsz": "503.1", "num_updates": "6200", "lr": "0.00031", "gnorm": "0.538", "loss_scale": "256", "train_wall": "1877", "gb_free": "6.2", "wall": "63853"}
[2022-06-13 07:15:04,958][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 07:15:42,402][valid][INFO] - {"epoch": 120, "valid_loss": "2.479", "valid_ppl": "5.58", "valid_wps": "67053.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6220", "valid_best_loss": "2.468"}
[2022-06-13 07:15:42,404][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 6220 updates
[2022-06-13 07:15:42,405][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:15:46,486][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:15:46,545][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 120 @ 6220 updates, score 2.479) (writing took 4.1411123720463365 seconds)
[2022-06-13 07:15:46,545][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2022-06-13 07:15:46,546][train][INFO] - {"epoch": 120, "train_loss": "2.248", "train_ppl": "4.75", "train_wps": "20438.4", "train_ups": "0.1", "train_wpb": "212954", "train_bsz": "503.3", "train_num_updates": "6220", "train_lr": "0.000311", "train_gnorm": "0.539", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "64080"}
[2022-06-13 07:15:46,558][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 07:15:46,561][fairseq.trainer][INFO] - begin training epoch 121
[2022-06-13 07:15:46,562][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 07:23:57,036][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 07:24:34,473][valid][INFO] - {"epoch": 121, "valid_loss": "2.47", "valid_ppl": "5.54", "valid_wps": "67058.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6272", "valid_best_loss": "2.468"}
[2022-06-13 07:24:34,475][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 121 @ 6272 updates
[2022-06-13 07:24:34,476][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:24:38,804][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:24:38,877][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 121 @ 6272 updates, score 2.47) (writing took 4.4022558719152585 seconds)
[2022-06-13 07:24:38,878][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2022-06-13 07:24:38,880][train][INFO] - {"epoch": 121, "train_loss": "2.244", "train_ppl": "4.74", "train_wps": "20796", "train_ups": "0.1", "train_wpb": "212892", "train_bsz": "503.5", "train_num_updates": "6272", "train_lr": "0.0003136", "train_gnorm": "0.546", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "64612"}
[2022-06-13 07:24:38,896][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 07:24:38,900][fairseq.trainer][INFO] - begin training epoch 122
[2022-06-13 07:24:38,901][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 07:32:49,298][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 07:33:26,669][valid][INFO] - {"epoch": 122, "valid_loss": "2.483", "valid_ppl": "5.59", "valid_wps": "67235.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6324", "valid_best_loss": "2.468"}
[2022-06-13 07:33:26,670][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 122 @ 6324 updates
[2022-06-13 07:33:26,671][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:33:30,936][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:33:31,010][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 122 @ 6324 updates, score 2.483) (writing took 4.339270742959343 seconds)
[2022-06-13 07:33:31,010][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2022-06-13 07:33:31,012][train][INFO] - {"epoch": 122, "train_loss": "2.229", "train_ppl": "4.69", "train_wps": "20806.7", "train_ups": "0.1", "train_wpb": "212921", "train_bsz": "503.5", "train_num_updates": "6324", "train_lr": "0.0003162", "train_gnorm": "0.549", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.3", "train_wall": "65144"}
[2022-06-13 07:33:31,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 07:33:31,026][fairseq.trainer][INFO] - begin training epoch 123
[2022-06-13 07:33:31,026][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 07:41:40,859][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 07:42:18,371][valid][INFO] - {"epoch": 123, "valid_loss": "2.429", "valid_ppl": "5.38", "valid_wps": "66993.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6376", "valid_best_loss": "2.429"}
[2022-06-13 07:42:18,372][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 123 @ 6376 updates
[2022-06-13 07:42:18,373][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 07:42:22,530][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 07:42:25,811][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 123 @ 6376 updates, score 2.429) (writing took 7.438752508023754 seconds)
[2022-06-13 07:42:25,812][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2022-06-13 07:42:25,813][train][INFO] - {"epoch": 123, "train_loss": "2.215", "train_ppl": "4.64", "train_wps": "20701.8", "train_ups": "0.1", "train_wpb": "212910", "train_bsz": "503.5", "train_num_updates": "6376", "train_lr": "0.0003188", "train_gnorm": "0.542", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.3", "train_wall": "65679"}
[2022-06-13 07:42:25,843][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 07:42:25,851][fairseq.trainer][INFO] - begin training epoch 124
[2022-06-13 07:42:25,852][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 07:46:15,899][train_inner][INFO] - {"epoch": 124, "update": 123.462, "loss": "2.23", "ppl": "4.69", "wps": "20713.9", "ups": "0.1", "wpb": "212995", "bsz": "503.1", "num_updates": "6400", "lr": "0.00032", "gnorm": "0.546", "loss_scale": "256", "train_wall": "1868", "gb_free": "6.2", "wall": "65909"}
[2022-06-13 07:50:36,881][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 07:51:14,315][valid][INFO] - {"epoch": 124, "valid_loss": "2.438", "valid_ppl": "5.42", "valid_wps": "66974.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6428", "valid_best_loss": "2.429"}
[2022-06-13 07:51:14,317][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 124 @ 6428 updates
[2022-06-13 07:51:14,319][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:51:18,638][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 07:51:18,684][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 124 @ 6428 updates, score 2.438) (writing took 4.366319476976059 seconds)
[2022-06-13 07:51:18,684][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2022-06-13 07:51:18,685][train][INFO] - {"epoch": 124, "train_loss": "2.19", "train_ppl": "4.56", "train_wps": "20766.7", "train_ups": "0.1", "train_wpb": "212807", "train_bsz": "503.5", "train_num_updates": "6428", "train_lr": "0.0003214", "train_gnorm": "0.539", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "66212"}
[2022-06-13 07:51:18,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 07:51:18,700][fairseq.trainer][INFO] - begin training epoch 125
[2022-06-13 07:51:18,701][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 07:58:46,915][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 07:59:29,013][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 08:00:06,406][valid][INFO] - {"epoch": 125, "valid_loss": "2.445", "valid_ppl": "5.45", "valid_wps": "67223.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6479", "valid_best_loss": "2.429"}
[2022-06-13 08:00:06,408][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 125 @ 6479 updates
[2022-06-13 08:00:06,408][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 08:00:10,621][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 08:00:10,677][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 125 @ 6479 updates, score 2.445) (writing took 4.269075157935731 seconds)
[2022-06-13 08:00:10,677][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2022-06-13 08:00:10,678][train][INFO] - {"epoch": 125, "train_loss": "2.177", "train_ppl": "4.52", "train_wps": "20398.6", "train_ups": "0.1", "train_wpb": "212782", "train_bsz": "503.3", "train_num_updates": "6479", "train_lr": "0.00032395", "train_gnorm": "0.549", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "66744"}
[2022-06-13 08:00:10,689][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 08:00:10,693][fairseq.trainer][INFO] - begin training epoch 126
[2022-06-13 08:00:10,693][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 08:08:22,891][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 08:09:00,349][valid][INFO] - {"epoch": 126, "valid_loss": "2.445", "valid_ppl": "5.44", "valid_wps": "67269.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6531", "valid_best_loss": "2.429"}
[2022-06-13 08:09:00,351][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 126 @ 6531 updates
[2022-06-13 08:09:00,351][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 08:09:05,165][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 08:09:05,224][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 126 @ 6531 updates, score 2.445) (writing took 4.873108961968683 seconds)
[2022-06-13 08:09:05,224][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2022-06-13 08:09:05,225][train][INFO] - {"epoch": 126, "train_loss": "2.168", "train_ppl": "4.5", "train_wps": "20709.8", "train_ups": "0.1", "train_wpb": "212891", "train_bsz": "503.5", "train_num_updates": "6531", "train_lr": "0.00032655", "train_gnorm": "0.551", "train_loss_scale": "256", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "67279"}
[2022-06-13 08:09:05,236][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 08:09:05,240][fairseq.trainer][INFO] - begin training epoch 127
[2022-06-13 08:09:05,241][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 08:17:14,161][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 08:17:51,924][valid][INFO] - {"epoch": 127, "valid_loss": "2.418", "valid_ppl": "5.34", "valid_wps": "67044.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6583", "valid_best_loss": "2.418"}
[2022-06-13 08:17:51,925][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 127 @ 6583 updates
[2022-06-13 08:17:51,926][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:17:55,976][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:17:59,366][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 127 @ 6583 updates, score 2.418) (writing took 7.440477697062306 seconds)
[2022-06-13 08:17:59,367][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2022-06-13 08:17:59,369][train][INFO] - {"epoch": 127, "train_loss": "2.158", "train_ppl": "4.46", "train_wps": "20714.4", "train_ups": "0.1", "train_wpb": "212778", "train_bsz": "503.5", "train_num_updates": "6583", "train_lr": "0.00032915", "train_gnorm": "0.547", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.1", "train_wall": "67813"}
[2022-06-13 08:17:59,397][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 08:17:59,406][fairseq.trainer][INFO] - begin training epoch 128
[2022-06-13 08:17:59,407][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 08:20:39,580][train_inner][INFO] - {"epoch": 128, "update": 127.327, "loss": "2.169", "ppl": "4.5", "wps": "20572.3", "ups": "0.1", "wpb": "212274", "bsz": "503.1", "num_updates": "6600", "lr": "0.00033", "gnorm": "0.55", "loss_scale": "256", "train_wall": "1874", "gb_free": "6.2", "wall": "67973"}
[2022-06-13 08:26:09,287][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 08:26:46,817][valid][INFO] - {"epoch": 128, "valid_loss": "2.406", "valid_ppl": "5.3", "valid_wps": "67276.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6635", "valid_best_loss": "2.406"}
[2022-06-13 08:26:46,819][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 128 @ 6635 updates
[2022-06-13 08:26:46,820][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:26:50,991][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:26:54,309][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 128 @ 6635 updates, score 2.406) (writing took 7.4905238300561905 seconds)
[2022-06-13 08:26:54,310][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2022-06-13 08:26:54,312][train][INFO] - {"epoch": 128, "train_loss": "2.139", "train_ppl": "4.4", "train_wps": "20704.6", "train_ups": "0.1", "train_wpb": "212996", "train_bsz": "503.5", "train_num_updates": "6635", "train_lr": "0.00033175", "train_gnorm": "0.543", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "68348"}
[2022-06-13 08:26:54,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 08:26:54,331][fairseq.trainer][INFO] - begin training epoch 129
[2022-06-13 08:26:54,332][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 08:35:03,431][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 08:35:41,003][valid][INFO] - {"epoch": 129, "valid_loss": "2.391", "valid_ppl": "5.24", "valid_wps": "66821.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6687", "valid_best_loss": "2.391"}
[2022-06-13 08:35:41,005][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 129 @ 6687 updates
[2022-06-13 08:35:41,006][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:35:45,223][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:35:48,594][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 129 @ 6687 updates, score 2.391) (writing took 7.588617110042833 seconds)
[2022-06-13 08:35:48,595][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2022-06-13 08:35:48,596][train][INFO] - {"epoch": 129, "train_loss": "2.12", "train_ppl": "4.35", "train_wps": "20718.3", "train_ups": "0.1", "train_wpb": "212874", "train_bsz": "503.5", "train_num_updates": "6687", "train_lr": "0.00033435", "train_gnorm": "0.543", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "68882"}
[2022-06-13 08:35:48,612][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 08:35:48,615][fairseq.trainer][INFO] - begin training epoch 130
[2022-06-13 08:35:48,615][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 08:44:00,186][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 08:44:37,897][valid][INFO] - {"epoch": 130, "valid_loss": "2.416", "valid_ppl": "5.34", "valid_wps": "67173.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6739", "valid_best_loss": "2.391"}
[2022-06-13 08:44:37,898][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 6739 updates
[2022-06-13 08:44:37,899][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 08:44:42,035][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 08:44:42,114][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 130 @ 6739 updates, score 2.416) (writing took 4.215525895007886 seconds)
[2022-06-13 08:44:42,115][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2022-06-13 08:44:42,116][train][INFO] - {"epoch": 130, "train_loss": "2.115", "train_ppl": "4.33", "train_wps": "20748.2", "train_ups": "0.1", "train_wpb": "212876", "train_bsz": "503.5", "train_num_updates": "6739", "train_lr": "0.00033695", "train_gnorm": "0.546", "train_loss_scale": "512", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "69416"}
[2022-06-13 08:44:42,134][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 08:44:42,140][fairseq.trainer][INFO] - begin training epoch 131
[2022-06-13 08:44:42,141][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 08:44:51,753][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 08:47:06,041][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 08:52:53,279][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 08:53:30,646][valid][INFO] - {"epoch": 131, "valid_loss": "2.377", "valid_ppl": "5.19", "valid_wps": "67144.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6789", "valid_best_loss": "2.377"}
[2022-06-13 08:53:30,648][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 131 @ 6789 updates
[2022-06-13 08:53:30,649][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:53:34,946][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 08:53:38,347][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 131 @ 6789 updates, score 2.377) (writing took 7.699262580019422 seconds)
[2022-06-13 08:53:38,348][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2022-06-13 08:53:38,350][train][INFO] - {"epoch": 131, "train_loss": "2.102", "train_ppl": "4.29", "train_wps": "19836.4", "train_ups": "0.09", "train_wpb": "212739", "train_bsz": "503.1", "train_num_updates": "6789", "train_lr": "0.00033945", "train_gnorm": "0.563", "train_loss_scale": "128", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "69952"}
[2022-06-13 08:53:38,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 08:53:38,370][fairseq.trainer][INFO] - begin training epoch 132
[2022-06-13 08:53:38,371][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 08:55:22,300][train_inner][INFO] - {"epoch": 132, "update": 131.212, "loss": "2.116", "ppl": "4.34", "wps": "20441.9", "ups": "0.1", "wpb": "212874", "bsz": "503.1", "num_updates": "6800", "lr": "0.00034", "gnorm": "0.55", "loss_scale": "128", "train_wall": "1887", "gb_free": "6.2", "wall": "70056"}
[2022-06-13 09:01:48,244][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 09:02:25,743][valid][INFO] - {"epoch": 132, "valid_loss": "2.371", "valid_ppl": "5.17", "valid_wps": "66899.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6841", "valid_best_loss": "2.371"}
[2022-06-13 09:02:25,745][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 132 @ 6841 updates
[2022-06-13 09:02:25,746][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:02:30,051][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:02:33,534][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 132 @ 6841 updates, score 2.371) (writing took 7.789192099007778 seconds)
[2022-06-13 09:02:33,535][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2022-06-13 09:02:33,537][train][INFO] - {"epoch": 132, "train_loss": "2.093", "train_ppl": "4.27", "train_wps": "20696.4", "train_ups": "0.1", "train_wpb": "213008", "train_bsz": "503.5", "train_num_updates": "6841", "train_lr": "0.00034205", "train_gnorm": "0.541", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "70487"}
[2022-06-13 09:02:33,574][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 09:02:33,583][fairseq.trainer][INFO] - begin training epoch 133
[2022-06-13 09:02:33,584][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 09:10:43,474][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 09:11:21,030][valid][INFO] - {"epoch": 133, "valid_loss": "2.373", "valid_ppl": "5.18", "valid_wps": "66967.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6893", "valid_best_loss": "2.371"}
[2022-06-13 09:11:21,032][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 133 @ 6893 updates
[2022-06-13 09:11:21,033][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 09:11:25,194][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 09:11:25,241][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 133 @ 6893 updates, score 2.373) (writing took 4.208834882010706 seconds)
[2022-06-13 09:11:25,241][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2022-06-13 09:11:25,242][train][INFO] - {"epoch": 133, "train_loss": "2.066", "train_ppl": "4.19", "train_wps": "20812.6", "train_ups": "0.1", "train_wpb": "212811", "train_bsz": "503.5", "train_num_updates": "6893", "train_lr": "0.00034465", "train_gnorm": "0.543", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "71019"}
[2022-06-13 09:11:25,252][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 09:11:25,255][fairseq.trainer][INFO] - begin training epoch 134
[2022-06-13 09:11:25,256][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 09:19:37,172][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 09:20:14,662][valid][INFO] - {"epoch": 134, "valid_loss": "2.37", "valid_ppl": "5.17", "valid_wps": "67550", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6945", "valid_best_loss": "2.37"}
[2022-06-13 09:20:14,664][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 134 @ 6945 updates
[2022-06-13 09:20:14,665][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:20:18,641][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:20:21,989][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 134 @ 6945 updates, score 2.37) (writing took 7.324869256932288 seconds)
[2022-06-13 09:20:21,990][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2022-06-13 09:20:21,991][train][INFO] - {"epoch": 134, "train_loss": "2.06", "train_ppl": "4.17", "train_wps": "20625.4", "train_ups": "0.1", "train_wpb": "212897", "train_bsz": "503.5", "train_num_updates": "6945", "train_lr": "0.00034725", "train_gnorm": "0.544", "train_loss_scale": "128", "train_train_wall": "488", "train_gb_free": "6.1", "train_wall": "71555"}
[2022-06-13 09:20:22,022][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 09:20:22,031][fairseq.trainer][INFO] - begin training epoch 135
[2022-06-13 09:20:22,032][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 09:28:32,804][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 09:29:10,387][valid][INFO] - {"epoch": 135, "valid_loss": "2.367", "valid_ppl": "5.16", "valid_wps": "66849.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "6997", "valid_best_loss": "2.367"}
[2022-06-13 09:29:10,388][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 135 @ 6997 updates
[2022-06-13 09:29:10,389][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:29:14,476][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:29:17,859][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 135 @ 6997 updates, score 2.367) (writing took 7.470581945031881 seconds)
[2022-06-13 09:29:17,860][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2022-06-13 09:29:17,861][train][INFO] - {"epoch": 135, "train_loss": "2.043", "train_ppl": "4.12", "train_wps": "20655.2", "train_ups": "0.1", "train_wpb": "212856", "train_bsz": "503.5", "train_num_updates": "6997", "train_lr": "0.00034985", "train_gnorm": "0.553", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "72091"}
[2022-06-13 09:29:17,887][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 09:29:17,896][fairseq.trainer][INFO] - begin training epoch 136
[2022-06-13 09:29:17,897][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 09:29:46,065][train_inner][INFO] - {"epoch": 136, "update": 135.058, "loss": "2.062", "ppl": "4.17", "wps": "20623.9", "ups": "0.1", "wpb": "212814", "bsz": "503.1", "num_updates": "7000", "lr": "0.00035", "gnorm": "0.546", "loss_scale": "128", "train_wall": "1869", "gb_free": "6.2", "wall": "72119"}
[2022-06-13 09:37:26,832][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 09:38:04,389][valid][INFO] - {"epoch": 136, "valid_loss": "2.374", "valid_ppl": "5.18", "valid_wps": "67001.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7049", "valid_best_loss": "2.367"}
[2022-06-13 09:38:04,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 136 @ 7049 updates
[2022-06-13 09:38:04,391][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 09:38:08,458][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 09:38:08,518][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 136 @ 7049 updates, score 2.374) (writing took 4.127558969077654 seconds)
[2022-06-13 09:38:08,518][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2022-06-13 09:38:08,519][train][INFO] - {"epoch": 136, "train_loss": "2.044", "train_ppl": "4.12", "train_wps": "20865.5", "train_ups": "0.1", "train_wpb": "212931", "train_bsz": "503.5", "train_num_updates": "7049", "train_lr": "0.00035245", "train_gnorm": "0.543", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "72622"}
[2022-06-13 09:38:08,532][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 09:38:08,535][fairseq.trainer][INFO] - begin training epoch 137
[2022-06-13 09:38:08,536][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 09:46:22,096][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 09:46:59,884][valid][INFO] - {"epoch": 137, "valid_loss": "2.369", "valid_ppl": "5.16", "valid_wps": "67113.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7101", "valid_best_loss": "2.367"}
[2022-06-13 09:46:59,885][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 137 @ 7101 updates
[2022-06-13 09:46:59,886][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 09:47:04,129][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 09:47:04,188][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 137 @ 7101 updates, score 2.369) (writing took 4.302664528018795 seconds)
[2022-06-13 09:47:04,189][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2022-06-13 09:47:04,190][train][INFO] - {"epoch": 137, "train_loss": "2.022", "train_ppl": "4.06", "train_wps": "20660.9", "train_ups": "0.1", "train_wpb": "212836", "train_bsz": "503.5", "train_num_updates": "7101", "train_lr": "0.00035505", "train_gnorm": "0.554", "train_loss_scale": "256", "train_train_wall": "489", "train_gb_free": "6.2", "train_wall": "73158"}
[2022-06-13 09:47:04,202][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 09:47:04,205][fairseq.trainer][INFO] - begin training epoch 138
[2022-06-13 09:47:04,205][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 09:55:13,349][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 09:55:50,846][valid][INFO] - {"epoch": 138, "valid_loss": "2.35", "valid_ppl": "5.1", "valid_wps": "66914.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7153", "valid_best_loss": "2.35"}
[2022-06-13 09:55:50,847][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 138 @ 7153 updates
[2022-06-13 09:55:50,848][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:55:54,805][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 09:55:58,023][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 138 @ 7153 updates, score 2.35) (writing took 7.176057863980532 seconds)
[2022-06-13 09:55:58,024][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2022-06-13 09:55:58,026][train][INFO] - {"epoch": 138, "train_loss": "2.019", "train_ppl": "4.05", "train_wps": "20740.7", "train_ups": "0.1", "train_wpb": "212925", "train_bsz": "503.5", "train_num_updates": "7153", "train_lr": "0.00035765", "train_gnorm": "0.558", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "73691"}
[2022-06-13 09:55:58,054][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 09:55:58,063][fairseq.trainer][INFO] - begin training epoch 139
[2022-06-13 09:55:58,064][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 10:03:21,628][train_inner][INFO] - {"epoch": 139, "update": 138.904, "loss": "2.022", "ppl": "4.06", "wps": "21206.6", "ups": "0.1", "wpb": "213716", "bsz": "505.3", "num_updates": "7200", "lr": "0.00036", "gnorm": "0.542", "loss_scale": "256", "train_wall": "1871", "gb_free": "6.2", "wall": "74135"}
[2022-06-13 10:04:04,333][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 10:04:41,998][valid][INFO] - {"epoch": 139, "valid_loss": "2.342", "valid_ppl": "5.07", "valid_wps": "66739.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7205", "valid_best_loss": "2.342"}
[2022-06-13 10:04:42,000][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 139 @ 7205 updates
[2022-06-13 10:04:42,001][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:04:46,223][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:04:49,724][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 139 @ 7205 updates, score 2.342) (writing took 7.7241861439542845 seconds)
[2022-06-13 10:04:49,725][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2022-06-13 10:04:49,727][train][INFO] - {"epoch": 139, "train_loss": "2.005", "train_ppl": "4.02", "train_wps": "20827.6", "train_ups": "0.1", "train_wpb": "212962", "train_bsz": "503.5", "train_num_updates": "7205", "train_lr": "0.00036025", "train_gnorm": "0.555", "train_loss_scale": "256", "train_train_wall": "482", "train_gb_free": "6.2", "train_wall": "74223"}
[2022-06-13 10:04:49,754][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 10:04:49,762][fairseq.trainer][INFO] - begin training epoch 140
[2022-06-13 10:04:49,764][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 10:12:57,557][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 10:13:35,225][valid][INFO] - {"epoch": 140, "valid_loss": "2.327", "valid_ppl": "5.02", "valid_wps": "67021.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7257", "valid_best_loss": "2.327"}
[2022-06-13 10:13:35,227][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 7257 updates
[2022-06-13 10:13:35,228][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:13:39,411][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:13:42,690][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 140 @ 7257 updates, score 2.327) (writing took 7.462398506002501 seconds)
[2022-06-13 10:13:42,690][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2022-06-13 10:13:42,692][train][INFO] - {"epoch": 140, "train_loss": "2", "train_ppl": "4", "train_wps": "20774.1", "train_ups": "0.1", "train_wpb": "212920", "train_bsz": "503.5", "train_num_updates": "7257", "train_lr": "0.00036285", "train_gnorm": "0.55", "train_loss_scale": "256", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "74756"}
[2022-06-13 10:13:42,720][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 10:13:42,729][fairseq.trainer][INFO] - begin training epoch 141
[2022-06-13 10:13:42,730][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 10:15:44,579][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 10:21:49,969][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 10:22:27,356][valid][INFO] - {"epoch": 141, "valid_loss": "2.367", "valid_ppl": "5.16", "valid_wps": "67155.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7308", "valid_best_loss": "2.327"}
[2022-06-13 10:22:27,357][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 141 @ 7308 updates
[2022-06-13 10:22:27,358][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 10:22:31,477][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 10:22:31,547][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 141 @ 7308 updates, score 2.367) (writing took 4.189671250991523 seconds)
[2022-06-13 10:22:31,547][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2022-06-13 10:22:31,549][train][INFO] - {"epoch": 141, "train_loss": "1.98", "train_ppl": "3.94", "train_wps": "20500.3", "train_ups": "0.1", "train_wpb": "212582", "train_bsz": "503.3", "train_num_updates": "7308", "train_lr": "0.0003654", "train_gnorm": "0.559", "train_loss_scale": "256", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "75285"}
[2022-06-13 10:22:31,565][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 10:22:31,570][fairseq.trainer][INFO] - begin training epoch 142
[2022-06-13 10:22:31,571][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 10:30:40,248][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 10:31:17,849][valid][INFO] - {"epoch": 142, "valid_loss": "2.332", "valid_ppl": "5.03", "valid_wps": "66919.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7360", "valid_best_loss": "2.327"}
[2022-06-13 10:31:17,851][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 142 @ 7360 updates
[2022-06-13 10:31:17,852][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 10:31:21,936][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 10:31:22,018][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 142 @ 7360 updates, score 2.332) (writing took 4.167428679065779 seconds)
[2022-06-13 10:31:22,019][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2022-06-13 10:31:22,020][train][INFO] - {"epoch": 142, "train_loss": "1.975", "train_ppl": "3.93", "train_wps": "20872.2", "train_ups": "0.1", "train_wpb": "212925", "train_bsz": "503.5", "train_num_updates": "7360", "train_lr": "0.000368", "train_gnorm": "0.569", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "75815"}
[2022-06-13 10:31:22,038][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 10:31:22,044][fairseq.trainer][INFO] - begin training epoch 143
[2022-06-13 10:31:22,045][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 10:37:41,779][train_inner][INFO] - {"epoch": 143, "update": 142.769, "loss": "1.983", "ppl": "3.95", "wps": "20656.9", "ups": "0.1", "wpb": "212782", "bsz": "503.1", "num_updates": "7400", "lr": "0.00037", "gnorm": "0.562", "loss_scale": "256", "train_wall": "1868", "gb_free": "6.2", "wall": "76195"}
[2022-06-13 10:39:31,628][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 10:40:09,245][valid][INFO] - {"epoch": 143, "valid_loss": "2.302", "valid_ppl": "4.93", "valid_wps": "67494.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7412", "valid_best_loss": "2.302"}
[2022-06-13 10:40:09,246][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 143 @ 7412 updates
[2022-06-13 10:40:09,247][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:40:13,518][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:40:17,177][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 143 @ 7412 updates, score 2.302) (writing took 7.930201072944328 seconds)
[2022-06-13 10:40:17,177][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2022-06-13 10:40:17,179][train][INFO] - {"epoch": 143, "train_loss": "1.967", "train_ppl": "3.91", "train_wps": "20693.9", "train_ups": "0.1", "train_wpb": "212971", "train_bsz": "503.5", "train_num_updates": "7412", "train_lr": "0.0003706", "train_gnorm": "0.551", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "76351"}
[2022-06-13 10:40:17,209][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 10:40:17,218][fairseq.trainer][INFO] - begin training epoch 144
[2022-06-13 10:40:17,219][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 10:48:25,475][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 10:49:02,978][valid][INFO] - {"epoch": 144, "valid_loss": "2.309", "valid_ppl": "4.96", "valid_wps": "67013.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7464", "valid_best_loss": "2.302"}
[2022-06-13 10:49:02,979][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 144 @ 7464 updates
[2022-06-13 10:49:02,980][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 10:49:07,122][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 10:49:07,168][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 144 @ 7464 updates, score 2.309) (writing took 4.188101246021688 seconds)
[2022-06-13 10:49:07,168][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2022-06-13 10:49:07,169][train][INFO] - {"epoch": 144, "train_loss": "1.942", "train_ppl": "3.84", "train_wps": "20881.4", "train_ups": "0.1", "train_wpb": "212826", "train_bsz": "503.5", "train_num_updates": "7464", "train_lr": "0.0003732", "train_gnorm": "0.554", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "76881"}
[2022-06-13 10:49:07,179][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 10:49:07,182][fairseq.trainer][INFO] - begin training epoch 145
[2022-06-13 10:49:07,183][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 10:57:15,952][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 10:57:53,213][valid][INFO] - {"epoch": 145, "valid_loss": "2.302", "valid_ppl": "4.93", "valid_wps": "67492.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7516", "valid_best_loss": "2.302"}
[2022-06-13 10:57:53,215][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 145 @ 7516 updates
[2022-06-13 10:57:53,216][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:57:57,453][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 10:58:00,956][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 145 @ 7516 updates, score 2.302) (writing took 7.741268949932419 seconds)
[2022-06-13 10:58:00,957][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2022-06-13 10:58:00,959][train][INFO] - {"epoch": 145, "train_loss": "1.938", "train_ppl": "3.83", "train_wps": "20749.3", "train_ups": "0.1", "train_wpb": "212996", "train_bsz": "503.5", "train_num_updates": "7516", "train_lr": "0.0003758", "train_gnorm": "0.548", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "77414"}
[2022-06-13 10:58:00,986][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 10:58:00,994][fairseq.trainer][INFO] - begin training epoch 146
[2022-06-13 10:58:00,996][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 11:00:12,502][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 11:06:09,144][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 11:06:46,830][valid][INFO] - {"epoch": 146, "valid_loss": "2.315", "valid_ppl": "4.98", "valid_wps": "67285.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7567", "valid_best_loss": "2.302"}
[2022-06-13 11:06:46,832][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 146 @ 7567 updates
[2022-06-13 11:06:46,833][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 11:06:51,003][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 11:06:51,042][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 146 @ 7567 updates, score 2.315) (writing took 4.209684913977981 seconds)
[2022-06-13 11:06:51,042][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2022-06-13 11:06:51,043][train][INFO] - {"epoch": 146, "train_loss": "1.913", "train_ppl": "3.77", "train_wps": "20483.8", "train_ups": "0.1", "train_wpb": "212904", "train_bsz": "503.3", "train_num_updates": "7567", "train_lr": "0.00037835", "train_gnorm": "0.557", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "77944"}
[2022-06-13 11:06:51,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 11:06:51,056][fairseq.trainer][INFO] - begin training epoch 147
[2022-06-13 11:06:51,056][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 11:12:04,192][train_inner][INFO] - {"epoch": 147, "update": 146.635, "loss": "1.932", "ppl": "3.82", "wps": "20634.5", "ups": "0.1", "wpb": "212784", "bsz": "503.1", "num_updates": "7600", "lr": "0.00038", "gnorm": "0.556", "loss_scale": "256", "train_wall": "1870", "gb_free": "6.2", "wall": "78258"}
[2022-06-13 11:14:59,935][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 11:15:37,270][valid][INFO] - {"epoch": 147, "valid_loss": "2.3", "valid_ppl": "4.93", "valid_wps": "67291.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7619", "valid_best_loss": "2.3"}
[2022-06-13 11:15:37,272][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 147 @ 7619 updates
[2022-06-13 11:15:37,273][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 11:15:41,531][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 11:15:44,777][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 147 @ 7619 updates, score 2.3) (writing took 7.504917767946608 seconds)
[2022-06-13 11:15:44,777][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2022-06-13 11:15:44,779][train][INFO] - {"epoch": 147, "train_loss": "1.921", "train_ppl": "3.79", "train_wps": "20762.8", "train_ups": "0.1", "train_wpb": "213112", "train_bsz": "503.5", "train_num_updates": "7619", "train_lr": "0.00038095", "train_gnorm": "0.559", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "78478"}
[2022-06-13 11:15:44,809][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 11:15:44,818][fairseq.trainer][INFO] - begin training epoch 148
[2022-06-13 11:15:44,819][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 11:23:55,044][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 11:24:32,671][valid][INFO] - {"epoch": 148, "valid_loss": "2.309", "valid_ppl": "4.96", "valid_wps": "67003.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7671", "valid_best_loss": "2.3"}
[2022-06-13 11:24:32,673][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 148 @ 7671 updates
[2022-06-13 11:24:32,673][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 11:24:37,412][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 11:24:37,456][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 148 @ 7671 updates, score 2.309) (writing took 4.783379171043634 seconds)
[2022-06-13 11:24:37,457][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2022-06-13 11:24:37,457][train][INFO] - {"epoch": 148, "train_loss": "1.901", "train_ppl": "3.73", "train_wps": "20779.9", "train_ups": "0.1", "train_wpb": "212865", "train_bsz": "503.5", "train_num_updates": "7671", "train_lr": "0.00038355", "train_gnorm": "0.557", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "79011"}
[2022-06-13 11:24:37,469][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 11:24:37,472][fairseq.trainer][INFO] - begin training epoch 149
[2022-06-13 11:24:37,473][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 11:32:45,951][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 11:33:23,334][valid][INFO] - {"epoch": 149, "valid_loss": "2.298", "valid_ppl": "4.92", "valid_wps": "67215.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7723", "valid_best_loss": "2.298"}
[2022-06-13 11:33:23,335][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 149 @ 7723 updates
[2022-06-13 11:33:23,336][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 11:33:27,648][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 11:33:31,174][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 149 @ 7723 updates, score 2.298) (writing took 7.838892069994472 seconds)
[2022-06-13 11:33:31,175][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2022-06-13 11:33:31,176][train][INFO] - {"epoch": 149, "train_loss": "1.9", "train_ppl": "3.73", "train_wps": "20739.2", "train_ups": "0.1", "train_wpb": "212863", "train_bsz": "503.5", "train_num_updates": "7723", "train_lr": "0.00038615", "train_gnorm": "0.561", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "79545"}
[2022-06-13 11:33:31,188][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 11:33:31,192][fairseq.trainer][INFO] - begin training epoch 150
[2022-06-13 11:33:31,192][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 11:41:40,308][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 11:42:17,784][valid][INFO] - {"epoch": 150, "valid_loss": "2.287", "valid_ppl": "4.88", "valid_wps": "66940.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7775", "valid_best_loss": "2.287"}
[2022-06-13 11:42:17,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 150 @ 7775 updates
[2022-06-13 11:42:17,787][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 11:42:22,091][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 11:42:25,378][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 150 @ 7775 updates, score 2.287) (writing took 7.592489780043252 seconds)
[2022-06-13 11:42:25,379][fairseq_cli.train][INFO] - end of epoch 150 (average epoch stats below)
[2022-06-13 11:42:25,381][train][INFO] - {"epoch": 150, "train_loss": "1.893", "train_ppl": "3.71", "train_wps": "20726.2", "train_ups": "0.1", "train_wpb": "212923", "train_bsz": "503.5", "train_num_updates": "7775", "train_lr": "0.00038875", "train_gnorm": "0.568", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "80079"}
[2022-06-13 11:42:25,411][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 11:42:25,420][fairseq.trainer][INFO] - begin training epoch 151
[2022-06-13 11:42:25,421][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 11:45:25,528][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2022-06-13 11:46:31,888][train_inner][INFO] - {"epoch": 151, "update": 150.5, "loss": "1.899", "ppl": "3.73", "wps": "20590.8", "ups": "0.1", "wpb": "212877", "bsz": "503.1", "num_updates": "7800", "lr": "0.00039", "gnorm": "0.563", "loss_scale": "256", "train_wall": "1872", "gb_free": "6.2", "wall": "80325"}
[2022-06-13 11:50:32,508][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 11:51:10,105][valid][INFO] - {"epoch": 151, "valid_loss": "2.295", "valid_ppl": "4.91", "valid_wps": "67361.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7826", "valid_best_loss": "2.287"}
[2022-06-13 11:51:10,107][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 151 @ 7826 updates
[2022-06-13 11:51:10,107][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 11:51:14,424][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 11:51:14,522][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 151 @ 7826 updates, score 2.295) (writing took 4.415039933985099 seconds)
[2022-06-13 11:51:14,522][fairseq_cli.train][INFO] - end of epoch 151 (average epoch stats below)
[2022-06-13 11:51:14,524][train][INFO] - {"epoch": 151, "train_loss": "1.886", "train_ppl": "3.7", "train_wps": "20514.3", "train_ups": "0.1", "train_wpb": "212843", "train_bsz": "503.3", "train_num_updates": "7826", "train_lr": "0.0003913", "train_gnorm": "0.565", "train_loss_scale": "256", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "80608"}
[2022-06-13 11:51:14,547][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 11:51:14,555][fairseq.trainer][INFO] - begin training epoch 152
[2022-06-13 11:51:14,556][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 11:59:22,866][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 12:00:00,231][valid][INFO] - {"epoch": 152, "valid_loss": "2.278", "valid_ppl": "4.85", "valid_wps": "67353.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7878", "valid_best_loss": "2.278"}
[2022-06-13 12:00:00,232][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 152 @ 7878 updates
[2022-06-13 12:00:00,233][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:00:04,454][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:00:07,742][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 152 @ 7878 updates, score 2.278) (writing took 7.509056893060915 seconds)
[2022-06-13 12:00:07,742][fairseq_cli.train][INFO] - end of epoch 152 (average epoch stats below)
[2022-06-13 12:00:07,744][train][INFO] - {"epoch": 152, "train_loss": "1.87", "train_ppl": "3.66", "train_wps": "20768.1", "train_ups": "0.1", "train_wpb": "212961", "train_bsz": "503.5", "train_num_updates": "7878", "train_lr": "0.0003939", "train_gnorm": "0.559", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.1", "train_wall": "81141"}
[2022-06-13 12:00:07,775][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 12:00:07,783][fairseq.trainer][INFO] - begin training epoch 153
[2022-06-13 12:00:07,785][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 12:08:18,440][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 12:08:55,881][valid][INFO] - {"epoch": 153, "valid_loss": "2.266", "valid_ppl": "4.81", "valid_wps": "67267.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7930", "valid_best_loss": "2.266"}
[2022-06-13 12:08:55,883][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 153 @ 7930 updates
[2022-06-13 12:08:55,884][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:09:00,019][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:09:03,356][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 153 @ 7930 updates, score 2.266) (writing took 7.473142053000629 seconds)
[2022-06-13 12:09:03,357][fairseq_cli.train][INFO] - end of epoch 153 (average epoch stats below)
[2022-06-13 12:09:03,358][train][INFO] - {"epoch": 153, "train_loss": "1.857", "train_ppl": "3.62", "train_wps": "20676", "train_ups": "0.1", "train_wpb": "212968", "train_bsz": "503.5", "train_num_updates": "7930", "train_lr": "0.0003965", "train_gnorm": "0.557", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.1", "train_wall": "81677"}
[2022-06-13 12:09:03,390][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 12:09:03,398][fairseq.trainer][INFO] - begin training epoch 154
[2022-06-13 12:09:03,400][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 12:09:30,218][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 12:17:13,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 12:17:51,121][valid][INFO] - {"epoch": 154, "valid_loss": "2.276", "valid_ppl": "4.84", "valid_wps": "67233", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "7981", "valid_best_loss": "2.266"}
[2022-06-13 12:17:51,123][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 154 @ 7981 updates
[2022-06-13 12:17:51,124][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 12:17:55,523][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 12:17:55,621][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 154 @ 7981 updates, score 2.276) (writing took 4.497952930978499 seconds)
[2022-06-13 12:17:55,622][fairseq_cli.train][INFO] - end of epoch 154 (average epoch stats below)
[2022-06-13 12:17:55,624][train][INFO] - {"epoch": 154, "train_loss": "1.851", "train_ppl": "3.61", "train_wps": "20401.3", "train_ups": "0.1", "train_wpb": "212919", "train_bsz": "503.3", "train_num_updates": "7981", "train_lr": "0.00039905", "train_gnorm": "0.562", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "82209"}
[2022-06-13 12:17:55,650][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 12:17:55,658][fairseq.trainer][INFO] - begin training epoch 155
[2022-06-13 12:17:55,659][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 12:20:57,487][train_inner][INFO] - {"epoch": 155, "update": 154.365, "loss": "1.863", "ppl": "3.64", "wps": "20594.9", "ups": "0.1", "wpb": "212704", "bsz": "503.1", "num_updates": "8000", "lr": "0.0004", "gnorm": "0.562", "loss_scale": "128", "train_wall": "1874", "gb_free": "6.2", "wall": "82391"}
[2022-06-13 12:26:06,678][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 12:26:44,182][valid][INFO] - {"epoch": 155, "valid_loss": "2.269", "valid_ppl": "4.82", "valid_wps": "67025.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8033", "valid_best_loss": "2.266"}
[2022-06-13 12:26:44,184][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 155 @ 8033 updates
[2022-06-13 12:26:44,185][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 12:26:48,369][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 12:26:48,427][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 155 @ 8033 updates, score 2.269) (writing took 4.243429330992512 seconds)
[2022-06-13 12:26:48,428][fairseq_cli.train][INFO] - end of epoch 155 (average epoch stats below)
[2022-06-13 12:26:48,429][train][INFO] - {"epoch": 155, "train_loss": "1.848", "train_ppl": "3.6", "train_wps": "20761.3", "train_ups": "0.1", "train_wpb": "212726", "train_bsz": "503.5", "train_num_updates": "8033", "train_lr": "0.00040165", "train_gnorm": "0.562", "train_loss_scale": "128", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "82742"}
[2022-06-13 12:26:48,440][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 12:26:48,444][fairseq.trainer][INFO] - begin training epoch 156
[2022-06-13 12:26:48,444][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 12:35:00,153][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 12:35:37,368][valid][INFO] - {"epoch": 156, "valid_loss": "2.261", "valid_ppl": "4.79", "valid_wps": "67502.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8085", "valid_best_loss": "2.261"}
[2022-06-13 12:35:37,370][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 156 @ 8085 updates
[2022-06-13 12:35:37,370][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:35:41,607][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:35:45,055][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 156 @ 8085 updates, score 2.261) (writing took 7.685647908016108 seconds)
[2022-06-13 12:35:45,056][fairseq_cli.train][INFO] - end of epoch 156 (average epoch stats below)
[2022-06-13 12:35:45,058][train][INFO] - {"epoch": 156, "train_loss": "1.833", "train_ppl": "3.56", "train_wps": "20630.9", "train_ups": "0.1", "train_wpb": "212906", "train_bsz": "503.5", "train_num_updates": "8085", "train_lr": "0.00040425", "train_gnorm": "0.563", "train_loss_scale": "128", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "83278"}
[2022-06-13 12:35:45,079][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 12:35:45,083][fairseq.trainer][INFO] - begin training epoch 157
[2022-06-13 12:35:45,083][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 12:43:52,370][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 12:44:30,119][valid][INFO] - {"epoch": 157, "valid_loss": "2.265", "valid_ppl": "4.81", "valid_wps": "66443.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8137", "valid_best_loss": "2.261"}
[2022-06-13 12:44:30,120][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 157 @ 8137 updates
[2022-06-13 12:44:30,121][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 12:44:34,204][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 12:44:34,249][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 157 @ 8137 updates, score 2.265) (writing took 4.1287573230220005 seconds)
[2022-06-13 12:44:34,249][fairseq_cli.train][INFO] - end of epoch 157 (average epoch stats below)
[2022-06-13 12:44:34,250][train][INFO] - {"epoch": 157, "train_loss": "1.825", "train_ppl": "3.54", "train_wps": "20914.2", "train_ups": "0.1", "train_wpb": "212840", "train_bsz": "503.5", "train_num_updates": "8137", "train_lr": "0.00040685", "train_gnorm": "0.568", "train_loss_scale": "128", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "83808"}
[2022-06-13 12:44:34,263][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 12:44:34,266][fairseq.trainer][INFO] - begin training epoch 158
[2022-06-13 12:44:34,266][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 12:52:45,491][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 12:53:23,387][valid][INFO] - {"epoch": 158, "valid_loss": "2.255", "valid_ppl": "4.77", "valid_wps": "66640.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8189", "valid_best_loss": "2.255"}
[2022-06-13 12:53:23,389][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 158 @ 8189 updates
[2022-06-13 12:53:23,389][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:53:27,446][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 12:53:30,950][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 158 @ 8189 updates, score 2.255) (writing took 7.560865441104397 seconds)
[2022-06-13 12:53:30,951][fairseq_cli.train][INFO] - end of epoch 158 (average epoch stats below)
[2022-06-13 12:53:30,952][train][INFO] - {"epoch": 158, "train_loss": "1.818", "train_ppl": "3.53", "train_wps": "20631.5", "train_ups": "0.1", "train_wpb": "212941", "train_bsz": "503.5", "train_num_updates": "8189", "train_lr": "0.00040945", "train_gnorm": "0.574", "train_loss_scale": "256", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "84344"}
[2022-06-13 12:53:30,965][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 12:53:30,969][fairseq.trainer][INFO] - begin training epoch 159
[2022-06-13 12:53:30,969][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 12:55:14,887][train_inner][INFO] - {"epoch": 159, "update": 158.212, "loss": "1.827", "ppl": "3.55", "wps": "20676.3", "ups": "0.1", "wpb": "212698", "bsz": "503.1", "num_updates": "8200", "lr": "0.00041", "gnorm": "0.569", "loss_scale": "256", "train_wall": "1865", "gb_free": "6.2", "wall": "84448"}
[2022-06-13 13:01:41,800][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 13:02:19,227][valid][INFO] - {"epoch": 159, "valid_loss": "2.254", "valid_ppl": "4.77", "valid_wps": "67079.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8241", "valid_best_loss": "2.254"}
[2022-06-13 13:02:19,228][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 159 @ 8241 updates
[2022-06-13 13:02:19,229][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:02:23,328][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:02:27,283][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 159 @ 8241 updates, score 2.254) (writing took 8.05441480805166 seconds)
[2022-06-13 13:02:27,284][fairseq_cli.train][INFO] - end of epoch 159 (average epoch stats below)
[2022-06-13 13:02:27,285][train][INFO] - {"epoch": 159, "train_loss": "1.815", "train_ppl": "3.52", "train_wps": "20637.2", "train_ups": "0.1", "train_wpb": "212854", "train_bsz": "503.5", "train_num_updates": "8241", "train_lr": "0.00041205", "train_gnorm": "0.562", "train_loss_scale": "256", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "84881"}
[2022-06-13 13:02:27,304][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 13:02:27,308][fairseq.trainer][INFO] - begin training epoch 160
[2022-06-13 13:02:27,308][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 13:10:39,458][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 13:11:16,895][valid][INFO] - {"epoch": 160, "valid_loss": "2.248", "valid_ppl": "4.75", "valid_wps": "67263.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8293", "valid_best_loss": "2.248"}
[2022-06-13 13:11:16,897][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 160 @ 8293 updates
[2022-06-13 13:11:16,898][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:11:21,091][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:11:24,755][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 160 @ 8293 updates, score 2.248) (writing took 7.857400247012265 seconds)
[2022-06-13 13:11:24,755][fairseq_cli.train][INFO] - end of epoch 160 (average epoch stats below)
[2022-06-13 13:11:24,757][train][INFO] - {"epoch": 160, "train_loss": "1.801", "train_ppl": "3.48", "train_wps": "20599.2", "train_ups": "0.1", "train_wpb": "212913", "train_bsz": "503.5", "train_num_updates": "8293", "train_lr": "0.00041465", "train_gnorm": "0.566", "train_loss_scale": "256", "train_train_wall": "488", "train_gb_free": "6.2", "train_wall": "85418"}
[2022-06-13 13:11:24,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 13:11:24,794][fairseq.trainer][INFO] - begin training epoch 161
[2022-06-13 13:11:24,795][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 13:19:34,500][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 13:20:12,132][valid][INFO] - {"epoch": 161, "valid_loss": "2.247", "valid_ppl": "4.75", "valid_wps": "67351.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8345", "valid_best_loss": "2.247"}
[2022-06-13 13:20:12,134][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 161 @ 8345 updates
[2022-06-13 13:20:12,134][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:20:16,205][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:20:19,853][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 161 @ 8345 updates, score 2.247) (writing took 7.719839695957489 seconds)
[2022-06-13 13:20:19,854][fairseq_cli.train][INFO] - end of epoch 161 (average epoch stats below)
[2022-06-13 13:20:19,856][train][INFO] - {"epoch": 161, "train_loss": "1.796", "train_ppl": "3.47", "train_wps": "20685", "train_ups": "0.1", "train_wpb": "212855", "train_bsz": "503.5", "train_num_updates": "8345", "train_lr": "0.00041725", "train_gnorm": "0.57", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "85953"}
[2022-06-13 13:20:19,883][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 13:20:19,891][fairseq.trainer][INFO] - begin training epoch 162
[2022-06-13 13:20:19,892][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 13:23:08,162][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 13:28:30,093][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 13:29:07,826][valid][INFO] - {"epoch": 162, "valid_loss": "2.26", "valid_ppl": "4.79", "valid_wps": "67152", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8396", "valid_best_loss": "2.247"}
[2022-06-13 13:29:07,828][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 162 @ 8396 updates
[2022-06-13 13:29:07,828][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 13:29:11,891][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 13:29:11,930][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 162 @ 8396 updates, score 2.26) (writing took 4.1019127540057525 seconds)
[2022-06-13 13:29:11,930][fairseq_cli.train][INFO] - end of epoch 162 (average epoch stats below)
[2022-06-13 13:29:11,931][train][INFO] - {"epoch": 162, "train_loss": "1.792", "train_ppl": "3.46", "train_wps": "20395.6", "train_ups": "0.1", "train_wpb": "212784", "train_bsz": "503.3", "train_num_updates": "8396", "train_lr": "0.0004198", "train_gnorm": "0.574", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "86485"}
[2022-06-13 13:29:11,943][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 13:29:11,945][fairseq.trainer][INFO] - begin training epoch 163
[2022-06-13 13:29:11,946][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 13:29:49,017][train_inner][INFO] - {"epoch": 163, "update": 162.077, "loss": "1.799", "ppl": "3.48", "wps": "20510.5", "ups": "0.1", "wpb": "212707", "bsz": "503.1", "num_updates": "8400", "lr": "0.00042", "gnorm": "0.569", "loss_scale": "128", "train_wall": "1879", "gb_free": "6.2", "wall": "86522"}
[2022-06-13 13:37:21,079][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 13:37:58,730][valid][INFO] - {"epoch": 163, "valid_loss": "2.253", "valid_ppl": "4.77", "valid_wps": "67286.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8448", "valid_best_loss": "2.247"}
[2022-06-13 13:37:58,731][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 163 @ 8448 updates
[2022-06-13 13:37:58,732][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 13:38:02,922][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 13:38:02,977][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 163 @ 8448 updates, score 2.253) (writing took 4.245632719015703 seconds)
[2022-06-13 13:38:02,977][fairseq_cli.train][INFO] - end of epoch 163 (average epoch stats below)
[2022-06-13 13:38:02,978][train][INFO] - {"epoch": 163, "train_loss": "1.776", "train_ppl": "3.42", "train_wps": "20857.7", "train_ups": "0.1", "train_wpb": "213008", "train_bsz": "503.5", "train_num_updates": "8448", "train_lr": "0.0004224", "train_gnorm": "0.567", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.3", "train_wall": "87016"}
[2022-06-13 13:38:02,987][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 13:38:02,990][fairseq.trainer][INFO] - begin training epoch 164
[2022-06-13 13:38:02,990][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 13:46:14,488][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 13:46:52,254][valid][INFO] - {"epoch": 164, "valid_loss": "2.253", "valid_ppl": "4.77", "valid_wps": "66920.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8500", "valid_best_loss": "2.247"}
[2022-06-13 13:46:52,256][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 164 @ 8500 updates
[2022-06-13 13:46:52,257][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 13:46:56,403][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 13:46:56,461][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 164 @ 8500 updates, score 2.253) (writing took 4.204740591929294 seconds)
[2022-06-13 13:46:56,461][fairseq_cli.train][INFO] - end of epoch 164 (average epoch stats below)
[2022-06-13 13:46:56,462][train][INFO] - {"epoch": 164, "train_loss": "1.776", "train_ppl": "3.42", "train_wps": "20747.2", "train_ups": "0.1", "train_wpb": "212852", "train_bsz": "503.5", "train_num_updates": "8500", "train_lr": "0.000425", "train_gnorm": "0.582", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.4", "train_wall": "87550"}
[2022-06-13 13:46:56,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 13:46:56,484][fairseq.trainer][INFO] - begin training epoch 165
[2022-06-13 13:46:56,484][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 13:55:06,147][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 13:55:43,675][valid][INFO] - {"epoch": 165, "valid_loss": "2.231", "valid_ppl": "4.69", "valid_wps": "66887.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8552", "valid_best_loss": "2.231"}
[2022-06-13 13:55:43,676][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 165 @ 8552 updates
[2022-06-13 13:55:43,677][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:55:47,744][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 13:55:51,053][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 165 @ 8552 updates, score 2.231) (writing took 7.376413963967934 seconds)
[2022-06-13 13:55:51,054][fairseq_cli.train][INFO] - end of epoch 165 (average epoch stats below)
[2022-06-13 13:55:51,055][train][INFO] - {"epoch": 165, "train_loss": "1.777", "train_ppl": "3.43", "train_wps": "20709.7", "train_ups": "0.1", "train_wpb": "212909", "train_bsz": "503.5", "train_num_updates": "8552", "train_lr": "0.0004276", "train_gnorm": "0.581", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "88084"}
[2022-06-13 13:55:51,084][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 13:55:51,092][fairseq.trainer][INFO] - begin training epoch 166
[2022-06-13 13:55:51,093][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:03:26,327][train_inner][INFO] - {"epoch": 166, "update": 165.923, "loss": "1.773", "ppl": "3.42", "wps": "21192.4", "ups": "0.1", "wpb": "213758", "bsz": "505.3", "num_updates": "8600", "lr": "0.00043", "gnorm": "0.566", "loss_scale": "128", "train_wall": "1871", "gb_free": "6.2", "wall": "88540"}
[2022-06-13 14:03:59,587][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 14:04:37,096][valid][INFO] - {"epoch": 166, "valid_loss": "2.232", "valid_ppl": "4.7", "valid_wps": "67579.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8604", "valid_best_loss": "2.231"}
[2022-06-13 14:04:37,098][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 166 @ 8604 updates
[2022-06-13 14:04:37,098][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:04:41,370][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:04:41,414][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 166 @ 8604 updates, score 2.232) (writing took 4.3167755720205605 seconds)
[2022-06-13 14:04:41,415][fairseq_cli.train][INFO] - end of epoch 166 (average epoch stats below)
[2022-06-13 14:04:41,416][train][INFO] - {"epoch": 166, "train_loss": "1.762", "train_ppl": "3.39", "train_wps": "20872.7", "train_ups": "0.1", "train_wpb": "212885", "train_bsz": "503.5", "train_num_updates": "8604", "train_lr": "0.0004302", "train_gnorm": "0.568", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "88615"}
[2022-06-13 14:04:41,429][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 14:04:41,432][fairseq.trainer][INFO] - begin training epoch 167
[2022-06-13 14:04:41,432][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:12:13,172][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 14:12:46,865][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 14:13:24,240][valid][INFO] - {"epoch": 167, "valid_loss": "2.235", "valid_ppl": "4.71", "valid_wps": "67260.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8655", "valid_best_loss": "2.231"}
[2022-06-13 14:13:24,241][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 167 @ 8655 updates
[2022-06-13 14:13:24,242][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:13:28,865][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:13:28,923][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 167 @ 8655 updates, score 2.235) (writing took 4.681506362976506 seconds)
[2022-06-13 14:13:28,923][fairseq_cli.train][INFO] - end of epoch 167 (average epoch stats below)
[2022-06-13 14:13:28,924][train][INFO] - {"epoch": 167, "train_loss": "1.746", "train_ppl": "3.35", "train_wps": "20577.3", "train_ups": "0.1", "train_wpb": "212837", "train_bsz": "503.3", "train_num_updates": "8655", "train_lr": "0.00043275", "train_gnorm": "0.566", "train_loss_scale": "128", "train_train_wall": "481", "train_gb_free": "6.2", "train_wall": "89142"}
[2022-06-13 14:13:28,935][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 14:13:28,938][fairseq.trainer][INFO] - begin training epoch 168
[2022-06-13 14:13:28,939][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:21:42,078][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 14:22:19,667][valid][INFO] - {"epoch": 168, "valid_loss": "2.224", "valid_ppl": "4.67", "valid_wps": "67365.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8707", "valid_best_loss": "2.224"}
[2022-06-13 14:22:19,668][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 168 @ 8707 updates
[2022-06-13 14:22:19,669][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 14:22:24,081][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 14:22:27,608][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 168 @ 8707 updates, score 2.224) (writing took 7.938962467946112 seconds)
[2022-06-13 14:22:27,608][fairseq_cli.train][INFO] - end of epoch 168 (average epoch stats below)
[2022-06-13 14:22:27,610][train][INFO] - {"epoch": 168, "train_loss": "1.737", "train_ppl": "3.33", "train_wps": "20558.2", "train_ups": "0.1", "train_wpb": "212970", "train_bsz": "503.5", "train_num_updates": "8707", "train_lr": "0.00043535", "train_gnorm": "0.57", "train_loss_scale": "128", "train_train_wall": "489", "train_gb_free": "6.2", "train_wall": "89681"}
[2022-06-13 14:22:27,631][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 14:22:27,634][fairseq.trainer][INFO] - begin training epoch 169
[2022-06-13 14:22:27,634][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:30:35,010][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 14:31:12,892][valid][INFO] - {"epoch": 169, "valid_loss": "2.247", "valid_ppl": "4.75", "valid_wps": "66838.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8759", "valid_best_loss": "2.224"}
[2022-06-13 14:31:12,894][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 169 @ 8759 updates
[2022-06-13 14:31:12,894][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:31:16,981][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:31:17,024][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 169 @ 8759 updates, score 2.247) (writing took 4.130576526047662 seconds)
[2022-06-13 14:31:17,025][fairseq_cli.train][INFO] - end of epoch 169 (average epoch stats below)
[2022-06-13 14:31:17,026][train][INFO] - {"epoch": 169, "train_loss": "1.734", "train_ppl": "3.33", "train_wps": "20900.5", "train_ups": "0.1", "train_wpb": "212789", "train_bsz": "503.5", "train_num_updates": "8759", "train_lr": "0.00043795", "train_gnorm": "0.572", "train_loss_scale": "128", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "90210"}
[2022-06-13 14:31:17,036][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 14:31:17,039][fairseq.trainer][INFO] - begin training epoch 170
[2022-06-13 14:31:17,039][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:37:46,601][train_inner][INFO] - {"epoch": 170, "update": 169.788, "loss": "1.736", "ppl": "3.33", "wps": "20655.6", "ups": "0.1", "wpb": "212781", "bsz": "503.1", "num_updates": "8800", "lr": "0.00044", "gnorm": "0.572", "loss_scale": "128", "train_wall": "1871", "gb_free": "6.2", "wall": "90600"}
[2022-06-13 14:39:27,478][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 14:40:05,142][valid][INFO] - {"epoch": 170, "valid_loss": "2.226", "valid_ppl": "4.68", "valid_wps": "67282.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8811", "valid_best_loss": "2.224"}
[2022-06-13 14:40:05,144][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 170 @ 8811 updates
[2022-06-13 14:40:05,144][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:40:09,359][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:40:09,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 170 @ 8811 updates, score 2.226) (writing took 4.309700657962821 seconds)
[2022-06-13 14:40:09,454][fairseq_cli.train][INFO] - end of epoch 170 (average epoch stats below)
[2022-06-13 14:40:09,455][train][INFO] - {"epoch": 170, "train_loss": "1.727", "train_ppl": "3.31", "train_wps": "20793", "train_ups": "0.1", "train_wpb": "212900", "train_bsz": "503.5", "train_num_updates": "8811", "train_lr": "0.00044055", "train_gnorm": "0.575", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "90743"}
[2022-06-13 14:40:09,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 14:40:09,482][fairseq.trainer][INFO] - begin training epoch 171
[2022-06-13 14:40:09,483][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:48:18,771][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 14:48:56,456][valid][INFO] - {"epoch": 171, "valid_loss": "2.236", "valid_ppl": "4.71", "valid_wps": "66662.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8863", "valid_best_loss": "2.224"}
[2022-06-13 14:48:56,457][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 171 @ 8863 updates
[2022-06-13 14:48:56,458][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:49:00,769][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 14:49:00,822][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 171 @ 8863 updates, score 2.236) (writing took 4.36441877798643 seconds)
[2022-06-13 14:49:00,822][fairseq_cli.train][INFO] - end of epoch 171 (average epoch stats below)
[2022-06-13 14:49:00,823][train][INFO] - {"epoch": 171, "train_loss": "1.722", "train_ppl": "3.3", "train_wps": "20844.2", "train_ups": "0.1", "train_wpb": "212998", "train_bsz": "503.5", "train_num_updates": "8863", "train_lr": "0.00044315", "train_gnorm": "0.58", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.4", "train_wall": "91274"}
[2022-06-13 14:49:00,834][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 14:49:00,837][fairseq.trainer][INFO] - begin training epoch 172
[2022-06-13 14:49:00,837][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:57:09,680][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 14:57:47,241][valid][INFO] - {"epoch": 172, "valid_loss": "2.219", "valid_ppl": "4.66", "valid_wps": "66873.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8915", "valid_best_loss": "2.219"}
[2022-06-13 14:57:47,242][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 172 @ 8915 updates
[2022-06-13 14:57:47,243][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 14:57:51,428][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 14:57:54,774][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 172 @ 8915 updates, score 2.219) (writing took 7.531943820067681 seconds)
[2022-06-13 14:57:54,775][fairseq_cli.train][INFO] - end of epoch 172 (average epoch stats below)
[2022-06-13 14:57:54,777][train][INFO] - {"epoch": 172, "train_loss": "1.723", "train_ppl": "3.3", "train_wps": "20717.1", "train_ups": "0.1", "train_wpb": "212730", "train_bsz": "503.5", "train_num_updates": "8915", "train_lr": "0.00044575", "train_gnorm": "0.582", "train_loss_scale": "256", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "91808"}
[2022-06-13 14:57:54,794][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 14:57:54,798][fairseq.trainer][INFO] - begin training epoch 173
[2022-06-13 14:57:54,798][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 14:58:04,296][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 15:06:02,905][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 15:06:40,366][valid][INFO] - {"epoch": 173, "valid_loss": "2.211", "valid_ppl": "4.63", "valid_wps": "67258.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "8966", "valid_best_loss": "2.211"}
[2022-06-13 15:06:40,368][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 173 @ 8966 updates
[2022-06-13 15:06:40,369][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 15:06:44,481][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 15:06:48,287][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 173 @ 8966 updates, score 2.211) (writing took 7.919153725029901 seconds)
[2022-06-13 15:06:48,288][fairseq_cli.train][INFO] - end of epoch 173 (average epoch stats below)
[2022-06-13 15:06:48,289][train][INFO] - {"epoch": 173, "train_loss": "1.712", "train_ppl": "3.28", "train_wps": "20361.4", "train_ups": "0.1", "train_wpb": "213001", "train_bsz": "503.3", "train_num_updates": "8966", "train_lr": "0.0004483", "train_gnorm": "0.573", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "92342"}
[2022-06-13 15:06:48,302][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 15:06:48,306][fairseq.trainer][INFO] - begin training epoch 174
[2022-06-13 15:06:48,307][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 15:12:12,407][train_inner][INFO] - {"epoch": 174, "update": 173.654, "loss": "1.717", "ppl": "3.29", "wps": "20599", "ups": "0.1", "wpb": "212767", "bsz": "503.1", "num_updates": "9000", "lr": "0.00045", "gnorm": "0.579", "loss_scale": "128", "train_wall": "1873", "gb_free": "6.2", "wall": "92666"}
[2022-06-13 15:14:57,293][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 15:15:34,863][valid][INFO] - {"epoch": 174, "valid_loss": "2.235", "valid_ppl": "4.71", "valid_wps": "67088.9", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9018", "valid_best_loss": "2.211"}
[2022-06-13 15:15:34,865][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 174 @ 9018 updates
[2022-06-13 15:15:34,866][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:15:39,012][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:15:39,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 174 @ 9018 updates, score 2.235) (writing took 4.193110827007331 seconds)
[2022-06-13 15:15:39,059][fairseq_cli.train][INFO] - end of epoch 174 (average epoch stats below)
[2022-06-13 15:15:39,059][train][INFO] - {"epoch": 174, "train_loss": "1.701", "train_ppl": "3.25", "train_wps": "20843.1", "train_ups": "0.1", "train_wpb": "212748", "train_bsz": "503.5", "train_num_updates": "9018", "train_lr": "0.0004509", "train_gnorm": "0.585", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "92872"}
[2022-06-13 15:15:39,072][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 15:15:39,075][fairseq.trainer][INFO] - begin training epoch 175
[2022-06-13 15:15:39,076][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 15:23:49,514][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 15:24:27,133][valid][INFO] - {"epoch": 175, "valid_loss": "2.215", "valid_ppl": "4.64", "valid_wps": "67406", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9070", "valid_best_loss": "2.211"}
[2022-06-13 15:24:27,134][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 175 @ 9070 updates
[2022-06-13 15:24:27,135][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:24:31,358][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:24:31,430][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 175 @ 9070 updates, score 2.215) (writing took 4.295209062984213 seconds)
[2022-06-13 15:24:31,430][fairseq_cli.train][INFO] - end of epoch 175 (average epoch stats below)
[2022-06-13 15:24:31,431][train][INFO] - {"epoch": 175, "train_loss": "1.714", "train_ppl": "3.28", "train_wps": "20785.2", "train_ups": "0.1", "train_wpb": "212797", "train_bsz": "503.5", "train_num_updates": "9070", "train_lr": "0.0004535", "train_gnorm": "0.585", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "93405"}
[2022-06-13 15:24:31,441][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 15:24:31,444][fairseq.trainer][INFO] - begin training epoch 176
[2022-06-13 15:24:31,444][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 15:32:41,232][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 15:33:18,926][valid][INFO] - {"epoch": 176, "valid_loss": "2.217", "valid_ppl": "4.65", "valid_wps": "66866", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9122", "valid_best_loss": "2.211"}
[2022-06-13 15:33:18,927][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 176 @ 9122 updates
[2022-06-13 15:33:18,928][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:33:23,081][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:33:23,137][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 176 @ 9122 updates, score 2.217) (writing took 4.209923404967412 seconds)
[2022-06-13 15:33:23,138][fairseq_cli.train][INFO] - end of epoch 176 (average epoch stats below)
[2022-06-13 15:33:23,139][train][INFO] - {"epoch": 176, "train_loss": "1.69", "train_ppl": "3.23", "train_wps": "20828.5", "train_ups": "0.1", "train_wpb": "212974", "train_bsz": "503.5", "train_num_updates": "9122", "train_lr": "0.0004561", "train_gnorm": "0.575", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.1", "train_wall": "93937"}
[2022-06-13 15:33:23,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 15:33:23,153][fairseq.trainer][INFO] - begin training epoch 177
[2022-06-13 15:33:23,154][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 15:41:32,505][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 15:42:10,265][valid][INFO] - {"epoch": 177, "valid_loss": "2.236", "valid_ppl": "4.71", "valid_wps": "67267.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9174", "valid_best_loss": "2.211"}
[2022-06-13 15:42:10,267][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 177 @ 9174 updates
[2022-06-13 15:42:10,267][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:42:14,363][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:42:14,419][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 177 @ 9174 updates, score 2.236) (writing took 4.151800534920767 seconds)
[2022-06-13 15:42:14,419][fairseq_cli.train][INFO] - end of epoch 177 (average epoch stats below)
[2022-06-13 15:42:14,420][train][INFO] - {"epoch": 177, "train_loss": "1.69", "train_ppl": "3.23", "train_wps": "20848.3", "train_ups": "0.1", "train_wpb": "213006", "train_bsz": "503.5", "train_num_updates": "9174", "train_lr": "0.0004587", "train_gnorm": "0.592", "train_loss_scale": "256", "train_train_wall": "485", "train_gb_free": "6.1", "train_wall": "94468"}
[2022-06-13 15:42:14,430][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 15:42:14,433][fairseq.trainer][INFO] - begin training epoch 178
[2022-06-13 15:42:14,434][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 15:42:23,990][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 15:46:29,155][train_inner][INFO] - {"epoch": 178, "update": 177.519, "loss": "1.698", "ppl": "3.25", "wps": "20664.6", "ups": "0.1", "wpb": "212509", "bsz": "503.1", "num_updates": "9200", "lr": "0.00046", "gnorm": "0.589", "loss_scale": "128", "train_wall": "1871", "gb_free": "6.1", "wall": "94723"}
[2022-06-13 15:50:23,622][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 15:51:01,225][valid][INFO] - {"epoch": 178, "valid_loss": "2.213", "valid_ppl": "4.64", "valid_wps": "66876.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9225", "valid_best_loss": "2.211"}
[2022-06-13 15:51:01,226][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 178 @ 9225 updates
[2022-06-13 15:51:01,227][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:51:05,469][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 15:51:05,527][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 178 @ 9225 updates, score 2.213) (writing took 4.300796944997273 seconds)
[2022-06-13 15:51:05,528][fairseq_cli.train][INFO] - end of epoch 178 (average epoch stats below)
[2022-06-13 15:51:05,529][train][INFO] - {"epoch": 178, "train_loss": "1.691", "train_ppl": "3.23", "train_wps": "20448.4", "train_ups": "0.1", "train_wpb": "212948", "train_bsz": "503.3", "train_num_updates": "9225", "train_lr": "0.00046125", "train_gnorm": "0.59", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "94999"}
[2022-06-13 15:51:05,540][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 15:51:05,544][fairseq.trainer][INFO] - begin training epoch 179
[2022-06-13 15:51:05,544][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 15:59:14,496][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 15:59:52,268][valid][INFO] - {"epoch": 179, "valid_loss": "2.194", "valid_ppl": "4.58", "valid_wps": "67295.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9277", "valid_best_loss": "2.194"}
[2022-06-13 15:59:52,270][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 179 @ 9277 updates
[2022-06-13 15:59:52,271][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 15:59:56,533][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 16:00:00,160][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 179 @ 9277 updates, score 2.194) (writing took 7.89032223506365 seconds)
[2022-06-13 16:00:00,162][fairseq_cli.train][INFO] - end of epoch 179 (average epoch stats below)
[2022-06-13 16:00:00,165][train][INFO] - {"epoch": 179, "train_loss": "1.676", "train_ppl": "3.2", "train_wps": "20705", "train_ups": "0.1", "train_wpb": "212877", "train_bsz": "503.5", "train_num_updates": "9277", "train_lr": "0.00046385", "train_gnorm": "0.581", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "95534"}
[2022-06-13 16:00:00,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 16:00:00,204][fairseq.trainer][INFO] - begin training epoch 180
[2022-06-13 16:00:00,205][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 16:08:08,521][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 16:08:46,340][valid][INFO] - {"epoch": 180, "valid_loss": "2.218", "valid_ppl": "4.65", "valid_wps": "66723.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9329", "valid_best_loss": "2.194"}
[2022-06-13 16:08:46,342][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 180 @ 9329 updates
[2022-06-13 16:08:46,343][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:08:50,452][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:08:50,493][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 180 @ 9329 updates, score 2.218) (writing took 4.150821566930972 seconds)
[2022-06-13 16:08:50,493][fairseq_cli.train][INFO] - end of epoch 180 (average epoch stats below)
[2022-06-13 16:08:50,494][train][INFO] - {"epoch": 180, "train_loss": "1.669", "train_ppl": "3.18", "train_wps": "20873.8", "train_ups": "0.1", "train_wpb": "212884", "train_bsz": "503.5", "train_num_updates": "9329", "train_lr": "0.00046645", "train_gnorm": "0.592", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "96064"}
[2022-06-13 16:08:50,505][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 16:08:50,508][fairseq.trainer][INFO] - begin training epoch 181
[2022-06-13 16:08:50,508][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 16:17:01,177][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 16:17:38,849][valid][INFO] - {"epoch": 181, "valid_loss": "2.213", "valid_ppl": "4.64", "valid_wps": "66740.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9381", "valid_best_loss": "2.194"}
[2022-06-13 16:17:38,850][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 181 @ 9381 updates
[2022-06-13 16:17:38,851][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:17:42,898][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:17:42,976][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 181 @ 9381 updates, score 2.213) (writing took 4.125706039951183 seconds)
[2022-06-13 16:17:42,977][fairseq_cli.train][INFO] - end of epoch 181 (average epoch stats below)
[2022-06-13 16:17:42,978][train][INFO] - {"epoch": 181, "train_loss": "1.683", "train_ppl": "3.21", "train_wps": "20794.9", "train_ups": "0.1", "train_wpb": "212941", "train_bsz": "503.5", "train_num_updates": "9381", "train_lr": "0.00046905", "train_gnorm": "0.597", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.5", "train_wall": "96596"}
[2022-06-13 16:17:42,996][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 16:17:43,001][fairseq.trainer][INFO] - begin training epoch 182
[2022-06-13 16:17:43,002][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 16:20:45,474][train_inner][INFO] - {"epoch": 182, "update": 181.365, "loss": "1.677", "ppl": "3.2", "wps": "20735.6", "ups": "0.1", "wpb": "213195", "bsz": "503.1", "num_updates": "9400", "lr": "0.00047", "gnorm": "0.591", "loss_scale": "128", "train_wall": "1867", "gb_free": "6.2", "wall": "96779"}
[2022-06-13 16:25:48,204][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2022-06-13 16:25:53,376][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 16:26:30,912][valid][INFO] - {"epoch": 182, "valid_loss": "2.205", "valid_ppl": "4.61", "valid_wps": "67079", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9432", "valid_best_loss": "2.194"}
[2022-06-13 16:26:30,914][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 182 @ 9432 updates
[2022-06-13 16:26:30,915][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:26:35,113][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:26:35,212][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 182 @ 9432 updates, score 2.205) (writing took 4.298126259003766 seconds)
[2022-06-13 16:26:35,213][fairseq_cli.train][INFO] - end of epoch 182 (average epoch stats below)
[2022-06-13 16:26:35,214][train][INFO] - {"epoch": 182, "train_loss": "1.666", "train_ppl": "3.17", "train_wps": "20417.8", "train_ups": "0.1", "train_wpb": "213079", "train_bsz": "503.3", "train_num_updates": "9432", "train_lr": "0.0004716", "train_gnorm": "0.587", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "97129"}
[2022-06-13 16:26:35,239][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 16:26:35,247][fairseq.trainer][INFO] - begin training epoch 183
[2022-06-13 16:26:35,248][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 16:34:43,826][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 16:35:21,143][valid][INFO] - {"epoch": 183, "valid_loss": "2.204", "valid_ppl": "4.61", "valid_wps": "67334.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9484", "valid_best_loss": "2.194"}
[2022-06-13 16:35:21,144][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 183 @ 9484 updates
[2022-06-13 16:35:21,145][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:35:25,586][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:35:25,668][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 183 @ 9484 updates, score 2.204) (writing took 4.523736992967315 seconds)
[2022-06-13 16:35:25,669][fairseq_cli.train][INFO] - end of epoch 183 (average epoch stats below)
[2022-06-13 16:35:25,670][train][INFO] - {"epoch": 183, "train_loss": "1.655", "train_ppl": "3.15", "train_wps": "20883.8", "train_ups": "0.1", "train_wpb": "213037", "train_bsz": "503.5", "train_num_updates": "9484", "train_lr": "0.0004742", "train_gnorm": "0.585", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "97659"}
[2022-06-13 16:35:25,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 16:35:25,704][fairseq.trainer][INFO] - begin training epoch 184
[2022-06-13 16:35:25,705][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 16:42:40,847][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-13 16:43:33,305][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 16:44:10,706][valid][INFO] - {"epoch": 184, "valid_loss": "2.199", "valid_ppl": "4.59", "valid_wps": "67141.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9535", "valid_best_loss": "2.194"}
[2022-06-13 16:44:10,708][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 184 @ 9535 updates
[2022-06-13 16:44:10,709][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:44:14,797][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:44:14,855][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 184 @ 9535 updates, score 2.199) (writing took 4.147323256940581 seconds)
[2022-06-13 16:44:14,856][fairseq_cli.train][INFO] - end of epoch 184 (average epoch stats below)
[2022-06-13 16:44:14,857][train][INFO] - {"epoch": 184, "train_loss": "1.649", "train_ppl": "3.14", "train_wps": "20507.5", "train_ups": "0.1", "train_wpb": "212790", "train_bsz": "503.3", "train_num_updates": "9535", "train_lr": "0.00047675", "train_gnorm": "0.587", "train_loss_scale": "64", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "98188"}
[2022-06-13 16:44:14,867][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 16:44:14,870][fairseq.trainer][INFO] - begin training epoch 185
[2022-06-13 16:44:14,870][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 16:52:24,222][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 16:53:01,619][valid][INFO] - {"epoch": 185, "valid_loss": "2.205", "valid_ppl": "4.61", "valid_wps": "67214", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9587", "valid_best_loss": "2.194"}
[2022-06-13 16:53:01,621][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 185 @ 9587 updates
[2022-06-13 16:53:01,622][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:53:06,002][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 16:53:06,113][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 185 @ 9587 updates, score 2.205) (writing took 4.49208899307996 seconds)
[2022-06-13 16:53:06,114][fairseq_cli.train][INFO] - end of epoch 185 (average epoch stats below)
[2022-06-13 16:53:06,115][train][INFO] - {"epoch": 185, "train_loss": "1.641", "train_ppl": "3.12", "train_wps": "20834", "train_ups": "0.1", "train_wpb": "212850", "train_bsz": "503.5", "train_num_updates": "9587", "train_lr": "0.00047935", "train_gnorm": "0.586", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "98720"}
[2022-06-13 16:53:06,137][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 16:53:06,143][fairseq.trainer][INFO] - begin training epoch 186
[2022-06-13 16:53:06,143][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 16:55:09,944][train_inner][INFO] - {"epoch": 186, "update": 185.25, "loss": "1.649", "ppl": "3.14", "wps": "20613.5", "ups": "0.1", "wpb": "212780", "bsz": "503.1", "num_updates": "9600", "lr": "0.00048", "gnorm": "0.587", "loss_scale": "64", "train_wall": "1880", "gb_free": "6.2", "wall": "98843"}
[2022-06-13 17:01:15,852][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 17:01:53,463][valid][INFO] - {"epoch": 186, "valid_loss": "2.222", "valid_ppl": "4.66", "valid_wps": "66794.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9639", "valid_best_loss": "2.194"}
[2022-06-13 17:01:53,464][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 186 @ 9639 updates
[2022-06-13 17:01:53,465][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:01:57,748][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:01:57,806][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 186 @ 9639 updates, score 2.222) (writing took 4.342067616060376 seconds)
[2022-06-13 17:01:57,807][fairseq_cli.train][INFO] - end of epoch 186 (average epoch stats below)
[2022-06-13 17:01:57,808][train][INFO] - {"epoch": 186, "train_loss": "1.634", "train_ppl": "3.1", "train_wps": "20817.4", "train_ups": "0.1", "train_wpb": "212855", "train_bsz": "503.5", "train_num_updates": "9639", "train_lr": "0.00048195", "train_gnorm": "0.591", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "99251"}
[2022-06-13 17:01:57,819][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 17:01:57,822][fairseq.trainer][INFO] - begin training epoch 187
[2022-06-13 17:01:57,822][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 17:10:06,385][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 17:10:43,925][valid][INFO] - {"epoch": 187, "valid_loss": "2.216", "valid_ppl": "4.65", "valid_wps": "66975.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9691", "valid_best_loss": "2.194"}
[2022-06-13 17:10:43,927][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 187 @ 9691 updates
[2022-06-13 17:10:43,928][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:10:48,293][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:10:48,351][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 187 @ 9691 updates, score 2.216) (writing took 4.424676868016832 seconds)
[2022-06-13 17:10:48,352][fairseq_cli.train][INFO] - end of epoch 187 (average epoch stats below)
[2022-06-13 17:10:48,353][train][INFO] - {"epoch": 187, "train_loss": "1.627", "train_ppl": "3.09", "train_wps": "20881.1", "train_ups": "0.1", "train_wpb": "213046", "train_bsz": "503.5", "train_num_updates": "9691", "train_lr": "0.00048455", "train_gnorm": "0.598", "train_loss_scale": "64", "train_train_wall": "484", "train_gb_free": "6.3", "train_wall": "99782"}
[2022-06-13 17:10:48,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 17:10:48,370][fairseq.trainer][INFO] - begin training epoch 188
[2022-06-13 17:10:48,370][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 17:18:56,589][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 17:19:34,189][valid][INFO] - {"epoch": 188, "valid_loss": "2.2", "valid_ppl": "4.59", "valid_wps": "66889.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9743", "valid_best_loss": "2.194"}
[2022-06-13 17:19:34,190][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 188 @ 9743 updates
[2022-06-13 17:19:34,191][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:19:38,877][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:19:38,932][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 188 @ 9743 updates, score 2.2) (writing took 4.741158946068026 seconds)
[2022-06-13 17:19:38,932][fairseq_cli.train][INFO] - end of epoch 188 (average epoch stats below)
[2022-06-13 17:19:38,933][train][INFO] - {"epoch": 188, "train_loss": "1.641", "train_ppl": "3.12", "train_wps": "20867.5", "train_ups": "0.1", "train_wpb": "212920", "train_bsz": "503.5", "train_num_updates": "9743", "train_lr": "0.00048715", "train_gnorm": "0.598", "train_loss_scale": "64", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "100312"}
[2022-06-13 17:19:38,944][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 17:19:38,947][fairseq.trainer][INFO] - begin training epoch 189
[2022-06-13 17:19:38,948][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 17:27:47,578][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 17:28:24,929][valid][INFO] - {"epoch": 189, "valid_loss": "2.199", "valid_ppl": "4.59", "valid_wps": "67302.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9795", "valid_best_loss": "2.194"}
[2022-06-13 17:28:24,931][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 189 @ 9795 updates
[2022-06-13 17:28:24,932][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:28:29,068][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:28:29,131][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 189 @ 9795 updates, score 2.199) (writing took 4.199666686006822 seconds)
[2022-06-13 17:28:29,131][fairseq_cli.train][INFO] - end of epoch 189 (average epoch stats below)
[2022-06-13 17:28:29,133][train][INFO] - {"epoch": 189, "train_loss": "1.623", "train_ppl": "3.08", "train_wps": "20893.8", "train_ups": "0.1", "train_wpb": "213036", "train_bsz": "503.5", "train_num_updates": "9795", "train_lr": "0.00048975", "train_gnorm": "0.594", "train_loss_scale": "128", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "100843"}
[2022-06-13 17:28:29,155][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 17:28:29,163][fairseq.trainer][INFO] - begin training epoch 190
[2022-06-13 17:28:29,164][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 17:29:15,874][train_inner][INFO] - {"epoch": 190, "update": 189.096, "loss": "1.629", "ppl": "3.09", "wps": "20793.2", "ups": "0.1", "wpb": "212707", "bsz": "503.1", "num_updates": "9800", "lr": "0.00049", "gnorm": "0.597", "loss_scale": "128", "train_wall": "1860", "gb_free": "6.2", "wall": "100889"}
[2022-06-13 17:36:38,267][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 17:37:15,752][valid][INFO] - {"epoch": 190, "valid_loss": "2.202", "valid_ppl": "4.6", "valid_wps": "67002.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9847", "valid_best_loss": "2.194"}
[2022-06-13 17:37:15,754][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 190 @ 9847 updates
[2022-06-13 17:37:15,755][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:37:19,983][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:37:20,036][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 190 @ 9847 updates, score 2.202) (writing took 4.281926933093928 seconds)
[2022-06-13 17:37:20,036][fairseq_cli.train][INFO] - end of epoch 190 (average epoch stats below)
[2022-06-13 17:37:20,037][train][INFO] - {"epoch": 190, "train_loss": "1.619", "train_ppl": "3.07", "train_wps": "20845.1", "train_ups": "0.1", "train_wpb": "212822", "train_bsz": "503.5", "train_num_updates": "9847", "train_lr": "0.00049235", "train_gnorm": "0.597", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "101373"}
[2022-06-13 17:37:20,048][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 17:37:20,050][fairseq.trainer][INFO] - begin training epoch 191
[2022-06-13 17:37:20,051][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 17:45:30,648][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 17:46:08,245][valid][INFO] - {"epoch": 191, "valid_loss": "2.193", "valid_ppl": "4.57", "valid_wps": "66895.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9899", "valid_best_loss": "2.193"}
[2022-06-13 17:46:08,246][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 191 @ 9899 updates
[2022-06-13 17:46:08,247][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 17:46:12,461][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 17:46:15,740][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 191 @ 9899 updates, score 2.193) (writing took 7.493701435974799 seconds)
[2022-06-13 17:46:15,741][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2022-06-13 17:46:15,743][train][INFO] - {"epoch": 191, "train_loss": "1.623", "train_ppl": "3.08", "train_wps": "20667.2", "train_ups": "0.1", "train_wpb": "212914", "train_bsz": "503.5", "train_num_updates": "9899", "train_lr": "0.00049495", "train_gnorm": "0.591", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "101909"}
[2022-06-13 17:46:15,768][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 17:46:15,773][fairseq.trainer][INFO] - begin training epoch 192
[2022-06-13 17:46:15,774][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 17:54:24,840][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 17:55:02,299][valid][INFO] - {"epoch": 192, "valid_loss": "2.206", "valid_ppl": "4.61", "valid_wps": "67124.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "9951", "valid_best_loss": "2.193"}
[2022-06-13 17:55:02,301][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 192 @ 9951 updates
[2022-06-13 17:55:02,302][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:55:06,400][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 17:55:06,439][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 192 @ 9951 updates, score 2.206) (writing took 4.138117869966663 seconds)
[2022-06-13 17:55:06,440][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2022-06-13 17:55:06,440][train][INFO] - {"epoch": 192, "train_loss": "1.613", "train_ppl": "3.06", "train_wps": "20855.6", "train_ups": "0.1", "train_wpb": "212846", "train_bsz": "503.5", "train_num_updates": "9951", "train_lr": "0.00049755", "train_gnorm": "0.592", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "102440"}
[2022-06-13 17:55:06,452][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 17:55:06,455][fairseq.trainer][INFO] - begin training epoch 193
[2022-06-13 17:55:06,456][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 18:02:14,103][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-13 18:03:03,482][train_inner][INFO] - {"epoch": 193, "update": 192.962, "loss": "1.616", "ppl": "3.07", "wps": "21055.3", "ups": "0.1", "wpb": "213459", "bsz": "505.3", "num_updates": "10000", "lr": "0.0005", "gnorm": "0.584", "loss_scale": "64", "train_wall": "1883", "gb_free": "6.2", "wall": "102917"}
[2022-06-13 18:03:18,359][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 18:03:55,922][valid][INFO] - {"epoch": 193, "valid_loss": "2.203", "valid_ppl": "4.6", "valid_wps": "67130.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10002", "valid_best_loss": "2.193"}
[2022-06-13 18:03:55,923][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 193 @ 10002 updates
[2022-06-13 18:03:55,924][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:04:00,381][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:04:00,468][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 193 @ 10002 updates, score 2.203) (writing took 4.545144794974476 seconds)
[2022-06-13 18:04:00,469][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2022-06-13 18:04:00,470][train][INFO] - {"epoch": 193, "train_loss": "1.605", "train_ppl": "3.04", "train_wps": "20294.1", "train_ups": "0.1", "train_wpb": "212503", "train_bsz": "503.3", "train_num_updates": "10002", "train_lr": "0.000499991", "train_gnorm": "0.597", "train_loss_scale": "64", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "102974"}
[2022-06-13 18:04:00,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 18:04:00,499][fairseq.trainer][INFO] - begin training epoch 194
[2022-06-13 18:04:00,500][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 18:12:13,151][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 18:12:50,656][valid][INFO] - {"epoch": 194, "valid_loss": "2.194", "valid_ppl": "4.58", "valid_wps": "67223.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10054", "valid_best_loss": "2.193"}
[2022-06-13 18:12:50,657][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 194 @ 10054 updates
[2022-06-13 18:12:50,658][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:12:54,989][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:12:55,042][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 194 @ 10054 updates, score 2.194) (writing took 4.384711374994367 seconds)
[2022-06-13 18:12:55,042][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2022-06-13 18:12:55,043][train][INFO] - {"epoch": 194, "train_loss": "1.606", "train_ppl": "3.04", "train_wps": "20707.2", "train_ups": "0.1", "train_wpb": "212875", "train_bsz": "503.5", "train_num_updates": "10054", "train_lr": "0.000499765", "train_gnorm": "0.596", "train_loss_scale": "64", "train_train_wall": "488", "train_gb_free": "6.2", "train_wall": "103508"}
[2022-06-13 18:12:55,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 18:12:55,056][fairseq.trainer][INFO] - begin training epoch 195
[2022-06-13 18:12:55,057][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 18:21:02,555][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 18:21:39,962][valid][INFO] - {"epoch": 195, "valid_loss": "2.204", "valid_ppl": "4.61", "valid_wps": "67216.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10106", "valid_best_loss": "2.193"}
[2022-06-13 18:21:39,963][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 195 @ 10106 updates
[2022-06-13 18:21:39,964][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:21:44,376][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:21:44,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 195 @ 10106 updates, score 2.204) (writing took 4.496586887980811 seconds)
[2022-06-13 18:21:44,461][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2022-06-13 18:21:44,462][train][INFO] - {"epoch": 195, "train_loss": "1.597", "train_ppl": "3.03", "train_wps": "20924.9", "train_ups": "0.1", "train_wpb": "213039", "train_bsz": "503.5", "train_num_updates": "10106", "train_lr": "0.000499539", "train_gnorm": "0.603", "train_loss_scale": "64", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "104038"}
[2022-06-13 18:21:44,474][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 18:21:44,477][fairseq.trainer][INFO] - begin training epoch 196
[2022-06-13 18:21:44,478][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 18:29:52,765][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 18:30:30,207][valid][INFO] - {"epoch": 196, "valid_loss": "2.182", "valid_ppl": "4.54", "valid_wps": "67122.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10158", "valid_best_loss": "2.182"}
[2022-06-13 18:30:30,208][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 196 @ 10158 updates
[2022-06-13 18:30:30,209][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 18:30:34,323][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 18:30:37,737][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 196 @ 10158 updates, score 2.182) (writing took 7.528366798069328 seconds)
[2022-06-13 18:30:37,738][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2022-06-13 18:30:37,739][train][INFO] - {"epoch": 196, "train_loss": "1.596", "train_ppl": "3.02", "train_wps": "20764.3", "train_ups": "0.1", "train_wpb": "212944", "train_bsz": "503.5", "train_num_updates": "10158", "train_lr": "0.000499313", "train_gnorm": "0.609", "train_loss_scale": "64", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "104571"}
[2022-06-13 18:30:37,769][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 18:30:37,777][fairseq.trainer][INFO] - begin training epoch 197
[2022-06-13 18:30:37,778][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 18:37:16,044][train_inner][INFO] - {"epoch": 197, "update": 196.808, "loss": "1.596", "ppl": "3.02", "wps": "20742.8", "ups": "0.1", "wpb": "212880", "bsz": "503.1", "num_updates": "10200", "lr": "0.00049913", "gnorm": "0.603", "loss_scale": "64", "train_wall": "1864", "gb_free": "6.2", "wall": "104969"}
[2022-06-13 18:38:45,780][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 18:39:23,170][valid][INFO] - {"epoch": 197, "valid_loss": "2.22", "valid_ppl": "4.66", "valid_wps": "67167.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10210", "valid_best_loss": "2.182"}
[2022-06-13 18:39:23,172][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 197 @ 10210 updates
[2022-06-13 18:39:23,173][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:39:27,367][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:39:27,410][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 197 @ 10210 updates, score 2.22) (writing took 4.237679258920252 seconds)
[2022-06-13 18:39:27,410][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2022-06-13 18:39:27,411][train][INFO] - {"epoch": 197, "train_loss": "1.582", "train_ppl": "2.99", "train_wps": "20895.8", "train_ups": "0.1", "train_wpb": "212845", "train_bsz": "503.5", "train_num_updates": "10210", "train_lr": "0.000499087", "train_gnorm": "0.602", "train_loss_scale": "64", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "105101"}
[2022-06-13 18:39:27,422][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 18:39:27,425][fairseq.trainer][INFO] - begin training epoch 198
[2022-06-13 18:39:27,425][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 18:47:37,081][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 18:48:14,609][valid][INFO] - {"epoch": 198, "valid_loss": "2.187", "valid_ppl": "4.55", "valid_wps": "66996.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10262", "valid_best_loss": "2.182"}
[2022-06-13 18:48:14,611][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 198 @ 10262 updates
[2022-06-13 18:48:14,612][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:48:18,730][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 18:48:18,801][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 198 @ 10262 updates, score 2.187) (writing took 4.190426126937382 seconds)
[2022-06-13 18:48:18,802][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2022-06-13 18:48:18,803][train][INFO] - {"epoch": 198, "train_loss": "1.586", "train_ppl": "3", "train_wps": "20829.4", "train_ups": "0.1", "train_wpb": "212856", "train_bsz": "503.5", "train_num_updates": "10262", "train_lr": "0.000498861", "train_gnorm": "0.608", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "105632"}
[2022-06-13 18:48:18,813][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 18:48:18,817][fairseq.trainer][INFO] - begin training epoch 199
[2022-06-13 18:48:18,817][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 18:56:26,599][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 18:57:04,135][valid][INFO] - {"epoch": 199, "valid_loss": "2.168", "valid_ppl": "4.49", "valid_wps": "67087.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10314", "valid_best_loss": "2.168"}
[2022-06-13 18:57:04,136][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 199 @ 10314 updates
[2022-06-13 18:57:04,137][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 18:57:08,466][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 18:57:11,877][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 199 @ 10314 updates, score 2.168) (writing took 7.740279176970944 seconds)
[2022-06-13 18:57:11,877][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2022-06-13 18:57:11,878][train][INFO] - {"epoch": 199, "train_loss": "1.576", "train_ppl": "2.98", "train_wps": "20756.9", "train_ups": "0.1", "train_wpb": "212788", "train_bsz": "503.5", "train_num_updates": "10314", "train_lr": "0.000498635", "train_gnorm": "0.597", "train_loss_scale": "128", "train_train_wall": "483", "train_gb_free": "6.2", "train_wall": "106165"}
[2022-06-13 18:57:11,889][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 18:57:11,892][fairseq.trainer][INFO] - begin training epoch 200
[2022-06-13 18:57:11,893][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 19:05:24,826][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 19:06:02,395][valid][INFO] - {"epoch": 200, "valid_loss": "2.185", "valid_ppl": "4.55", "valid_wps": "67005.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10366", "valid_best_loss": "2.168"}
[2022-06-13 19:06:02,396][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 10366 updates
[2022-06-13 19:06:02,397][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:06:06,473][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:06:06,513][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 200 @ 10366 updates, score 2.185) (writing took 4.116847484954633 seconds)
[2022-06-13 19:06:06,513][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2022-06-13 19:06:06,514][train][INFO] - {"epoch": 200, "train_loss": "1.563", "train_ppl": "2.95", "train_wps": "20698.4", "train_ups": "0.1", "train_wpb": "212810", "train_bsz": "503.5", "train_num_updates": "10366", "train_lr": "0.000498409", "train_gnorm": "0.599", "train_loss_scale": "128", "train_train_wall": "488", "train_gb_free": "6.3", "train_wall": "106700"}
[2022-06-13 19:06:06,523][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 19:06:06,526][fairseq.trainer][INFO] - begin training epoch 201
[2022-06-13 19:06:06,527][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 19:11:28,986][train_inner][INFO] - {"epoch": 201, "update": 200.654, "loss": "1.574", "ppl": "2.98", "wps": "20695.6", "ups": "0.1", "wpb": "212434", "bsz": "503.1", "num_updates": "10400", "lr": "0.000498261", "gnorm": "0.605", "loss_scale": "128", "train_wall": "1864", "gb_free": "6.2", "wall": "107022"}
[2022-06-13 19:14:17,049][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 19:14:54,415][valid][INFO] - {"epoch": 201, "valid_loss": "2.158", "valid_ppl": "4.46", "valid_wps": "67188.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10418", "valid_best_loss": "2.158"}
[2022-06-13 19:14:54,416][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 201 @ 10418 updates
[2022-06-13 19:14:54,417][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 19:14:58,750][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 19:15:02,042][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 201 @ 10418 updates, score 2.158) (writing took 7.625590925919823 seconds)
[2022-06-13 19:15:02,042][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2022-06-13 19:15:02,043][train][INFO] - {"epoch": 201, "train_loss": "1.56", "train_ppl": "2.95", "train_wps": "20682.8", "train_ups": "0.1", "train_wpb": "213005", "train_bsz": "503.5", "train_num_updates": "10418", "train_lr": "0.000498183", "train_gnorm": "0.596", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "107235"}
[2022-06-13 19:15:02,056][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 19:15:02,059][fairseq.trainer][INFO] - begin training epoch 202
[2022-06-13 19:15:02,060][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 19:23:13,851][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 19:23:51,728][valid][INFO] - {"epoch": 202, "valid_loss": "2.178", "valid_ppl": "4.53", "valid_wps": "66546.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10470", "valid_best_loss": "2.158"}
[2022-06-13 19:23:51,730][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 202 @ 10470 updates
[2022-06-13 19:23:51,731][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:23:55,887][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:23:55,927][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 202 @ 10470 updates, score 2.178) (writing took 4.197673661052249 seconds)
[2022-06-13 19:23:55,928][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2022-06-13 19:23:55,929][train][INFO] - {"epoch": 202, "train_loss": "1.546", "train_ppl": "2.92", "train_wps": "20730.6", "train_ups": "0.1", "train_wpb": "212841", "train_bsz": "503.5", "train_num_updates": "10470", "train_lr": "0.000497957", "train_gnorm": "0.598", "train_loss_scale": "128", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "107769"}
[2022-06-13 19:23:55,939][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 19:23:55,942][fairseq.trainer][INFO] - begin training epoch 203
[2022-06-13 19:23:55,942][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 19:26:28,919][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-13 19:32:06,469][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 19:32:44,161][valid][INFO] - {"epoch": 203, "valid_loss": "2.171", "valid_ppl": "4.5", "valid_wps": "67247.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10521", "valid_best_loss": "2.158"}
[2022-06-13 19:32:44,163][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 203 @ 10521 updates
[2022-06-13 19:32:44,164][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:32:48,290][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:32:48,347][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 203 @ 10521 updates, score 2.171) (writing took 4.184615197009407 seconds)
[2022-06-13 19:32:48,348][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2022-06-13 19:32:48,349][train][INFO] - {"epoch": 203, "train_loss": "1.55", "train_ppl": "2.93", "train_wps": "20367.6", "train_ups": "0.1", "train_wpb": "212629", "train_bsz": "503.3", "train_num_updates": "10521", "train_lr": "0.000497735", "train_gnorm": "0.609", "train_loss_scale": "64", "train_train_wall": "486", "train_gb_free": "6.1", "train_wall": "108302"}
[2022-06-13 19:32:48,360][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 19:32:48,363][fairseq.trainer][INFO] - begin training epoch 204
[2022-06-13 19:32:48,363][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 19:40:59,829][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 19:41:37,490][valid][INFO] - {"epoch": 204, "valid_loss": "2.165", "valid_ppl": "4.48", "valid_wps": "67063.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10573", "valid_best_loss": "2.158"}
[2022-06-13 19:41:37,492][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 204 @ 10573 updates
[2022-06-13 19:41:37,492][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:41:41,809][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:41:41,869][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 204 @ 10573 updates, score 2.165) (writing took 4.3773312020348385 seconds)
[2022-06-13 19:41:41,870][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2022-06-13 19:41:41,871][train][INFO] - {"epoch": 204, "train_loss": "1.544", "train_ppl": "2.92", "train_wps": "20744.4", "train_ups": "0.1", "train_wpb": "212838", "train_bsz": "503.5", "train_num_updates": "10573", "train_lr": "0.000497509", "train_gnorm": "0.6", "train_loss_scale": "64", "train_train_wall": "487", "train_gb_free": "6.3", "train_wall": "108835"}
[2022-06-13 19:41:41,884][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 19:41:41,887][fairseq.trainer][INFO] - begin training epoch 205
[2022-06-13 19:41:41,888][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 19:45:59,377][train_inner][INFO] - {"epoch": 205, "update": 204.519, "loss": "1.545", "ppl": "2.92", "wps": "20559.6", "ups": "0.1", "wpb": "212832", "bsz": "503.1", "num_updates": "10600", "lr": "0.000497391", "gnorm": "0.602", "loss_scale": "64", "train_wall": "1881", "gb_free": "6.3", "wall": "109093"}
[2022-06-13 19:49:52,947][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 19:50:30,630][valid][INFO] - {"epoch": 205, "valid_loss": "2.174", "valid_ppl": "4.51", "valid_wps": "67158.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10625", "valid_best_loss": "2.158"}
[2022-06-13 19:50:30,631][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 205 @ 10625 updates
[2022-06-13 19:50:30,632][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:50:35,055][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:50:35,150][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 205 @ 10625 updates, score 2.174) (writing took 4.518767489003949 seconds)
[2022-06-13 19:50:35,151][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2022-06-13 19:50:35,152][train][INFO] - {"epoch": 205, "train_loss": "1.531", "train_ppl": "2.89", "train_wps": "20758.6", "train_ups": "0.1", "train_wpb": "212888", "train_bsz": "503.5", "train_num_updates": "10625", "train_lr": "0.000497283", "train_gnorm": "0.599", "train_loss_scale": "64", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "109369"}
[2022-06-13 19:50:35,162][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 19:50:35,165][fairseq.trainer][INFO] - begin training epoch 206
[2022-06-13 19:50:35,166][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 19:58:43,735][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 19:59:21,114][valid][INFO] - {"epoch": 206, "valid_loss": "2.166", "valid_ppl": "4.49", "valid_wps": "67175.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10677", "valid_best_loss": "2.158"}
[2022-06-13 19:59:21,116][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 206 @ 10677 updates
[2022-06-13 19:59:21,117][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:59:25,601][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 19:59:25,674][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 206 @ 10677 updates, score 2.166) (writing took 4.558471078984439 seconds)
[2022-06-13 19:59:25,675][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2022-06-13 19:59:25,676][train][INFO] - {"epoch": 206, "train_loss": "1.527", "train_ppl": "2.88", "train_wps": "20871.5", "train_ups": "0.1", "train_wpb": "212938", "train_bsz": "503.5", "train_num_updates": "10677", "train_lr": "0.000497057", "train_gnorm": "0.608", "train_loss_scale": "64", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "109899"}
[2022-06-13 19:59:25,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 19:59:25,705][fairseq.trainer][INFO] - begin training epoch 207
[2022-06-13 19:59:25,707][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 20:07:37,228][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 20:08:14,843][valid][INFO] - {"epoch": 207, "valid_loss": "2.165", "valid_ppl": "4.48", "valid_wps": "66799.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10729", "valid_best_loss": "2.158"}
[2022-06-13 20:08:14,844][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 207 @ 10729 updates
[2022-06-13 20:08:14,845][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:08:19,279][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:08:19,351][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 207 @ 10729 updates, score 2.165) (writing took 4.506256517022848 seconds)
[2022-06-13 20:08:19,351][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2022-06-13 20:08:19,352][train][INFO] - {"epoch": 207, "train_loss": "1.529", "train_ppl": "2.89", "train_wps": "20739.9", "train_ups": "0.1", "train_wpb": "212854", "train_bsz": "503.5", "train_num_updates": "10729", "train_lr": "0.00049683", "train_gnorm": "0.606", "train_loss_scale": "64", "train_train_wall": "487", "train_gb_free": "6.2", "train_wall": "110433"}
[2022-06-13 20:08:19,363][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 20:08:19,366][fairseq.trainer][INFO] - begin training epoch 208
[2022-06-13 20:08:19,366][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 20:16:29,883][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 20:17:07,466][valid][INFO] - {"epoch": 208, "valid_loss": "2.158", "valid_ppl": "4.46", "valid_wps": "67238.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10781", "valid_best_loss": "2.158"}
[2022-06-13 20:17:07,467][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 208 @ 10781 updates
[2022-06-13 20:17:07,468][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 20:17:11,848][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 20:17:15,251][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 208 @ 10781 updates, score 2.158) (writing took 7.7833471790654585 seconds)
[2022-06-13 20:17:15,252][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2022-06-13 20:17:15,254][train][INFO] - {"epoch": 208, "train_loss": "1.517", "train_ppl": "2.86", "train_wps": "20670.3", "train_ups": "0.1", "train_wpb": "213024", "train_bsz": "503.5", "train_num_updates": "10781", "train_lr": "0.000496604", "train_gnorm": "0.602", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "110969"}
[2022-06-13 20:17:15,284][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 20:17:15,292][fairseq.trainer][INFO] - begin training epoch 209
[2022-06-13 20:17:15,293][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 20:18:50,043][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-13 20:20:24,741][train_inner][INFO] - {"epoch": 209, "update": 208.385, "loss": "1.524", "ppl": "2.88", "wps": "20607.5", "ups": "0.1", "wpb": "212810", "bsz": "503.1", "num_updates": "10800", "lr": "0.000496522", "gnorm": "0.605", "loss_scale": "64", "train_wall": "1876", "gb_free": "6.2", "wall": "111158"}
[2022-06-13 20:25:27,542][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 20:26:05,061][valid][INFO] - {"epoch": 209, "valid_loss": "2.163", "valid_ppl": "4.48", "valid_wps": "66894.7", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10832", "valid_best_loss": "2.158"}
[2022-06-13 20:26:05,062][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 10832 updates
[2022-06-13 20:26:05,063][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:26:09,316][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:26:09,356][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 209 @ 10832 updates, score 2.163) (writing took 4.293591408059001 seconds)
[2022-06-13 20:26:09,356][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2022-06-13 20:26:09,357][train][INFO] - {"epoch": 209, "train_loss": "1.513", "train_ppl": "2.85", "train_wps": "20322", "train_ups": "0.1", "train_wpb": "212825", "train_bsz": "503.3", "train_num_updates": "10832", "train_lr": "0.000496383", "train_gnorm": "0.602", "train_loss_scale": "64", "train_train_wall": "488", "train_gb_free": "6.2", "train_wall": "111503"}
[2022-06-13 20:26:09,368][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 20:26:09,371][fairseq.trainer][INFO] - begin training epoch 210
[2022-06-13 20:26:09,371][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 20:34:18,476][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 20:34:56,130][valid][INFO] - {"epoch": 210, "valid_loss": "2.178", "valid_ppl": "4.53", "valid_wps": "66792.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10884", "valid_best_loss": "2.158"}
[2022-06-13 20:34:56,132][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 210 @ 10884 updates
[2022-06-13 20:34:56,132][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:35:00,373][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:35:00,427][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 210 @ 10884 updates, score 2.178) (writing took 4.295477454084903 seconds)
[2022-06-13 20:35:00,427][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2022-06-13 20:35:00,428][train][INFO] - {"epoch": 210, "train_loss": "1.502", "train_ppl": "2.83", "train_wps": "20841.7", "train_ups": "0.1", "train_wpb": "212854", "train_bsz": "503.5", "train_num_updates": "10884", "train_lr": "0.000496157", "train_gnorm": "0.622", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "112034"}
[2022-06-13 20:35:00,439][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 20:35:00,441][fairseq.trainer][INFO] - begin training epoch 211
[2022-06-13 20:35:00,442][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 20:43:06,466][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 20:43:44,280][valid][INFO] - {"epoch": 211, "valid_loss": "2.187", "valid_ppl": "4.55", "valid_wps": "66926.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10936", "valid_best_loss": "2.158"}
[2022-06-13 20:43:44,282][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 211 @ 10936 updates
[2022-06-13 20:43:44,283][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:43:48,566][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 20:43:48,653][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 211 @ 10936 updates, score 2.187) (writing took 4.371308033005334 seconds)
[2022-06-13 20:43:48,654][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2022-06-13 20:43:48,655][train][INFO] - {"epoch": 211, "train_loss": "1.513", "train_ppl": "2.85", "train_wps": "20961.1", "train_ups": "0.1", "train_wpb": "212927", "train_bsz": "503.5", "train_num_updates": "10936", "train_lr": "0.00049593", "train_gnorm": "0.627", "train_loss_scale": "64", "train_train_wall": "481", "train_gb_free": "6.2", "train_wall": "112562"}
[2022-06-13 20:43:48,675][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 20:43:48,681][fairseq.trainer][INFO] - begin training epoch 212
[2022-06-13 20:43:48,682][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 20:52:02,651][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 20:52:40,157][valid][INFO] - {"epoch": 212, "valid_loss": "2.146", "valid_ppl": "4.43", "valid_wps": "66960.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "10988", "valid_best_loss": "2.146"}
[2022-06-13 20:52:40,159][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 212 @ 10988 updates
[2022-06-13 20:52:40,160][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 20:52:44,310][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 20:52:47,681][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 212 @ 10988 updates, score 2.146) (writing took 7.522244096035138 seconds)
[2022-06-13 20:52:47,682][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2022-06-13 20:52:47,684][train][INFO] - {"epoch": 212, "train_loss": "1.508", "train_ppl": "2.84", "train_wps": "20544.8", "train_ups": "0.1", "train_wpb": "212966", "train_bsz": "503.5", "train_num_updates": "10988", "train_lr": "0.000495704", "train_gnorm": "0.617", "train_loss_scale": "64", "train_train_wall": "490", "train_gb_free": "6.2", "train_wall": "113101"}
[2022-06-13 20:52:47,707][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 20:52:47,715][fairseq.trainer][INFO] - begin training epoch 213
[2022-06-13 20:52:47,716][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 20:54:40,228][train_inner][INFO] - {"epoch": 213, "update": 212.231, "loss": "1.507", "ppl": "2.84", "wps": "20694.2", "ups": "0.1", "wpb": "212683", "bsz": "503.1", "num_updates": "11000", "lr": "0.000495652", "gnorm": "0.62", "loss_scale": "64", "train_wall": "1867", "gb_free": "6.2", "wall": "113214"}
[2022-06-13 21:01:01,649][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 21:01:39,105][valid][INFO] - {"epoch": 213, "valid_loss": "2.149", "valid_ppl": "4.44", "valid_wps": "67157.5", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11040", "valid_best_loss": "2.146"}
[2022-06-13 21:01:39,107][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 213 @ 11040 updates
[2022-06-13 21:01:39,107][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:01:43,576][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:01:43,646][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 213 @ 11040 updates, score 2.149) (writing took 4.539419805048965 seconds)
[2022-06-13 21:01:43,647][fairseq_cli.train][INFO] - end of epoch 213 (average epoch stats below)
[2022-06-13 21:01:43,648][train][INFO] - {"epoch": 213, "train_loss": "1.486", "train_ppl": "2.8", "train_wps": "20655.5", "train_ups": "0.1", "train_wpb": "212896", "train_bsz": "503.5", "train_num_updates": "11040", "train_lr": "0.000495478", "train_gnorm": "0.609", "train_loss_scale": "64", "train_train_wall": "489", "train_gb_free": "6.2", "train_wall": "113637"}
[2022-06-13 21:01:43,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 21:01:43,672][fairseq.trainer][INFO] - begin training epoch 214
[2022-06-13 21:01:43,673][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 21:09:54,087][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 21:10:31,632][valid][INFO] - {"epoch": 214, "valid_loss": "2.156", "valid_ppl": "4.46", "valid_wps": "66971.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11092", "valid_best_loss": "2.146"}
[2022-06-13 21:10:31,633][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 214 @ 11092 updates
[2022-06-13 21:10:31,634][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:10:35,839][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:10:35,893][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 214 @ 11092 updates, score 2.156) (writing took 4.2599216480739415 seconds)
[2022-06-13 21:10:35,894][fairseq_cli.train][INFO] - end of epoch 214 (average epoch stats below)
[2022-06-13 21:10:35,895][train][INFO] - {"epoch": 214, "train_loss": "1.482", "train_ppl": "2.79", "train_wps": "20797.7", "train_ups": "0.1", "train_wpb": "212875", "train_bsz": "503.5", "train_num_updates": "11092", "train_lr": "0.000495252", "train_gnorm": "0.618", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "114169"}
[2022-06-13 21:10:35,905][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 21:10:35,908][fairseq.trainer][INFO] - begin training epoch 215
[2022-06-13 21:10:35,908][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 21:18:47,042][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 21:19:24,413][valid][INFO] - {"epoch": 215, "valid_loss": "2.163", "valid_ppl": "4.48", "valid_wps": "67244.8", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11144", "valid_best_loss": "2.146"}
[2022-06-13 21:19:24,414][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 215 @ 11144 updates
[2022-06-13 21:19:24,415][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:19:28,511][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:19:28,574][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 215 @ 11144 updates, score 2.163) (writing took 4.159486663993448 seconds)
[2022-06-13 21:19:28,574][fairseq_cli.train][INFO] - end of epoch 215 (average epoch stats below)
[2022-06-13 21:19:28,575][train][INFO] - {"epoch": 215, "train_loss": "1.484", "train_ppl": "2.8", "train_wps": "20796.8", "train_ups": "0.1", "train_wpb": "213039", "train_bsz": "503.5", "train_num_updates": "11144", "train_lr": "0.000495026", "train_gnorm": "0.618", "train_loss_scale": "128", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "114702"}
[2022-06-13 21:19:28,589][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 21:19:28,593][fairseq.trainer][INFO] - begin training epoch 216
[2022-06-13 21:19:28,594][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 21:27:01,431][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-13 21:27:35,320][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 21:28:13,025][valid][INFO] - {"epoch": 216, "valid_loss": "2.166", "valid_ppl": "4.49", "valid_wps": "66986.2", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11195", "valid_best_loss": "2.146"}
[2022-06-13 21:28:13,027][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 216 @ 11195 updates
[2022-06-13 21:28:13,028][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:28:17,070][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:28:17,178][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 216 @ 11195 updates, score 2.166) (writing took 4.151444710092619 seconds)
[2022-06-13 21:28:17,179][fairseq_cli.train][INFO] - end of epoch 216 (average epoch stats below)
[2022-06-13 21:28:17,181][train][INFO] - {"epoch": 216, "train_loss": "1.471", "train_ppl": "2.77", "train_wps": "20536", "train_ups": "0.1", "train_wpb": "212851", "train_bsz": "503.3", "train_num_updates": "11195", "train_lr": "0.000494804", "train_gnorm": "0.617", "train_loss_scale": "64", "train_train_wall": "482", "train_gb_free": "6.2", "train_wall": "115231"}
[2022-06-13 21:28:17,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 21:28:17,214][fairseq.trainer][INFO] - begin training epoch 217
[2022-06-13 21:28:17,216][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 21:29:04,716][train_inner][INFO] - {"epoch": 217, "update": 216.096, "loss": "1.48", "ppl": "2.79", "wps": "20621.4", "ups": "0.1", "wpb": "212863", "bsz": "503.1", "num_updates": "11200", "lr": "0.000494783", "gnorm": "0.617", "loss_scale": "64", "train_wall": "1879", "gb_free": "6.2", "wall": "115278"}
[2022-06-13 21:36:27,948][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 21:37:05,712][valid][INFO] - {"epoch": 217, "valid_loss": "2.169", "valid_ppl": "4.5", "valid_wps": "67116.6", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11247", "valid_best_loss": "2.146"}
[2022-06-13 21:37:05,714][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 217 @ 11247 updates
[2022-06-13 21:37:05,715][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:37:09,872][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:37:09,926][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 217 @ 11247 updates, score 2.169) (writing took 4.212325193919241 seconds)
[2022-06-13 21:37:09,926][fairseq_cli.train][INFO] - end of epoch 217 (average epoch stats below)
[2022-06-13 21:37:09,927][train][INFO] - {"epoch": 217, "train_loss": "1.476", "train_ppl": "2.78", "train_wps": "20783.8", "train_ups": "0.1", "train_wpb": "212932", "train_bsz": "503.5", "train_num_updates": "11247", "train_lr": "0.000494578", "train_gnorm": "0.613", "train_loss_scale": "64", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "115763"}
[2022-06-13 21:37:09,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 21:37:09,940][fairseq.trainer][INFO] - begin training epoch 218
[2022-06-13 21:37:09,940][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 21:45:18,986][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 21:45:56,699][valid][INFO] - {"epoch": 218, "valid_loss": "2.165", "valid_ppl": "4.49", "valid_wps": "67226.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11299", "valid_best_loss": "2.146"}
[2022-06-13 21:45:56,700][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 218 @ 11299 updates
[2022-06-13 21:45:56,701][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:46:00,951][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:46:01,005][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 218 @ 11299 updates, score 2.165) (writing took 4.305091671994887 seconds)
[2022-06-13 21:46:01,006][fairseq_cli.train][INFO] - end of epoch 218 (average epoch stats below)
[2022-06-13 21:46:01,007][train][INFO] - {"epoch": 218, "train_loss": "1.47", "train_ppl": "2.77", "train_wps": "20841.5", "train_ups": "0.1", "train_wpb": "212855", "train_bsz": "503.5", "train_num_updates": "11299", "train_lr": "0.000494352", "train_gnorm": "0.611", "train_loss_scale": "64", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "116294"}
[2022-06-13 21:46:01,017][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 21:46:01,020][fairseq.trainer][INFO] - begin training epoch 219
[2022-06-13 21:46:01,020][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 21:54:11,594][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 21:54:49,058][valid][INFO] - {"epoch": 219, "valid_loss": "2.148", "valid_ppl": "4.43", "valid_wps": "67379.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11351", "valid_best_loss": "2.146"}
[2022-06-13 21:54:49,060][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 219 @ 11351 updates
[2022-06-13 21:54:49,061][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:54:53,429][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 21:54:53,485][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 219 @ 11351 updates, score 2.148) (writing took 4.424466657103039 seconds)
[2022-06-13 21:54:53,485][fairseq_cli.train][INFO] - end of epoch 219 (average epoch stats below)
[2022-06-13 21:54:53,486][train][INFO] - {"epoch": 219, "train_loss": "1.45", "train_ppl": "2.73", "train_wps": "20803.1", "train_ups": "0.1", "train_wpb": "213023", "train_bsz": "503.5", "train_num_updates": "11351", "train_lr": "0.000494126", "train_gnorm": "0.61", "train_loss_scale": "64", "train_train_wall": "486", "train_gb_free": "6.2", "train_wall": "116827"}
[2022-06-13 21:54:53,496][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 21:54:53,499][fairseq.trainer][INFO] - begin training epoch 220
[2022-06-13 21:54:53,499][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 22:02:38,427][train_inner][INFO] - {"epoch": 220, "update": 219.942, "loss": "1.46", "ppl": "2.75", "wps": "21228.8", "ups": "0.1", "wpb": "213743", "bsz": "505.3", "num_updates": "11400", "lr": "0.000493913", "gnorm": "0.602", "loss_scale": "64", "train_wall": "1871", "gb_free": "6.2", "wall": "117292"}
[2022-06-13 22:03:02,627][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 22:03:40,269][valid][INFO] - {"epoch": 220, "valid_loss": "2.175", "valid_ppl": "4.52", "valid_wps": "67122.3", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11403", "valid_best_loss": "2.146"}
[2022-06-13 22:03:40,270][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 220 @ 11403 updates
[2022-06-13 22:03:40,271][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 22:03:44,416][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 22:03:44,478][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 220 @ 11403 updates, score 2.175) (writing took 4.208421554998495 seconds)
[2022-06-13 22:03:44,479][fairseq_cli.train][INFO] - end of epoch 220 (average epoch stats below)
[2022-06-13 22:03:44,480][train][INFO] - {"epoch": 220, "train_loss": "1.446", "train_ppl": "2.73", "train_wps": "20841.6", "train_ups": "0.1", "train_wpb": "212822", "train_bsz": "503.5", "train_num_updates": "11403", "train_lr": "0.0004939", "train_gnorm": "0.619", "train_loss_scale": "64", "train_train_wall": "484", "train_gb_free": "6.2", "train_wall": "117358"}
[2022-06-13 22:03:44,491][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 22:03:44,494][fairseq.trainer][INFO] - begin training epoch 221
[2022-06-13 22:03:44,495][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 22:11:54,021][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 22:12:31,625][valid][INFO] - {"epoch": 221, "valid_loss": "2.142", "valid_ppl": "4.41", "valid_wps": "66824.4", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11455", "valid_best_loss": "2.142"}
[2022-06-13 22:12:31,627][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 221 @ 11455 updates
[2022-06-13 22:12:31,628][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 22:12:35,722][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_best.pt
[2022-06-13 22:12:39,352][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 221 @ 11455 updates, score 2.142) (writing took 7.724888890981674 seconds)
[2022-06-13 22:12:39,353][fairseq_cli.train][INFO] - end of epoch 221 (average epoch stats below)
[2022-06-13 22:12:39,355][train][INFO] - {"epoch": 221, "train_loss": "1.453", "train_ppl": "2.74", "train_wps": "20694.9", "train_ups": "0.1", "train_wpb": "212868", "train_bsz": "503.5", "train_num_updates": "11455", "train_lr": "0.000493674", "train_gnorm": "0.622", "train_loss_scale": "128", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "117893"}
[2022-06-13 22:12:39,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 22:12:39,376][fairseq.trainer][INFO] - begin training epoch 222
[2022-06-13 22:12:39,377][fairseq_cli.train][INFO] - Start iterating over samples
[2022-06-13 22:17:51,232][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2022-06-13 22:20:48,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-06-13 22:21:26,180][valid][INFO] - {"epoch": 222, "valid_loss": "2.146", "valid_ppl": "4.42", "valid_wps": "67033.1", "valid_wpb": "13578.9", "valid_bsz": "32", "valid_num_updates": "11506", "valid_best_loss": "2.142"}
[2022-06-13 22:21:26,181][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 222 @ 11506 updates
[2022-06-13 22:21:26,182][fairseq.trainer][INFO] - Saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 22:21:30,288][fairseq.trainer][INFO] - Finished saving checkpoint to /local/home/CE/musaeed/pcm_roberta/data-bin/multirun/2022-06-12/13-27-34/0/checkpoints/checkpoint_last.pt
[2022-06-13 22:21:30,332][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 222 @ 11506 updates, score 2.146) (writing took 4.150446949992329 seconds)
[2022-06-13 22:21:30,332][fairseq_cli.train][INFO] - end of epoch 222 (average epoch stats below)
[2022-06-13 22:21:30,333][train][INFO] - {"epoch": 222, "train_loss": "1.442", "train_ppl": "2.72", "train_wps": "20423.9", "train_ups": "0.1", "train_wpb": "212640", "train_bsz": "503.3", "train_num_updates": "11506", "train_lr": "0.000493452", "train_gnorm": "0.628", "train_loss_scale": "64", "train_train_wall": "485", "train_gb_free": "6.2", "train_wall": "118424"}
[2022-06-13 22:21:30,344][fairseq.data.iterators][INFO] - grouped total_num_itrs = 52
[2022-06-13 22:21:30,347][fairseq.trainer][INFO] - begin training epoch 223
[2022-06-13 22:21:30,347][fairseq_cli.train][INFO] - Start iterating over samples
